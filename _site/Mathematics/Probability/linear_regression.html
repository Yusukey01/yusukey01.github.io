<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    
    <title>Linear Regression - MATH-CS COMPASS</title>
    
    
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
    </script>
    <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff" as="font" type="font/woff2" crossorigin>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff" as="font" type="font/woff2" crossorigin>
    
    
    

    <link rel="stylesheet" href="../../../css/styles.css?v=1.0.2">
  
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

    <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
    <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Learn about linear regression in probabilistic Perspective.">
    <meta name="google-site-verification" content="IieEujypYW38caEVe8ymjczouNl56yxAy27iPztcfRA" />
    

    <link rel="manifest" href="/manifest.json">

    <!-- Theme color for Chrome, Android, and other browsers -->
    <meta name="theme-color" content="#007bff">
  
    <!-- iOS specific tags -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="MATH-CS COMPASS">
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Icon references -->
    <link rel="icon" type="image/png" sizes="1280x1280" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="icon" type="image/png" sizes="512x512" href="/images//maskable_icon_x512.png?v=1.0.2">
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="apple-touch-icon" href="/images/maskable_icon_x512.png?v=1.0.2">

    <!-- For Windows -->
    <meta name="msapplication-TileImage" content="/images/test1.png?v=1.0.2">
    <meta name="msapplication-TileColor" content="#007bff">

    <!-- Schema.org Structured Data for AI Optimization -->
    

    <!-- Article Schema for content pages -->
    
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Linear Regression",
      "description": "Learn about linear regression in probabilistic Perspective.",
      "datePublished": "2024-01-01",
      "dateModified": "2025-01-01",
      "author": {
        "@type": "Person",
        "name": "Yusuke Yokota",
        "jobTitle": "Mathematics & Computer Science Educator",
        "knowsAbout": [
          "Linear Algebra",
          "Machine Learning",
          "Computer Science",
          "Mathematics"
        ]
      },
      "publisher": {
        "@type": "Organization",
        "name": "MATH-CS COMPASS",
        "url": "https://yusukey01.github.io",
        "logo": {
          "@type": "ImageObject",
          "url": "https://yusukey01.github.io/images/maskable_icon_x512.png"
        }
      },
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://yusukey01.github.io/Mathematics/Probability/linear_regression.html"
      },
      "about": [
        
        { "@type": "Thing", "name": "Probability" },
        { "@type": "Thing", "name": "Statistics" }
        
      ],
      "educationalLevel": "university",
      "learningResourceType": "tutorial",
      "educationalUse": "instruction"
    }
    </script>
    
</head>

<body>
    <header>
    <nav class="navbar">
        <!-- Logo as Home Button -->
        <div class="logo-home">
            <a href="../../../index.html" 
               class="logo-link " 
               title="Home - Math-CS Compass">
                <img src="../../images/icon_x512.png" 
                     alt="Math-CS Compass Logo" 
                     class="nav-logo">
            </a>
        </div>

        <div class="search-container">
            <input type="text" id="search-input" placeholder="Search keywords...">
            <button id="search-button" aria-label="Search" title="Search website"><i class="fas fa-search"></i></button>
        </div>
        
        <div class="menu-toggle">
            <i class="fas fa-bars"></i>
        </div>
        
        <ul class="nav-links">
            <li><a href="../Linear_algebra/linear_algebra.html" >I - Linear Algebra to Algebraic Foundations</a></li>
            
            <li><a href="../Calculus/calculus.html" >II - Calculus to Optimization & Analysis</a></li>
            
            <li><a href="../Probability/probability.html" class="active">III - Probability & Statistics</a></li>
            
            <li><a href="../Discrete/discrete_math.html" >IV - Discrete Mathematics & Algorithms</a></li>
            
            <li><a href="../Machine_learning/ml.html" >V - Machine Learning</a></li>
        </ul>
    </nav>
</header>
    
    <!DOCTYPE html>
<html>
    <body>
        <!-- Meta script for linear_regression.html -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "Linear Regression",
        "description": "Learn about linear regression in probabilistic Perspective.",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "active",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
        },
        "about": [
            { "@type": "Thing", "name": "Linear Regression" },
            { "@type": "Thing", "name": "Probabilistic Perspective" },
            { "@type": "Thing", "name": "Least Squares" },
            { "@type": "Thing", "name": "Maximum Likelihood Estimation" },
            { "@type": "Thing", "name": "MLE" },
            { "@type": "Thing", "name": "Design Matrix" },
            { "@type": "Thing", "name": "Parameter Vector" },
            { "@type": "Thing", "name": "Weight Vector" },
            { "@type": "Thing", "name": "Normal Equations" },
            { "@type": "Thing", "name": "Residual Vector" },
            { "@type": "Thing", "name": "Linear Model" },
            { "@type": "Thing", "name": "Least-Squares Hyperplane" },
            { "@type": "Thing", "name": "Likelihood Function" },
            { "@type": "Thing", "name": "Log-Likelihood" },
            { "@type": "Thing", "name": "Matrix Calculus" },
            { "@type": "Thing", "name": "Statistical Regression" },
            { "@type": "Thing", "name": "Random Error" },
            { "@type": "Thing", "name": "Regression Line" }
        ],
        "teaches": [
            "Linear regression theory and implementation",
            "Probabilistic modeling approaches",
            "Maximum likelihood estimation",
            "Statistical regression analysis"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Probability & Statistics",
            "description": "Explore fundamental concepts of probability and statistics essential for machine learning",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "III",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT2H30M",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>

        <!-- WebApplication Schema for Interactive Tools (for pages with interactive visualizations) -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "WebApplication",
        "name": "Linear Regression Interactive Tool",
        "description": "Interactive tool for exploring linear regression concepts with real-time visualizations and parameter adjustment",
        "applicationCategory": "EducationalApplication",
        "operatingSystem": "Web Browser",
        "url": "https://yusukey01.github.io/Mathematics/Probability/linear_regression.html",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota"
        },
        "applicationSubCategory": "Statistical Analysis Tool",
        "featureList": [
            "Interactive mathematical visualization",
            "Real-time parameter adjustment",
            "Educational demonstrations",
            "Statistical analysis tools",
            "Data visualization",
            "Distribution plotting"
        ],
        "isAccessibleForFree": true,
        "educationalUse": "instruction",
        "educationalLevel": "university"
        }
        </script>
        <div class="hero-section">
            <h1 class="webpage-name">Linear Regression
            </h1>
        </div>

        
  <div class="quick-jump-container">
    <button type="button" id="quick-jump-toggle" class="quick-jump-toggle">
      <i class="fas fa-list"></i> <strong>Section III Navigation</strong>
    </button>
    <div id="quick-jump-menu" class="quick-jump-menu">
      <h3>Probability & Statistics</h3>
      <div class="quick-jump-links">

         
        <a href="probability.html">‚Üê Back to Section III Overview</a>
        <hr style="margin: 8px 0; border: 1px solid #ddd;">
        
        
        <a href="basic.html" >Part 1: Basic Probability Ideas</a>
        <a href="random_variables.html" >Part 2: Random Variables</a>
        <a href="gamma.html" >Part 3: Gamma & Beta Distribution</a>
        <a href="gaussian.html" >Part 4: Normal (Gaussian) Distribution</a>
        <a href="student.html" >Part 5: Student's t-Distribution</a>
        <a href="covariance.html" >Part 6: Covariance</a>
        <a href="correlation.html" >Part 7: Correlation</a>
        <a href="mvn.html" >Part 8: Multivariate Distributions</a>
        <a href="mle.html" >Part 9: Maximum Likelihood Estimation</a>
        <a href="hypothesis_testing.html" >Part 10: Statistical Inference & Hypothesis Testing</a>
        <a href="linear_regression.html" class="current-page">Part 11: Linear Regression</a>
        <a href="entropy.html" >Part 12: Entropy</a>
        <a href="convergence.html" >Part 13: Convergence</a>
        <a href="bayesian.html" >Part 14: Intro to Bayesian Statistics</a>
        <a href="expfamily.html" >Part 15: The Exponential Family</a>
        <a href="fisher_info.html" >Part 16: Fisher Information Matrix</a>
        <a href="decision_theory.html" >Part 17: Bayesian Decision Theory</a>
        <a href="markov.html" >Part 18: Markov Chains</a>
        <a href="monte_carlo.html" >Part 19: Monte Carlo Methods</a>
        <a href="importance_sampling.html" >Part 20: Importance Sampling</a>
        <a href="gaussian_process.html" >Part 21: Gaussian Processes</a>
      </div>
    </div>
</div>


        <div class="topic-nav">
            <a href="#recap">Recap from Linear Algebra</a>
            <a href="#lr">Linear Regression: A Probabilistic Perspective</a>
            <a href="#interactive-tool">Interactive Statistical Regression Tool</a>
        </div> 

        <div class="container">  
           
            <section id="recap" class="section-content">
            <h2>Recap from Linear Algebra</h2>
            <p>
            Given a set of observed data points \(\{(x_i, y_i)\}_{i = 1}^{n}\) where \(x_i \in \mathbb{R}^d, \quad y_i \in \mathbb{R}\),
            we assume that the given data can be explained by the <strong>linear model</strong>:
            \[y = X\beta + \epsilon \tag{1} \]
            where \(X \in \mathbb{R}^{n \times d}\) is the <strong>design matrix</strong>, \(\beta \in \mathbb{R}^d\) is the <strong>parameter(weight) vector</strong>, \(y \in \mathbb{R}^n\) is the
            <strong>observation vector</strong>, and \(\epsilon = y - X\beta\) is a <strong>residual vector</strong>. 
            <br><br>
            The dimension \(d\) is the number of features, and \(n\) is the number of data points. 
            The residual \(\epsilon\) is the "difference" between each observed value \(y_i\) and its corresponding predicted \(y\) value.
            The <strong>least-squares hyperplane</strong> represents the set of predicted \(y\) values based on "estimated" parameters(weights) \(\hat{\beta}\), 
            and it must satisfy the <strong>normal equations</strong>:
            \[
            X^TX\hat{\beta} = X^Ty \tag{2}
            \]
            <br><br>
            Note: the linear model is linear in terms of <strong>parameters \(\beta \, \)</strong> , not \(X\). We can choose any non-linear transformation
            for each \(x_i\). For example, \(y = \beta_0 + \beta_1 x^2 + \beta_2 \sin(2\pi x)\) is linear. So, \(y\) is modeled as a 
            <strong>linear combination</strong> of features(predictors) \(X\) with respect to the coefficients(weights) \(\beta\).
            </p>
            Also, check: <a href="../Linear_algebra/leastsquares.html"><strong>Least-Squares Problems</strong></a>.
            </section>

            <section id="lr" class="section-content">
            <h2>Linear Regression: A Probabilistic Perspective</h2>
            <p>
            We consider a probabilistic model for linear regression.  We assume that \(y_i\) is the observed value of 
            the random variable \(Y_i\) and it depends on the predictor \(x_i\). In addition, the random error \(\epsilon_i\) is 
            an i.i.d. random variable following \(\epsilon_i \sim N(0, \sigma^2)\). Then since \(\mathbb{E}[\epsilon_i]=0\), the unknown 
            mean of \(Y_i\) can be represented as
            \[
            \mathbb{E }[Y_i] = \mu_i = x_i^T \beta
            \]
            where \(\beta \in \mathbb{R}^d\) represents the unknown parameters of the regression model. 
            <br>
            This relationship defines the true regression line between \(\mathbb{E }[Y_i]\) and \(x_i\). Here, \(Y_i\) is 
            the independent random variable \(Y_i \sim N(\mu_i, \sigma^2)\). 
            <br>
            In other words, the conditional p.d.f of \(y_i\) is given by 
            \[
            p(y_i | x_i, \beta, \sigma^2) = \frac{1}{\sigma \sqrt{2\pi}} \exp \Big\{-\frac{1}{2\sigma^2}(y_i - x_i^T \beta)^2 \Big\}
            \]
            and its likelihood function of \(\beta\) for fixed \(\sigma^2\) is given by 
            \[
            \begin{align*}
            L(\beta) &= \prod_{i =1}^n \Big[ \frac{1}{\sigma \sqrt{2\pi}} \exp \Big\{-\frac{1}{2\sigma^2}(y_i - x_i^T \beta)^2 \Big\} \Big] \\\\
                     &=  \Big(\frac{1}{\sigma \sqrt{2\pi}}\Big)^n \exp \Big\{-\frac{1}{2\sigma^2} \sum_{i=1}^n (y_i - x_i^T \beta)^2 \Big\}.
            \end{align*}
            \]
            The log-likelihood fuction is given by 
            \[
            \ln L(\beta) = n \ln \Big(\frac{1}{\sigma \sqrt{2\pi}}\Big) -\frac{1}{2\sigma^2} \sum_{i=1}^n (y_i - x_i^T \beta)^2
            \]
            Setting the derivative with respect to \(\beta\) equal to zero: 
            \[
            \begin{align*}
            & \nabla_{\beta} = -\frac{1}{\sigma^2} \sum_{i=1}^n (y_i - x_i^T \beta) \cdot x_i = 0 \\\\
            &\Longrightarrow \sum_{i=1}^n (x_i^T \beta -y_i) \cdot x_i = 0 \\\\
            &\Longrightarrow (\sum_{i=1}^n x_ix_i^T)\beta - \sum_{i=1}^n x_i y_i = 0 \\\\
            &\Longrightarrow X^TX \beta = X^Ty
            \end{align*}
            \]
            This is equivalent to the normal equations (2) and thus, the MLE solution for linear regression corresponds to 
            the <strong>least-squares</strong> solution:
            \[
            \begin{align*}
            \hat{\beta}_{MLE} &= \Big(\sum_{i=1}^n x_ix_i^T \Big)^{-1}\Big(\sum_{i=1}^n x_i y_i \Big) \\\\
                              &=(X^TX)^{-1}X^Ty \\\\
                              &= \hat{\beta}_{LS} 
            \end{align*}
            \]
            <br>
            <div class="proof">
                <span class="proof-title">Least-Squares Solution</span>
                Consider the linear model (1) where \(X \in \mathbb{R}^{n \times d}\), \(\, y \in \mathbb{R}^n\), 
                \(\, \beta \in \mathbb{R}^d\).
                <br>
                To obtain the least-squares solution \(\hat{\beta}_{LS}\), we minimize the <strong>least-squares error</strong>:
                \[
                \begin{align*}
                \hat{\beta}_{LS} &= \arg \min_{\beta} \| y - X \beta \|_{2}^2 \\\\
                                  &= \arg \min_{\beta} (y - X \beta)^T (y - X \beta) \\\\
                                  &= \arg \min_{\beta} y^T y - y^T X \beta - \beta^T X^T y + \beta^T X^T X \beta \\\\
                                  &= \arg \min_{\beta} f(\beta)

                \end{align*}
                \]
                Differentiating \(f(\beta)\) and setting it equal to zero: 
                \[
                \begin{align*}
                & df = - X^Ty - X^Ty + 2X^TX\beta \\\\
                &\Longrightarrow -2 X^Ty + 2X^TX\beta = 0 \\\\
                &\Longrightarrow \hat{\beta}_{LS}  = (X^TX)^{-1}X^Ty \\\\
                \end{align*}
                \] 
                Note: The matrix \(X^TX\) is symmetric. 
                <br>
                If you are not familiar with Matrix Calculus, See: <a href="../Calculus/linear_approximation.html">Matrix Calculus</a>.
            </div>
            </p>
            </section>

            <section id="interactive-tool" class="section-content">
                <h2>Interactive Statistical Regression Tool</h2>
                <p>
                    This interactive tool allows you to explore linear regression from a statistical perspective. You can upload your own data or use the provided sample datasets to analyze regression models, check statistical significance, and perform diagnostics.
                </p>
                
                <!-- The tool will be rendered in this div -->
                <div id="statistical-regression-analyzer"></div>
            </section>

        </div>
        <script src="/js/main.js"></script>   
        <script src="/js/statistical-regression-analyzer.js"></script>
    </body>
</html>
    
    <footer>
    <div class="footer-content">
        <div class="footer-about">
            <h3>About MATH-CS COMPASS</h3>
            <p>Bridging the gap between pure mathematics and computer science applications.</p>
            <div class="contact-section">
                <strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSf3_RNkegREvfCEIQznn6SCaf-iB5c-Doxn7Ymuu78Uf-PBjg/viewform" target="_blank">
                    Submit Your Questions & Feedback <i class="fas fa-external-link-alt"></i>
                </a></strong>
            </div>
        </div>
        <div class="footer-links">
            <h3>Quick Links</h3>
            <ul>
                
                <li><a href="../../../index.html">Home</a></li>
                <li>
                <a href="../Linear_algebra/linear_algebra.html">
                    <span class="nav-number">I</span>
                    <span>Linear Algebra to Algebraic Foundations</span>
                </a>
                </li>
                <li>
                <a href="../Calculus/calculus.html">
                    <span class="nav-number">II</span>
                    <span>Calculus to Optimization & Analysis</span>
                </a>
                </li>
                <li>
                <a href="../Probability/probability.html">
                    <span class="nav-number">III</span>
                    <span>Probability & Statistics</span>
                </a>
                </li>
                <li>
                <a href="../Discrete/discrete_math.html">
                    <span class="nav-number">IV</span>
                    <span>Discrete Mathematics & Algorithms</span>
                </a>
                </li>
                <li>
                <a href="../Machine_learning/ml.html">
                    <span class="nav-number">V</span>
                    <span>Machine Learning</span>
                </a>
                </li>
            </ul>
        </div>
        <div class="footer-social">
            <h3>Connect With Me</h3>
            <p>
                <a href="https://x.com/MathCSCompass?t=Zi8nyfzszeFw8QizbJwnNg&s=09" target="_blank">
                    <i class="fab fa-x-twitter"></i> X (Twitter)
                </a>
            </p>
            <p>
                <a href="https://www.facebook.com/share/15uPaBWgQN/" target="_blank">
                    <i class="fab fa-facebook"></i> Facebook
                </a>
            </p>
      
            <h3>MATH-CS COMPASS App</h3>
            <div class="app-download-footer">
                <a href="https://play.google.com/store/apps/details?id=io.github.yusukey01.twa" target="_blank" rel="noopener">
                    <img src="../../../images/google-play-badge.png" 
                        alt="Get it on Google Play" 
                        class="google-play-badge">
                </a>
            </div>
            
        </div>

    </div>
    <div class="footer-bottom">
        <p>&copy; 2024-2025 MATH-CS COMPASS. All rights reserved.</p>
    </div>
</footer>
    <script src="../../../js/main.js?v=1.0.2"></script>
    <script src="../../../js/search.js?v=1.0.2"></script>
    

    <button id="go-to-top-btn" class="go-to-top-btn" title="Go to top">
        <i class="fas fa-arrow-up"></i>
    </button>
    <script>
        // Register the service worker
        if ('serviceWorker' in navigator) {
          window.addEventListener('load', () => {
            navigator.serviceWorker.register('/js/service-worker.js')
              .then(registration => {
                console.log('ServiceWorker registration successful with scope: ', registration.scope);
              })
              .catch(error => {
                console.log('ServiceWorker registration failed: ', error);
              });
          });
        }
      </script>
</body>
</html>