<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    
    <title>Convergence - MATH-CS COMPASS</title>
    
    
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
    </script>
    <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff" as="font" type="font/woff2" crossorigin>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff" as="font" type="font/woff2" crossorigin>
    
    
    

    <link rel="stylesheet" href="../../../css/styles.css?v=1.0.2">
  
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

    <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
    <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Learn about convergence in probability and distribution.">
    <meta name="google-site-verification" content="IieEujypYW38caEVe8ymjczouNl56yxAy27iPztcfRA" />
    

    <link rel="manifest" href="/manifest.json">

    <!-- Theme color for Chrome, Android, and other browsers -->
    <meta name="theme-color" content="#007bff">
  
    <!-- iOS specific tags -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="MATH-CS COMPASS">
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Icon references -->
    <link rel="icon" type="image/png" sizes="1280x1280" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="icon" type="image/png" sizes="512x512" href="/images//maskable_icon_x512.png?v=1.0.2">
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="apple-touch-icon" href="/images/maskable_icon_x512.png?v=1.0.2">

    <!-- For Windows -->
    <meta name="msapplication-TileImage" content="/images/test1.png?v=1.0.2">
    <meta name="msapplication-TileColor" content="#007bff">

    <!-- Schema.org Structured Data for AI Optimization -->
    

    <!-- Article Schema for content pages -->
    
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Convergence",
      "description": "Learn about convergence in probability and distribution.",
      "datePublished": "2024-01-01",
      "dateModified": "2025-01-01",
      "author": {
        "@type": "Person",
        "name": "Yusuke Yokota",
        "jobTitle": "Mathematics & Computer Science Educator",
        "knowsAbout": [
          "Linear Algebra",
          "Machine Learning",
          "Computer Science",
          "Mathematics"
        ]
      },
      "publisher": {
        "@type": "Organization",
        "name": "MATH-CS COMPASS",
        "url": "https://yusukey01.github.io",
        "logo": {
          "@type": "ImageObject",
          "url": "https://yusukey01.github.io/images/maskable_icon_x512.png"
        }
      },
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://yusukey01.github.io/Mathematics/Probability/convergence.html"
      },
      "about": [
        
        { "@type": "Thing", "name": "Probability" },
        { "@type": "Thing", "name": "Statistics" }
        
      ],
      "educationalLevel": "university",
      "learningResourceType": "tutorial",
      "educationalUse": "instruction"
    }
    </script>
    
</head>

<body>
    <header>
    <nav class="navbar">
        <!-- Logo as Home Button -->
        <div class="logo-home">
            <a href="../../../index.html" 
               class="logo-link " 
               title="Home - Math-CS Compass">
                <img src="../../images/icon_x512.png" 
                     alt="Math-CS Compass Logo" 
                     class="nav-logo">
            </a>
        </div>

        <div class="search-container">
            <input type="text" id="search-input" placeholder="Search keywords...">
            <button id="search-button" aria-label="Search" title="Search website"><i class="fas fa-search"></i></button>
        </div>
        
        <div class="menu-toggle">
            <i class="fas fa-bars"></i>
        </div>
        
        <ul class="nav-links">
            <li><a href="../Linear_algebra/linear_algebra.html" >I - Linear Algebra to Algebraic Foundations</a></li>
            
            <li><a href="../Calculus/calculus.html" >II - Calculus to Optimization & Analysis</a></li>
            
            <li><a href="../Probability/probability.html" class="active">III - Probability & Statistics</a></li>
            
            <li><a href="../Discrete/discrete_math.html" >IV - Discrete Mathematics & Algorithms</a></li>
            
            <li><a href="../Machine_learning/ml.html" >V - Machine Learning</a></li>
        </ul>
    </nav>
</header>
    
    <!DOCTYPE html>
<html>
    <body>
        <!-- Meta script for convergence.html -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "Convergence",
        "description": "Learn about convergence in probability and distribution.",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "active",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
        },
        "about": [
            { "@type": "Thing", "name": "Convergence in Probability" },
            { "@type": "Thing", "name": "Convergence in Distribution" },
            { "@type": "Thing", "name": "Moment Generating Function" },
            { "@type": "Thing", "name": "Central Limit Theorem" },
            { "@type": "Thing", "name": "Asymptotic Distribution" },
            { "@type": "Thing", "name": "Limiting Behavior" },
            { "@type": "Thing", "name": "Statistical Convergence" },
            { "@type": "Thing", "name": "Continuity Theorem" },
            { "@type": "Thing", "name": "Random Variables Sequences" }
        ],
        "teaches": [
            "Types of statistical convergence",
            "Central limit theorem proof",
            "Moment generating functions",
            "Asymptotic behavior analysis"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Probability & Statistics",
            "description": "Explore fundamental concepts of probability and statistics essential for machine learning",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "III",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT2H30M",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>

        <div class="hero-section">
            <h1 class="webpage-name">Convergence
            </h1>
        </div>

        
  <div class="quick-jump-container">
    <button type="button" id="quick-jump-toggle" class="quick-jump-toggle">
      <i class="fas fa-list"></i> <strong>Section III Navigation</strong>
    </button>
    <div id="quick-jump-menu" class="quick-jump-menu">
      <h3>Probability & Statistics</h3>
      <div class="quick-jump-links">

         
        <a href="probability.html">‚Üê Back to Section III Overview</a>
        <hr style="margin: 8px 0; border: 1px solid #ddd;">
        
        
        <a href="basic.html" >Part 1: Basic Probability Ideas</a>
        <a href="random_variables.html" >Part 2: Random Variables</a>
        <a href="gamma.html" >Part 3: Gamma & Beta Distribution</a>
        <a href="gaussian.html" >Part 4: Normal (Gaussian) Distribution</a>
        <a href="student.html" >Part 5: Student's t-Distribution</a>
        <a href="covariance.html" >Part 6: Covariance</a>
        <a href="correlation.html" >Part 7: Correlation</a>
        <a href="mvn.html" >Part 8: Multivariate Distributions</a>
        <a href="mle.html" >Part 9: Maximum Likelihood Estimation</a>
        <a href="hypothesis_testing.html" >Part 10: Statistical Inference & Hypothesis Testing</a>
        <a href="linear_regression.html" >Part 11: Linear Regression</a>
        <a href="entropy.html" >Part 12: Entropy</a>
        <a href="convergence.html" class="current-page">Part 13: Convergence</a>
        <a href="bayesian.html" >Part 14: Intro to Bayesian Statistics</a>
        <a href="expfamily.html" >Part 15: The Exponential Family</a>
        <a href="fisher_info.html" >Part 16: Fisher Information Matrix</a>
        <a href="decision_theory.html" >Part 17: Bayesian Decision Theory</a>
        <a href="markov.html" >Part 18: Markov Chains</a>
        <a href="monte_carlo.html" >Part 19: Monte Carlo Methods</a>
        <a href="importance_sampling.html" >Part 20: Importance Sampling</a>
        <a href="gaussian_process.html" >Part 21: Gaussian Processes</a>
      </div>
    </div>
</div>


        <div class="topic-nav">
            <a href="#convergence">Convergence in Probability</a>
            <a href="#dist">Convergence in distribution</a>
            <a href="#mgf">Moment Generating Function(mgf)</a>
        </div> 

        <div class="container">  
           
            <section id="convergence" class="section-content">
            <h2>Convergence in Probability</h2>
            <p> 
            Even in computer science, we often accept the convergence of probabilities and distributions based on experimental results. 
            However, to gain a deeper understanding of statistics, we introduce formal definitions to clarify what convergence means in 
            statistical contexts. 
            <br><br>
            Let \(\{X_n\}\) be a sequence of random variables and \(X\) be a random variable defined on a sample space. 
            \(X_n\) <strong>converges in probability</strong> to \(X\) denoted by
            \[
            X_n \xrightarrow{P} X,
            \]
             if \(\quad \forall \epsilon > 0\), 
            \[
            \lim_{n \to \infty} P [| X_n - X | \geq \epsilon ] = 0 
            \]
            or equivalently,
            \[
            \lim_{n \to \infty} P [| X_n - X | < \epsilon ] = 1.
            \]
            <br>
            <div class="theorem">
                <span class="theorem-title">Theorem 1:</span>
                Suppose \(X_n \xrightarrow{P} a\) where \(a\) is a constant, and the real function \(f\) is continuous at \(a\). Then 
                \[
                f(X_n) \xrightarrow{P} f(a).
                \]
            </div>

            <div class="proof">
                <span class="proof-title">Proof:</span>
                Let \(\epsilon > 0\). Since \(f\) is continuous at \(a\), \(\, \exists \delta > 0 \) such that if 
                \[
                |x - a | < \delta \Longrightarrow |f(x) - f(a)| < \epsilon. 
                \]
                Thus, 
                \[
                |f(x) - f(a)| \geq \epsilon \Longrightarrow  |x - a | \geq \delta
                \]
                Substituting \(X_n\) for \(x\), we obtain 
                \[
                P[|f(X_n) - f(a)| \geq \epsilon] \leq P [| X_n - a| \geq \delta ].
                \]
                As \(n \to \infty\), we have \(f(X_n) \xrightarrow{P} f(a)\).
            </div>
            <br>
            In general, if \(X_n \xrightarrow{P} X,\) and \(f\) is a continuous function, then 
            \[
            f(X_n) \xrightarrow{P} f(X).
            \]
            </p>
            </section>

            <section id="dist" class="section-content">
            <h2>Convergence in distribution</h2>
            <p> 
            Let \(\{X_n\}\) be a sequence of random variables and let \(X\) be a random variable. Let \(F_{X_n}\) and 
            \(F_X\) be the cdfs of \(X_n\) and \(X\)  respectively. 
            <br>
            Let \(C(F_X)\) denote the set of all points where \(F_X\) is continuous. 
            <br>
            \(X_n\) <strong>converges in distribution</strong> to \(X\) denoted by 
            \[
            X_n \xrightarrow{D} X,
            \]
            if \(\quad \forall x \in C(F_{X})\), 
            \[
            \lim_{n \to \infty} F_{X_n} (x) = F_X (x).
            \]
            Often the distribution of \(X\) is called the <strong>asymptotic(limiting) distribution</strong> of the sequence of random 
            variables of \(\{X_n\}\).
            <br>
            In this case, \(X_n\) does NOT always get close to \(X\) in probability. However, following the theorem gives us a connection 
            between the two concepts.
            <div class="theorem">
                <span class="theorem-title">Theorem 2:</span>
                If \(X_n\) converges to \(X\) in probability, then \(X_n\) converges to \(X\) in distribution. 
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                Suppose \(X_n \xrightarrow{P} X\), and let \(x\) be a point of continuity of \(F_{x_n}\).  
                <br>
                \(\forall \, \epsilon > 0\),
                \[
                \begin{align*}
                F_{X_n}(x) &= P[X_n \leq x] \\\\
                           &= P[\{X_n \leq x\} \cap \{|X_n - X| < \epsilon\}] + P [\{X_n \leq x\} \cap \{|X_n - X| \geq \epsilon\}] \\\\
                           &\leq P[X \leq x + \epsilon] + P[|X_n - X| \geq \epsilon]
                \end{align*}
                \]
                Since \(X_n \xrightarrow{P} X\), we know  \(P[|X_n - X| \geq \epsilon] \to 0\). Then we get a upper bound 
                \[
                \lim_{n \to \infty} \sup F_{X_n}(x) \leq F_{X}(x + \epsilon) \tag{1}.
                \]
                Similarly, we can get a lower bound:
                \[
                P[X_n  > x ] \leq P[X \geq x - \epsilon] + P[|X_n - X| \geq \epsilon]
                \]
                \[
                \Longrightarrow  \lim_{n \to \infty} \inf F_{X_n}(x) \geq F_X (x - \epsilon) \tag{2}.
                \]
                Combining (1) and (2), we obtain 
                \[
                F_X(x - \epsilon) \leq \lim_{n \to \infty} \inf F_{X_n}(x) \leq \lim_{n \to \infty} \sup F_{X_n}(x) \leq F_X (x + \epsilon).
                \]
                Here, as \(\epsilon \to 0\), we have
                \[
                \lim_{n \to \infty} F_{X_n}(x) = F_X (x)
                \]
                because \(x\) is a point of continuity of \(F_{x_n}\). 
                <br>
                Therefore
                \[
                X_n \xrightarrow{D} X.
                \]
            </div>
            Now, we can see that the <strong>central limit theorem(CLT)</strong> is a statement about convergence in distribution. 
            (See <a href="gaussian.html">Normal Distribution</a>)
            </p>
            </section>

            <section id="mgf" class="section-content">
            <h2>Moment Generating Function(mgf)</h2>
            <p>
            Let \(X\) be a random variable such that for some \(h > 0\), the expectation of \(e^{tX}\) exists for \(t \in (-h, h)\). 
            The <strong>moment generating function(mgf)</strong> of \(X\) is given by
            \[
            M(t) = \mathbb{E } (e^{tX}), \qquad t \in (-h, h).
            \]
            Note: we must need an open interval about 0. 
            <br><br>
            We revisit the central limit theorem and now we can prove it under some assumption. 
            <div class="theorem">
                <span class="theorem-title">Theorem 3: Central Limit Theorem(CLT)</span>
                Let \(X_1, X_2, \cdots, X_n\) be a random sample from a distribution that has mean \(\mu\) and variance \(\sigma^2 >0\). 
                Then the random variable 
                \[
                Y_n = \frac{\sum X_i - n\mu}{\sigma \sqrt{n}} = \frac{\sqrt{n}(\bar{X_n}-\mu)}{\sigma}
                \]
                converges in distribution to a random variable that has a standard normal distribution:
                \[
                Y_n  \xrightarrow{D}  N(0, 1).
                \]
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                Assume that the mgf \(M(t) = \mathbb{E } (e^{tX})\) exists for \(t \in (-h, h)\). 
                <br>
                The mgf for \(X-\mu\) is:
                \[
                m(t) = \mathbb{E }[e^{t(X-\mu)}] = e^{-\mu t} M(t), \qquad t \in (-h, h)
                \]
                and satisfies that 
                \(m(0) = 1\), \(\quad m'(0) = \mathbb{E }(X -\mu)\), and \(m''(0) = \mathbb{E }[(X-\mu)^2] = \sigma^2\).
                <br>
                By Taylor's theorem with remainder, \(\exists \, \xi \in (0, t)\) such that 
                \[
                \begin{align*}
                m(t) &= m(0) + m'(0)t + \frac{m''(\xi)t^2}{2} \\\\
                    &=  m(0) + m'(0)t + \frac{\sigma^2 t^2}{2} - \frac{\sigma^2 t^2}{2} + \frac{m''(\xi)t^2}{2} \\\\
                    &=  1 + \frac{\sigma^2 t^2}{2} + \frac{[m''(\xi) - \sigma^2]t^2}{2}  \tag{3}
                \end{align*}
                \]
                Consider the mgf for the normalized sum:
                \[
                \begin{align*}
                M(t ; n) &= \mathbb{E }\Big[\exp \Big(t \frac{\sum X_i - n \mu}{\sigma \sqrt{n}}\Big)\Big] \\\\
                        &= \Big\{\mathbb{E } \Big[\exp \Big(t \frac{X - \mu}{\sigma \sqrt{n}}\Big)\Big]\Big\}^n \\\\
                        &= \Big[m \Big(\frac{t}{\sigma \sqrt{n}}\Big)\Big]^n
                \end{align*}
                \]
                where \(\frac{t}{\sigma \sqrt{n}} \in (-h, h) \).
                <br><br>
                Replacing \(t\) by \(\frac{t}{\sigma \sqrt{n}}\) in equation (3):
                \[
                m \Big(\frac{t}{\sigma \sqrt{n}}\Big) =  1 + \frac{t^2}{2n} + \frac{[m''(\xi) - \sigma^2]t^2}{2n\sigma^2}
                \]
                where \(\xi \in (0, \frac{t}{\sigma \sqrt{n}})\) and \(t \in (-h\sigma \sqrt{n}, h \sigma \sqrt{n})\).
                <br><br>
                Thus, 
                \[
                M(t ; n) = \Big\{1 + \frac{t^2}{2n} + \frac{[m''(\xi) - \sigma^2]t^2}{2n\sigma^2} \Big\}^n .
                \]
                Since \(m''(t)\) is continuous at \(t = 0\) and \(\xi \to 0\) as \(n \to \infty\), 
                \[
                \lim_{n \to \infty}[m''(\xi) - \sigma^2] = 0.
                \]
                Note that we use the fact: 
                \[
                \lim_{n \to \infty} \Big(1 + \frac{x}{n} \Big)^n = e^x
                \]
                with \(x = \frac{t^2}{2}\). Thus, for all \(t \in \mathbb{R}\), 
                \[
                \lim_{n \to \infty} M(t ; n) = e^{\frac{t^2}{2}}.
                \]
                This is the mgf of the standard normal distribution \(N(0, 1)\).
                Therefore, the random variable \(Y_n = \frac{\sqrt{n}(\bar{X_n}-\mu)}{\sigma}\) has an asymptotic 
                standard normal distribution: 
                \[
                Y_n = \frac{\sqrt{n}(\bar{X_n}-\mu)}{\sigma} \xrightarrow{D} N(0, 1).
                \]
            </div>
            Note: Without standardization, we can say that
            \[
            \sqrt{n}(\bar{X_n}-\mu) \xrightarrow{D} N(0, \sigma^2).
            \]
            <br>
            Note: We can get the mgf of \(N(0, 1)\) as follows:
            \[
            \begin{align*}
            M(t) &= \int_{-\infty}^{\infty} e^{tx} \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \, dx \\\\
                 &= \int_{-\infty}^{\infty} e^{-\frac{1}{2}(x^2 -2tx)} \frac{1}{\sqrt{2\pi}}  \, dx \\\\
                 &= \int_{-\infty}^{\infty} e^{-\frac{1}{2}\{(x-t)^2 -t^2\}} \frac{1}{\sqrt{2\pi}}  \, dx \\\\
                 &= e^{\frac{t^2}{2}}\int_{-\infty}^{\infty}  \frac{1}{\sqrt{2\pi}} e^{-\frac{(x-t)^2}{2}} \, dx \\\\
                 &= e^{\frac{t^2}{2}} \cdot 1
            \end{align*}
            \]
            </p>
            </section>
        </div>
        <script src="/js/main.js"></script>    
    </body>
</html>
    
    <footer>
    <div class="footer-content">
        <div class="footer-about">
            <h3>About MATH-CS COMPASS</h3>
            <p>Bridging the gap between pure mathematics and computer science applications.</p>
            <div class="contact-section">
                <strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSf3_RNkegREvfCEIQznn6SCaf-iB5c-Doxn7Ymuu78Uf-PBjg/viewform" target="_blank">
                    Submit Your Questions & Feedback <i class="fas fa-external-link-alt"></i>
                </a></strong>
            </div>
        </div>
        <div class="footer-links">
            <h3>Quick Links</h3>
            <ul>
                
                <li><a href="../../../index.html">Home</a></li>
                <li>
                <a href="../Linear_algebra/linear_algebra.html">
                    <span class="nav-number">I</span>
                    <span>Linear Algebra to Algebraic Foundations</span>
                </a>
                </li>
                <li>
                <a href="../Calculus/calculus.html">
                    <span class="nav-number">II</span>
                    <span>Calculus to Optimization & Analysis</span>
                </a>
                </li>
                <li>
                <a href="../Probability/probability.html">
                    <span class="nav-number">III</span>
                    <span>Probability & Statistics</span>
                </a>
                </li>
                <li>
                <a href="../Discrete/discrete_math.html">
                    <span class="nav-number">IV</span>
                    <span>Discrete Mathematics & Algorithms</span>
                </a>
                </li>
                <li>
                <a href="../Machine_learning/ml.html">
                    <span class="nav-number">V</span>
                    <span>Machine Learning</span>
                </a>
                </li>
            </ul>
        </div>
        <div class="footer-social">
            <h3>Connect With Me</h3>
            <p>
                <a href="https://x.com/MathCSCompass?t=Zi8nyfzszeFw8QizbJwnNg&s=09" target="_blank">
                    <i class="fab fa-x-twitter"></i> X (Twitter)
                </a>
            </p>
            <p>
                <a href="https://www.facebook.com/share/15uPaBWgQN/" target="_blank">
                    <i class="fab fa-facebook"></i> Facebook
                </a>
            </p>
      
            <h3>MATH-CS COMPASS App</h3>
            <div class="app-download-footer">
                <a href="https://play.google.com/store/apps/details?id=io.github.yusukey01.twa" target="_blank" rel="noopener">
                    <img src="../../../images/google-play-badge.png" 
                        alt="Get it on Google Play" 
                        class="google-play-badge">
                </a>
            </div>
            
        </div>

    </div>
    <div class="footer-bottom">
        <p>&copy; 2024-2025 MATH-CS COMPASS. All rights reserved.</p>
    </div>
</footer>
    <script src="../../../js/main.js?v=1.0.2"></script>
    <script src="../../../js/search.js?v=1.0.2"></script>
    

    <button id="go-to-top-btn" class="go-to-top-btn" title="Go to top">
        <i class="fas fa-arrow-up"></i>
    </button>
    <script>
        // Register the service worker
        if ('serviceWorker' in navigator) {
          window.addEventListener('load', () => {
            navigator.serviceWorker.register('/js/service-worker.js')
              .then(registration => {
                console.log('ServiceWorker registration successful with scope: ', registration.scope);
              })
              .catch(error => {
                console.log('ServiceWorker registration failed: ', error);
              });
          });
        }
      </script>
</body>
</html>