<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    
    <title>Probability & Statistics - MATH-CS COMPASS</title>
    
    
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
    </script>
    <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff" as="font" type="font/woff2" crossorigin>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff" as="font" type="font/woff2" crossorigin>
    
    
    

    <link rel="stylesheet" href="../../css/styles.css?v=1.0.2">
  
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

    <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
    <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Explore fundamental concepts of probability and statistics essential for machine learning, including probability theory, random variables, distributions, Bayesian inference, entropy, and the Fisher Information Matrix">
    <meta name="google-site-verification" content="IieEujypYW38caEVe8ymjczouNl56yxAy27iPztcfRA" />
    

    <link rel="manifest" href="/manifest.json">

    <!-- Theme color for Chrome, Android, and other browsers -->
    <meta name="theme-color" content="#007bff">
  
    <!-- iOS specific tags -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="MATH-CS COMPASS">
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Icon references -->
    <link rel="icon" type="image/png" sizes="1280x1280" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="icon" type="image/png" sizes="512x512" href="/images//maskable_icon_x512.png?v=1.0.2">
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="apple-touch-icon" href="/images/maskable_icon_x512.png?v=1.0.2">

    <!-- For Windows -->
    <meta name="msapplication-TileImage" content="/images/test1.png?v=1.0.2">
    <meta name="msapplication-TileColor" content="#007bff">

    <!-- Schema.org Structured Data for AI Optimization -->
    

    <!-- Article Schema for content pages -->
    
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Probability & Statistics",
      "description": "Explore fundamental concepts of probability and statistics essential for machine learning, including probability theory, random variables, distributions, Bayesian inference, entropy, and the Fisher Information Matrix",
      "datePublished": "2024-01-01",
      "dateModified": "2025-01-01",
      "author": {
        "@type": "Person",
        "name": "Yusuke Yokota",
        "jobTitle": "Mathematics & Computer Science Educator",
        "knowsAbout": [
          "Linear Algebra",
          "Machine Learning",
          "Computer Science",
          "Mathematics"
        ]
      },
      "publisher": {
        "@type": "Organization",
        "name": "MATH-CS COMPASS",
        "url": "https://math-cs-compass.com",
        "logo": {
          "@type": "ImageObject",
          "url": "https://math-cs-compass.com/images/maskable_icon_x512.png"
        }
      },
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://math-cs-compass.com/Mathematics/Probability/probability.html"
      },
      "about": [
        
        { "@type": "Thing", "name": "Probability" },
        { "@type": "Thing", "name": "Statistics" }
        
      ],
      "educationalLevel": "university",
      "learningResourceType": "tutorial",
      "educationalUse": "instruction"
    }
    </script>
    
</head>

<body>
    <header>
    <nav class="navbar">
        <!-- Logo as Home Button -->
        <div class="logo-home">
            <a href="../../index.html" 
               class="logo-link " 
               title="Home - Math-CS Compass">
                <img src="../../images/icon_x512.png" 
                     alt="Math-CS Compass Logo" 
                     class="nav-logo">
            </a>
        </div>

        <div class="search-container">
            <input type="text" id="search-input" placeholder="Search keywords...">
            <button id="search-button" aria-label="Search" title="Search website"><i class="fas fa-search"></i></button>
        </div>
        
        <div class="menu-toggle">
            <i class="fas fa-bars"></i>
        </div>
        
        <ul class="nav-links">
            <li><a href="../Linear_algebra/linear_algebra.html" >I - Linear Algebra to Algebraic Foundations</a></li>
            
            <li><a href="../Calculus/calculus.html" >II - Calculus to Optimization & Analysis</a></li>
            
            <li><a href="../Probability/probability.html" class="active">III - Probability & Statistics</a></li>
            
            <li><a href="../Discrete/discrete_math.html" >IV - Discrete Mathematics & Algorithms</a></li>
            
            <li><a href="../Machine_learning/ml.html" >V - Machine Learning</a></li>
        </ul>
    </nav>
</header>
    
    <!DOCTYPE html>
<html>
    <body> 
        <!-- Course Schema for Probability & Statistics Section -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "Course",
        "name": "Probability & Statistics",
        "description": "Explore fundamental concepts of probability and statistics essential for machine learning, including probability theory, random variables, distributions, Bayesian inference, entropy, and the Fisher Information Matrix",
        "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://math-cs-compass.com"
        },
        "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
        },
        "courseCode": "III",
        "educationalLevel": "university",
        "about": [
            { "@type": "Thing", "name": "Probability Theory" },
            { "@type": "Thing", "name": "Statistics" },
            { "@type": "Thing", "name": "Bayesian Inference" },
            { "@type": "Thing", "name": "Random Variables" },
            { "@type": "Thing", "name": "Statistical Distributions" }
        ],
        "teaches": [
            "Fundamental probability concepts",
            "Random variables and distributions",
            "Bayesian statistics and inference",
            "Maximum likelihood estimation",
            "Hypothesis testing and confidence intervals",
            "Entropy and information theory",
            "Markov chains and Monte Carlo methods"
        ],
        "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT2H30M",
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota"
            }
        },
        "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
        },
        "isPartOf": {
            "@type": "EducationalOrganization",
            "name": "MATH-CS COMPASS"
        }
        }
        </script>
        <div class="hero-section">
            <h1 class="webpage-name">III - Probability & Statistics
            </h1>
        </div>

        
  <div class="quick-jump-container">
    <button type="button" id="quick-jump-toggle" class="quick-jump-toggle">
      <i class="fas fa-list"></i> <strong>Section III Navigation</strong>
    </button>
    <div id="quick-jump-menu" class="quick-jump-menu">
      <h3>Probability & Statistics</h3>
      <div class="quick-jump-links">

         
        
        <a href="../Probability/basic.html" >Part 1: Basic Probability Ideas</a>
        <a href="../Probability/random_variables.html" >Part 2: Random Variables</a>
        <a href="../Probability/gamma.html" >Part 3: Gamma & Beta Distribution</a>
        <a href="../Probability/gaussian.html" >Part 4: Normal (Gaussian) Distribution</a>
        <a href="../Probability/student.html" >Part 5: Student's t-Distribution</a>
        <a href="../Probability/covariance.html" >Part 6: Covariance</a>
        <a href="../Probability/correlation.html" >Part 7: Correlation</a>
        <a href="../Probability/mvn.html" >Part 8: Multivariate Distributions</a>
        <a href="../Probability/mle.html" >Part 9: Maximum Likelihood Estimation</a>
        <a href="../Probability/hypothesis_testing.html" >Part 10: Statistical Inference & Hypothesis Testing</a>
        <a href="../Probability/linear_regression.html" >Part 11: Linear Regression</a>
        <a href="../Probability/entropy.html" >Part 12: Entropy</a>
        <a href="../Probability/convergence.html" >Part 13: Convergence</a>
        <a href="../Probability/bayesian.html" >Part 14: Intro to Bayesian Statistics</a>
        <a href="../Probability/expfamily.html" >Part 15: The Exponential Family</a>
        <a href="../Probability/fisher_info.html" >Part 16: Fisher Information Matrix</a>
        <a href="../Probability/decision_theory.html" >Part 17: Bayesian Decision Theory</a>
        <a href="../Probability/markov.html" >Part 18: Markov Chains</a>
        <a href="../Probability/monte_carlo.html" >Part 19: Monte Carlo Methods</a>
        <a href="../Probability/importance_sampling.html" >Part 20: Importance Sampling</a>
        <a href="../Probability/gaussian_process.html" >Part 21: Gaussian Processes</a>
      </div>
    </div>
</div>


        <div class="container">

            <div class="homepage-introduction">
                <p>
                    To truly understand machine learning, a strong grasp of <strong>probability theory</strong> and <strong>statistics</strong> 
                    is essential because machine learning is an elegant combination of statistics and algorithms. In Section I: Linear Algebra, we 
                    intentionally avoided applications related to statistics, focusing instead on foundational concepts. Now, it's time to build 
                    upon the probabilistic basis of machine learning. This section introduces the essential concepts of probability, providing 
                    the tools and insights necessary to understand and apply machine learning techniques. At its core, statistics involves inferring 
                    unknown parameters from outcomes. This process is the inverse of probability theory. Two main approaches dominate statistical 
                    inference: <strong>frequentist statistics</strong>, which treats parameters as fixed and data as random, and in contrast, 
                    <strong>Bayesian statistics</strong>, which treats data as fixed and parameters as random. In particular, Bayesian statistics 
                    forms the foundation of many machine learning algorithms.
                </p>
            </div>

            <section>
                <div class="topic-cards">

                    <div class="card">
                        <div class="card-icon">p</div>
                        <h3><a href="basic.html">Part 1: Basic Probability Ideas</a></h3>
                        <div class="keywords">
                            <span>Probability</span>
                            <span>Sample Space</span>
                            <span>Events</span>
                            <span>Mutually Exclusive</span>
                            <span>Permutation</span>
                            <span>Combinations</span>
                            <span>Conditional Probability</span>
                            <span>Independent Events</span>
                            <span>Law of Total Probability</span>
                            <span>Bayes' Theorem</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(X\)</div>
                        <h3><a href="random_variables.html">Part 2: Random Variables</a></h3>
                        <div class="keywords">
                            <span>Discrete Random Variables</span>
                            <span>Continuous Random Variables</span>
                            <span>Probability Mass Function (p.m.f.)</span>
                            <span>Probability Density Function (p.d.f.)</span>
                            <span>Cumulative Distribution Function(c.d.f.)</span>
                            <span>Expected Value</span>
                            <span>Variance</span>
                            <span>Standard Deviation</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\Gamma\)</div>
                        <h3><a href="gamma.html">Part 3: Gamma & Beta Distribution</a></h3>
                        <div class="keywords">
                            <span><strong>Interactive Demo</strong></span>
                            <span>Gamma Distribution</span>
                            <span>Gamma Function</span>
                            <span>Exponential Distribution</span>
                            <span>Beta Function</span>
                            <span>Beta Distribution</span>
                            <span>Uniform Distribution</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\mathcal{N}\)</div>
                        <h3><a href="gaussian.html">Part 4: Normal (Gaussian) Distribution</a></h3>
                        <div class="keywords">
                            <span>Gaussian Function</span>
                            <span>Error Function</span>
                            <span>Gaussian Integral</span>
                            <span>Normal(Gaussian) Distribution</span>
                            <span>Standard Normal Distribution</span>
                            <span>Independent and Identically Distributed(i.i.d.)</span>
                            <span>Random Sample</span>
                            <span>Sample Mean</span>
                            <span>Sample Variance</span>
                            <span>Central Limit Theorem</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">t</div>
                        <h3><a href="student.html">Part 5: Student's \(t\)-Distribution</a></h3>
                        <div class="keywords">
                            <span>Student's \(t\)-Distribution</span>
                            <span>Degrees of Freedom</span>
                            <span>Cauchy Distribution</span>
                            <span>Half Cauchy Distribution</span>
                            <span>Laplace Distribution</span>
                            <span>Double Sided Exponential Distribution</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">Cov</div>
                        <h3><a href="covariance.html">Covariance</a></h3>
                        <div class="keywords">
                            <span><strong>Code Included</strong></span>
                            <span>Covariance</span>
                            <span>Covariance Matrix</span>
                            <span>Total Variance</span>
                            <span>Principal Component</span>
                            <span>Principal Component Analysis(PCA)</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">r</div>
                        <h3><a href="correlation.html">Part 7: Correlation</a></h3>
                        <div class="keywords">
                            <span>Cross-Covariance Matrix</span>
                            <span>Auto-Covariance Matrix</span>
                            <span>Correlation Coefficient</span>
                            <span>Correlation Matrix</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\Sigma\)</div>
                        <h3><a href="mvn.html">Part 8: Multivariate Distributions</a></h3>
                        <div class="keywords">
                            <span>Multivariate Normal Distribution (MVN)</span>
                            <span>Mahalanobis Distance</span>
                            <span>Bivariate Normal Distribution</span>
                            <span>Cholesky Decomposition</span>                      
                            <span>Dirichlet Distribution</span>
                            <span>Probability Simplex</span>
                            <span>Wishart Distribution</span>
                            <span>Inverse Wishart Distribution</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\mathcal{L}\)</div>
                        <h3><a href="mle.html">Part 9: Maximum Likelihood Estimation</a></h3>
                        <div class="keywords">
                            <span>Point Estimator</span>
                            <span>Mean Square Error(MSE)</span>
                            <span>Standard Error (SE)</span>
                            <span>Likelihood Function</span>
                            <span>Log-likelihood Function</span>
                            <span>Maximum Likelihood Estimation(MLE)</span>
                            <span>Binomial Distribution</span>
                            <span>Sample Proportion</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(H_0\) vs \(H_1\)</div>
                        <h3><a href="hypothesis_testing.html">Part 10: Statistical Inference & Hypothesis Testing</a></h3>
                        <div class="keywords">
                            <span>Null Hypothesis</span>
                            <span>Alternative Hypothesis</span>
                            <span>Type I Error (False Negative)</span>
                            <span>Type II Error (False Positive)</span>
                            <span>Significance Level</span>
                            <span>Test Statistic</span>
                            <span>Null Hypothesis Significance Test(NHST)</span>
                            <span>One Sample t-Tests</span>
                            <span>Confidence intervals</span>
                            <span>Critical Values</span>
                            <span>z-scores</span>
                            <span>Credible Intervals</span>
                            <span>Bootstrap</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">LS</div>
                        <h3><a href="linear_regression.html">Part 11: Linear Regression</a></h3>
                        <div class="keywords">
                            <span><strong>Interactive Demo</strong></span>
                            <span>Linear Regression</span>
                            <span>Least-Squares Estimation</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\mathbb{H}\)</div>
                        <h3><a href="entropy.html">Part 12: Entropy</a></h3>
                        <div class="keywords">
                            <span>Information Content</span>
                            <span>Entropy</span>
                            <span>Joint Entropy</span>
                            <span>Conditional Entropy</span>
                            <span>Cross Entropy</span>
                            <span>KL Divergence(Relative Entropy, Information Gain)</span>
                            <span>Gibbs' Inequality</span>
                            <span>Log Sum Inequality</span>
                            <span>Jensen's Inequality</span>
                            <span>Mutual Information (MI)</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(n \to \infty\)</div>
                        <h3><a href="convergence.html">Part 13: Convergence</a></h3>
                        <div class="keywords">
                            <span>Convergence in Probability</span>
                            <span>Convergence in Distribution</span>
                            <span>Asymptotic(limiting) Distribution</span>
                            <span>Moment Generating Function(m.g.f.)</span>
                            <span>Central Limit Theorem(CLT)</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(p(\theta | \mathcal{D})\)</div>
                        <h3><a href="bayesian.html">Part 14: Intro to Bayesian Statistics</a></h3>
                        <div class="keywords">
                            <span>Bayesian Inference</span>
                            <span>Prior Distribution</span>
                            <span>Posterior Distribution</span>
                            <span>Marginal Likelihood</span>
                            <span>Conjugate Prior</span>
                            <span>Posterior Predictive Distribution</span>
                            <span>Beta-Binomial Model</span>
                            <span>Normal Distribution Model with known Variance \(\sigma^2\)</span>
                            <span>Normal Distribution Model with known Mean \(\mu\)</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\eta\)</div>
                        <h3><a href="expfamily.html">Part 15: The Exponential Family</a></h3>
                        <div class="keywords">
                            <span>Exponential Family</span>
                            <span>Natural Parameters(Canonical Parameters)</span>
                            <span>Base Measure</span>
                            <span>Sufficient Statistics</span>
                            <span>Partition Function</span>
                            <span>Minimal Representation</span>
                            <span>Natural Exponential Family(NEF)</span>
                            <span>Moment Parameters</span>
                            <span>Precision Matrix</span>
                            <span>Information Form</span>
                            <span>Moment Matching</span>
                            <span>Cumulants</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(F(\theta)\)</div>
                        <h3><a href="fisher_info.html">Part 16: Fisher Information Matrix</a></h3>
                        <div class="keywords">
                            <span>Fisher Information Matrix(FIM)</span>
                            <span>Score Function</span>
                            <span>Covariance</span>
                            <span>Negative Log Likelihood</span>
                            <span>Log Partition Function</span>
                            <span>Approximated KL Divergence</span>
                            <span>Natural Gradient</span>
                            <span>Jeffreys Prior</span>
                            <span>Uninformative Prior</span>
                            <span>Reference Prior</span>
                            <span>Mutual Information</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\pi\)</div>
                        <h3><a href="decision_theory.html"> Part 17: Bayesian Decision Theory</a></h3>
                        <div class="keywords">
                            <span>Decision Theory</span>
                            <span>Optimal Policy(Bayes estimator)</span>
                            <span>Zero-One Loss</span>
                            <span>Maximum A Posteriori (MAP) Estimate</span>
                            <span>Reject Option</span>
                            <span>Confusion Matrix</span>
                            <span>False Positive (FP, Type I error)</span>
                            <span>False Negative (FN, Type II error)</span>
                            <span>Receiver Operating Characteristic (ROC) Curve</span>
                            <span>Equal Error Rate (EER)</span>
                            <span>Precision-Recall (PR) Curve</span>
                            <span>Interpolated Precision</span>
                            <span>Average Precision (AP)</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\prod\)</div>
                        <h3><a href="markov.html">Part 18: Markov Chains</a></h3>
                        <div class="keywords">
                            <span><strong>Code Included</strong></span>
                            <span>Probabilistic Graphical Models(PGMs)</span>
                            <span>Bayesian Networks</span>
                            <span>Markov Chains</span>
                            <span>Language Modeling</span>
                            <span>n-gram</span>
                            <span>Transition Function(Kernel)</span>
                            <span>Stochastic Matrix(Transition Matrix)</span>
                            <span>Maximum likelihood estimation(MLE) in Markov models</span>
                            <span>Sparse Data Problem</span>
                            <span>Add-One Smoothing</span>
                            <span>Dirichlet Prior</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(p^*(\theta)\)</div>
                        <h3><a href="monte_carlo.html">Part 19: Monte Carlo Methods</a></h3>
                        <div class="keywords">
                            <span><strong>Interactive Demo</strong></span>
                            <span>Credible Intervals</span>
                            <span>Central Credible Intervals</span>
                            <span>Monte Carlo Approximation</span>
                            <span>Highest Posterior Density (HPD)</span>
                            <span>Markov Chain Monte Carlo (MCMC)</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\varphi\)</div>
                        <h3><a href="importance_sampling.html">Part 20: Importance Sampling</a></h3>
                        <div class="keywords">
                            <span>Importance Sampling</span>
                            <span>Importance Weights</span>
                            <span>Direct Importance Sampling</span>
                            <span>Effective Sample Size (ESS)</span>
                            <span>Self-Normalized Importance Sampling (SNIS)</span>
                            <span>Annealed Importance Sampling (AIS)</span>
                            <span>Annealing Schedule</span>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-icon">\(\mathcal{K}\)</div>
                        <h3><a href="gaussian_process.html">Part 21: Gaussian Processes</a></h3>
                        <div class="keywords">
                            <span>Nonparametric Models</span>
                            <span>Gaussian Process (GP)</span>
                            <span>Mercer Kernel</span>
                            <span>radial basis function (RBF) Kernel</span>
                            <span>Stationary Kernel</span>
                            <span>Automatic Relevance Determination (ARD) Kernel</span>
                            <span>Mat√©rn Kernel</span>
                            <span>Periodic Kernel</span>
                            <span>GP Regression</span>
                        </div>
                    </div>
                    
                </div>
            </section>

        </div>
        <script src="/js/main.js"></script>
        <script src="/js/search.js"></script>
    </body>
</html>
    
    <footer>
    <div class="footer-content">
        <div class="footer-about">
            <h3>About MATH-CS COMPASS</h3>
            <p>Bridging the gap between pure mathematics and computer science applications.</p>
            <div class="contact-section">
                <strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSf3_RNkegREvfCEIQznn6SCaf-iB5c-Doxn7Ymuu78Uf-PBjg/viewform" target="_blank">
                    Submit Your Questions & Feedback <i class="fas fa-external-link-alt"></i>
                </a></strong>
            </div>
        </div>
        <div class="footer-links">
            <h3>Quick Links</h3>
            <ul>
                
                <li><a href="../../index.html">Home</a></li>
                <li>
                <a href="../Linear_algebra/linear_algebra.html">
                    <span class="nav-number">I</span>
                    <span>Linear Algebra to Algebraic Foundations</span>
                </a>
                </li>
                <li>
                <a href="../Calculus/calculus.html">
                    <span class="nav-number">II</span>
                    <span>Calculus to Optimization & Analysis</span>
                </a>
                </li>
                <li>
                <a href="../Probability/probability.html">
                    <span class="nav-number">III</span>
                    <span>Probability & Statistics</span>
                </a>
                </li>
                <li>
                <a href="../Discrete/discrete_math.html">
                    <span class="nav-number">IV</span>
                    <span>Discrete Mathematics & Algorithms</span>
                </a>
                </li>
                <li>
                <a href="../Machine_learning/ml.html">
                    <span class="nav-number">V</span>
                    <span>Machine Learning</span>
                </a>
                </li>
            </ul>
        </div>
        <div class="footer-social">
            <h3>Connect With Me</h3>
            <p>
                <a href="https://x.com/MathCSCompass?t=Zi8nyfzszeFw8QizbJwnNg&s=09" target="_blank">
                    <i class="fab fa-x-twitter"></i> X (Twitter)
                </a>
            </p>
            <p>
                <a href="https://www.facebook.com/share/15uPaBWgQN/" target="_blank">
                    <i class="fab fa-facebook"></i> Facebook
                </a>
            </p>
      
            <h3>MATH-CS COMPASS App</h3>
            <div class="app-download-footer">
                <a href="https://play.google.com/store/apps/details?id=io.github.yusukey01.twa" target="_blank" rel="noopener">
                    <img src="../../images/google-play-badge.png" 
                        alt="Get it on Google Play" 
                        class="google-play-badge">
                </a>
            </div>
            
        </div>

    </div>
    <div class="footer-bottom">
        <p>&copy; 2024-2025 MATH-CS COMPASS. All rights reserved.</p>
    </div>
</footer>
    <script src="../../js/main.js?v=1.0.2"></script>
    <script src="../../js/search.js?v=1.0.2"></script>
    

    <button id="go-to-top-btn" class="go-to-top-btn" title="Go to top">
        <i class="fas fa-arrow-up"></i>
    </button>
    <script>
        // Register the service worker
        if ('serviceWorker' in navigator) {
          window.addEventListener('load', () => {
            navigator.serviceWorker.register('/js/service-worker.js')
              .then(registration => {
                console.log('ServiceWorker registration successful with scope: ', registration.scope);
              })
              .catch(error => {
                console.log('ServiceWorker registration failed: ', error);
              });
          });
        }
      </script>
</body>
</html>