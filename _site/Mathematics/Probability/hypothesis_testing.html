<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    
    <title>Statistical Inference & Hypothesis Testing - MATH-CS COMPASS</title>
    
    
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
    </script>
    <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff" as="font" type="font/woff2" crossorigin>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff" as="font" type="font/woff2" crossorigin>
    
    
    

    <link rel="stylesheet" href="../../../css/styles.css?v=1.0.2">
  
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

    <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
    <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Learn about null hypothesis significance test, confidence interval, credible interval, and bootstrap method.">
    <meta name="google-site-verification" content="IieEujypYW38caEVe8ymjczouNl56yxAy27iPztcfRA" />
    

    <link rel="manifest" href="/manifest.json">

    <!-- Theme color for Chrome, Android, and other browsers -->
    <meta name="theme-color" content="#007bff">
  
    <!-- iOS specific tags -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="MATH-CS COMPASS">
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Icon references -->
    <link rel="icon" type="image/png" sizes="1280x1280" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="icon" type="image/png" sizes="512x512" href="/images//maskable_icon_x512.png?v=1.0.2">
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="apple-touch-icon" href="/images/maskable_icon_x512.png?v=1.0.2">

    <!-- For Windows -->
    <meta name="msapplication-TileImage" content="/images/test1.png?v=1.0.2">
    <meta name="msapplication-TileColor" content="#007bff">

    <!-- Schema.org Structured Data for AI Optimization -->
    

    <!-- Article Schema for content pages -->
    
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Statistical Inference & Hypothesis Testing",
      "description": "Learn about null hypothesis significance test, confidence interval, credible interval, and bootstrap method.",
      "datePublished": "2024-01-01",
      "dateModified": "2025-01-01",
      "author": {
        "@type": "Person",
        "name": "Yusuke Yokota",
        "jobTitle": "Mathematics & Computer Science Educator",
        "knowsAbout": [
          "Linear Algebra",
          "Machine Learning",
          "Computer Science",
          "Mathematics"
        ]
      },
      "publisher": {
        "@type": "Organization",
        "name": "MATH-CS COMPASS",
        "url": "https://math-cs-compass.com",
        "logo": {
          "@type": "ImageObject",
          "url": "https://math-cs-compass.com/images/maskable_icon_x512.png"
        }
      },
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://math-cs-compass.com/Mathematics/Probability/hypothesis_testing.html"
      },
      "about": [
        
        { "@type": "Thing", "name": "Probability" },
        { "@type": "Thing", "name": "Statistics" }
        
      ],
      "educationalLevel": "university",
      "learningResourceType": "tutorial",
      "educationalUse": "instruction"
    }
    </script>
    
</head>

<body>
    <header>
    <nav class="navbar">
        <!-- Logo as Home Button -->
        <div class="logo-home">
            <a href="../../../index.html" 
               class="logo-link " 
               title="Home - Math-CS Compass">
                <img src="../../images/icon_x512.png" 
                     alt="Math-CS Compass Logo" 
                     class="nav-logo">
            </a>
        </div>

        <div class="search-container">
            <input type="text" id="search-input" placeholder="Search keywords...">
            <button id="search-button" aria-label="Search" title="Search website"><i class="fas fa-search"></i></button>
        </div>
        
        <div class="menu-toggle">
            <i class="fas fa-bars"></i>
        </div>
        
        <ul class="nav-links">
            <li><a href="../Linear_algebra/linear_algebra.html" >I - Linear Algebra to Algebraic Foundations</a></li>
            
            <li><a href="../Calculus/calculus.html" >II - Calculus to Optimization & Analysis</a></li>
            
            <li><a href="../Probability/probability.html" class="active">III - Probability & Statistics</a></li>
            
            <li><a href="../Discrete/discrete_math.html" >IV - Discrete Mathematics & Algorithms</a></li>
            
            <li><a href="../Machine_learning/ml.html" >V - Machine Learning</a></li>
        </ul>
    </nav>
</header>
    
    <!DOCTYPE html>
<html>
    <body>
        <!-- Meta script for hypothesis_testing.html -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "Statistical Inference & Hypothesis Testing",
        "description": "Learn about null hypothesis significance test, confidence interval, credible interval, and bootstrap method.",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "active",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://math-cs-compass.com"
        },
        "about": [
            { "@type": "Thing", "name": "Statistical Inference" },
            { "@type": "Thing", "name": "Hypothesis Testing" },
            { "@type": "Thing", "name": "Null Hypothesis Significance Test" },
            { "@type": "Thing", "name": "NHST" },
            { "@type": "Thing", "name": "Null Hypothesis" },
            { "@type": "Thing", "name": "Alternative Hypothesis" },
            { "@type": "Thing", "name": "Type I Error" },
            { "@type": "Thing", "name": "Type II Error" },
            { "@type": "Thing", "name": "p-value" },
            { "@type": "Thing", "name": "Significance Level" },
            { "@type": "Thing", "name": "Test Statistic" },
            { "@type": "Thing", "name": "t-Test" },
            { "@type": "Thing", "name": "One-Sample t-Test" },
            { "@type": "Thing", "name": "Confidence Interval" },
            { "@type": "Thing", "name": "Credible Interval" },
            { "@type": "Thing", "name": "Bootstrap Method" },
            { "@type": "Thing", "name": "Frequentist Statistics" },
            { "@type": "Thing", "name": "Bayesian Statistics" },
            { "@type": "Thing", "name": "Critical Value" },
            { "@type": "Thing", "name": "Sampling Distribution" },
            { "@type": "Thing", "name": "Resampling" }
        ],
        "teaches": [
            "Hypothesis testing methodology",
            "Statistical inference principles", 
            "Confidence vs credible intervals",
            "Bootstrap resampling techniques"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Probability & Statistics",
            "description": "Explore fundamental concepts of probability and statistics essential for machine learning",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://math-cs-compass.com"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "III",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT2H30M",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>
        <div class="hero-section">
            <h1 class="webpage-name">Statistical Inference & Hypothesis Testing
            </h1>
        </div>

        
  <div class="quick-jump-container">
    <button type="button" id="quick-jump-toggle" class="quick-jump-toggle">
      <i class="fas fa-list"></i> <strong>Section III Navigation</strong>
    </button>
    <div id="quick-jump-menu" class="quick-jump-menu">
      <h3>Probability & Statistics</h3>
      <div class="quick-jump-links">

         
        <a href="probability.html">← Back to Section III Overview</a>
        <hr style="margin: 8px 0; border: 1px solid #ddd;">
        
        
        <a href="basic.html" >Part 1: Basic Probability Ideas</a>
        <a href="random_variables.html" >Part 2: Random Variables</a>
        <a href="gamma.html" >Part 3: Gamma & Beta Distribution</a>
        <a href="gaussian.html" >Part 4: Normal (Gaussian) Distribution</a>
        <a href="student.html" >Part 5: Student's t-Distribution</a>
        <a href="covariance.html" >Part 6: Covariance</a>
        <a href="correlation.html" >Part 7: Correlation</a>
        <a href="mvn.html" >Part 8: Multivariate Distributions</a>
        <a href="mle.html" >Part 9: Maximum Likelihood Estimation</a>
        <a href="hypothesis_testing.html" class="current-page">Part 10: Statistical Inference & Hypothesis Testing</a>
        <a href="linear_regression.html" >Part 11: Linear Regression</a>
        <a href="entropy.html" >Part 12: Entropy</a>
        <a href="convergence.html" >Part 13: Convergence</a>
        <a href="bayesian.html" >Part 14: Intro to Bayesian Statistics</a>
        <a href="expfamily.html" >Part 15: The Exponential Family</a>
        <a href="fisher_info.html" >Part 16: Fisher Information Matrix</a>
        <a href="decision_theory.html" >Part 17: Bayesian Decision Theory</a>
        <a href="markov.html" >Part 18: Markov Chains</a>
        <a href="monte_carlo.html" >Part 19: Monte Carlo Methods</a>
        <a href="importance_sampling.html" >Part 20: Importance Sampling</a>
        <a href="gaussian_process.html" >Part 21: Gaussian Processes</a>
      </div>
    </div>
</div>


        <div class="topic-nav">
            <a href="#NHST">Null Hypothesis Significance Test</a>
            <a href="#test">Example: t-Tests</a>
            <a href="#CI">Confidence Intervals vs Credible Intervals</a>
            <a href="#BS">Bootstrap</a>
        </div> 

        <div class="container">  
           
            <section id="NHST" class="section-content">
            <h2>Null Hypothesis Significance Test</h2>
            <p>
            Once we have a statistical model (or <strong>hypothesis</strong>), we need to assess whether it's plausible given our data \(\mathcal{D}\). 
            In this section, we introduce <strong>frequentist statistical inference</strong> and <strong>hypothesis testing</strong>. Although 
            <a href="bayesian.html"><strong>Bayesian inference</strong></a> can replace many frequentist techniques and is especially popular in 
            modern machine learning, frequentist methods remain valuable tools — they're often simpler to compute, more standardized, and provide 
            complementary insights.
            <br><br>
            Here, we discuss the <strong>null hypothesis significance test(NHST)</strong>.
            <br>
            Suppose we have two competing hypotheses:
            <ul style="padding-left: 40px;">
                <li><strong>Null Hypothesis</strong> \(H_0\): This is the default assumption.</li>

                <li><strong>Alternative Hypothesis</strong> \(H_1\): This represents the claim we wish to support.</li>
            </ul>
            (So, hypothesis testing is a kind of <strong>binary classification</strong> problem.)
            <br><br>
            Our goal is to decide which hypothesis is more plausible. Usually, our reasoning is that if \(H_0\) is very unlikely, 
            then we conclude that \(H_1\) would be true (i.e., we <strong>reject the null hypothesis</strong>). 
            <br><br>
            Rejecting \(H_0\) does NOT mean \(H_1\) is absolutely true. Conversely, failing to reject \(H_0\) only means 
            that the evidence is insufficient to support \(H_1\). Thus, our conclusion can be wrong: 
            <br>
            <ul style="padding-left: 40px;">
                <li><strong>Type I error</strong>(or <strong>false negative</strong>) : Accidentally rejecting the null \(H_0\) when it is true.</li>
                <li><strong>Type II error</strong>(or <strong>false positive</strong>): Accidentally accepting \(H_0\) when the alternative \(H_1\) is true.</li>
            </ul>
            <br>
            The type I error rate \(\alpha\) is called <strong>significance</strong> of the test. It represents the probability of mistakenly rejecting 
            \(H_0\) when it is true (typically, set 0.05 to 0.01 in practice.)
            <br><br>
            To decide whether to reject \(H_0\), we define a function of the data \(\mathcal{D}\) that summarizes the evidence 
            against \(H_0\). This is called the <strong>test statistic</strong>, denoted as \(test(\mathcal{D})\).
            To evaluate the significance of our observed test statistic, we compare it to what we would expect under the null 
            hypothesis. That is, we sample the hypothetical dataset \(\tilde{\mathcal{D}}\) assuming \(H_0\) is true and compute 
            their test statistics, \(test(\tilde{\mathcal{D}})\). 
            <br><br>
            The <strong>p-value</strong> is defined as the probability, under \(H_0\), 
            of obtaining a test statistic at least as extreme as the one we observed:
            \[
            p = P(test(\tilde{\mathcal{D}}) \geq test(\mathcal{D}) | \tilde{\mathcal{D}} \sim H_0).
            \]
            A "small" p-value (typically, \(< \alpha\)) indicates that the observed result is unlikely under \(H_0\), 
            leading us to reject the null hypothesis in favor of \(H_1\). Traditionally we reject the null hypothesis 
            if the p-value is less than \(\alpha = 0.05\), which is called the <strong>significance level </strong> of the 
            test. Note that a p-value of 0.05 does NOT mean that the alternative hypothesis \(H_1\) is true with probability
            0.95. Indeed, even many scientists misinterpret p-values.
            <br><br>
            NHST provides a systematic way to evaluate claims, but it has limitations:
            <ul style="padding-left: 40px;">
                <li>Statistical significance does not imply practical significance. Even if \(H_0\) is rejected, the actual effect size may be too small to be meaningful.</li>
                <li>p-values depend on sample size. With very large datasets, even tiny, practically irrelevant differences may yield small p-values.</li>
                <li>Frequentist methods rely on fixed significance thresholds. Bayesian approaches offer an alternative framework by directly computing the probability of hypotheses given the data.</li>
            </ul>
            </p>
            </section>

            <section id="test" class="section-content">
            <h2>t-Tests</h2>
            <p>
                <span class="proof-title">Example:</span>
                Suppose we are analyzing the test scores of students in a school. Historically, the average test score is 70. A researcher 
                believes that a new teaching method has improved scores. To test this, we collect a sample of 30 students' scores after 
                using the new method.
                <ul style="padding-left: 40px;">
                    <li>\(H_0\): The new method has no effect, meaning the true mean is still 70.</li>
                    <li>\(H_1\): The new method increases the average score, meaning the mean is greater than 70.</li>
                </ul>
                <br>
                We collected a sample of (\(n = 30\)) students with the following observed statistics:
                <ul style="padding-left: 40px;">
                    <li> Sample mean: \(\bar{x} = 75.20\). </li>
                    <li> Sample standard deviation \(s = 9.00\)</li>
                </ul>
                where 
                \[
                s = \sqrt{\frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2}.
                \]
                Since the population standard deviation \(\sigma\) is unknown, we use <strong>one-sample t-test</strong>.
                The test statistic is computed by: 
                \[
                t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} = \frac{75.20 - 70}{9.00 / \sqrt{30}} \approx 3.16.
                \]
                The p-value is the probability of observing a test statistic as extreme as (or more extreme than) the calculated 
                t-value under the null hypothesis. This follows a <a href="student.html"><strong>Student's t-distribution</strong></a> 
                with \(n -1 = 29 \) degrees of freedom.
                <br>
                Then we have \(p \approx 0.0021\) via some numerical computation. Set the significance level \(\alpha = 0.05\). 
                Since \(p < 0.05\), we reject \(H_0\). Therefore, there is strong statistical evidence that the new teaching method 
                increases students' test scores.
                <br>
                We can only say that the data we observed(test scores) are very unlikely under the assumption that the true mean is still 70. 
                <br>
                It does <strong>NOT</strong> mean that..
                <ul style="padding-left: 40px;">
                    <li>the new teaching method definitely increases test scores.</li>
                    <li>the probability that \(H_0\) is true is 0.0021.</li>
                    <li>the effect is practically significant.</li>
                </ul>       
            </p>
            </section>

            <section id="CI" class="section-content">
            <h2>Confidence Intervals vs Credible Intervals</h2>
            <p>
            In frequentist statistics, we use the variability induced by the sampling distribution as a way to estimate uncertainty 
            of a parameter estimate. we define \(100(1 - \alpha)%\) <strong>confidence interval(CI)</strong>. It is common to set the 
            significance level \(\alpha = 0.05\), which yields a 95% CI. If we repeatedly sampled data, and construct a 95% CI for each data, 
            then about 95% of such intervals will contain the true parameter \(\theta\).
            <br>
            95% CI does <strong>NOT</strong> mean that the true parameter lies in the interval with probability 0.95 
            because, in frequentist statistics, \(\theta\) is treated as a <strong>fixed constant</strong>. 
            <br>
            On the other hand, in <a href="bayesian.html"><strong>Bayesian statistics</strong></a>, we treat the data as fixed (since it is known) and the parameter as random (since
            it is unknown). Indeed, the explanation; "the true parameter lies in the interval with probability 0.95." is valid in Bayesian 
            statistics. Such a interval is called the <strong>credible interval</strong>. 
            <div class="proof">
                <span class="proof-title">Example:</span>
                Suppose we toss a coin \(n = 100\) times and observe 60 heads. Now we want to estimate the probability of getting heads.
                <br><br>
                First, we try the frequentist approach. The point estimate for the probability of heads is \(\hat{p} = \frac{60}{100} = 0.6\), and 
                the standard error(SE) for a proportion is given by:
                \[
                \begin{align*}
                \text{SE} &= \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} \\\\
                          &= \sqrt{\frac{0.6 \times 0.4}{100}} \\\\\
                          &\approx 0.049.
                \end{align*}
                \]
                For a 95% CI using normal approximation, the <strong>critical value</strong> is \(z_{0.025} \approx 1.96\). Then CI is given by 
                \[
                \begin{align*}
                \text{CI} &= [\hat{p}-z_{0.025} \times \text{SE}, \quad \hat{p}+z_{0.025}\times \text{SE}] \\\\
                          &\approx [0.504, 0.696].
                \end{align*}
                \]
                If we repeated the experiment (tossing the coin 100 times) many times and computed a 95% CI each time, about 95% of those 
                intervals would contain the true \(p\).
                <div style="text-align: center;">
                    <img src="Images/zscore.webp" alt="z-score"  class="responsive-image">
                </div>
                Note: A <strong>z-score</strong> is any value that has been standardized to represent the number of standard deviations 
                away from the mean. The <strong>critical value</strong> is a specific z-score used as a threshold in hypothesis testing or 
                confidence interval calculations. In our case, \(z_{0.025} \approx 1.96\) is the critical value that separates the central 
                95% of the distribution from the outer 5% (2.5% in each tail).
                <br><br>
                In Bayesian approach, we assume a uniform prior for the probability \(p\) which is equivalent to 
                a <a href="gamma.html"><strong>Beta distribution</strong></a>: 
                \[
                p \sim \text{Beta}(1, 1).
                \]
                With 60 heads and 40 tails, the likelihood is given by a binomial distribution. In the Bayesian framework, the 
                <strong>posterior</strong> distribution is:
                \[
                p \sim \text{Beta}(1+60, 1+40) = \text{Beta}(61, 41).
                \]
                (Note:The Beta distribution is a <a href="bayesian.html"><strong>conjugate prior</strong></a> for the binomial likelihood. 
                This means that when the likelihood is binomial, which is the case for coin tosses, using a Beta prior results in a 
                posterior distribution that is also a Beta distribution.)
                <br>
                A 95% credible interval (CrI) is typically obtained by finding the 2.5th and 97.5th percentiles of the posterior 
                distribution. These percentiles can be computed using the inverse cumulative distribution function (CDF) for the 
                Beta distribution. For example, 
                \[
                \begin{align*}
                \text{CrI} &= [\text{invBeta}(0.025, 61, 41), \quad \text{invBeta}(0.975, 61, 41)] 
                           &\approx [0.52, 0.68].
                \end{align*}
                \]
                Given the observed data and the chosen prior, there is a 95% probability that \(p\) falls between 0.52 and 0.68. 
                This interval directly reflects our uncertainty about \(p\) after seeing the data.
            </div>
            You find the Bayesian credible interval "more intuitive" because it directly answers the question, “What is the probability 
            that the parameter falls within this interval given the data and our prior beliefs?” On the other hand, Frequentist methods 
            provide guarantees on long-run performance without the need for a prior, which can be an advantage in settings where subjective 
            beliefs are hard to justify.
            </p>
            </section>

            <section id="BS" class="section-content">
            <h2>Bootstrap</h2>
            <p>
            In situations where the estimator is a complex function of the data (for example, when it is not a simple maximum 
            likelihood estimator), or when the sample size is too small to reliably approximate its sampling distribution 
            analytically, we can use the <strong>bootstrap</strong> method. 
            <br>
            This technique involves resampling the observed data with replacement to generate many "bootstrap samples," which are 
            then used to empirically estimate the sampling distribution of the estimator. This approach is especially useful when 
            traditional assumptions (e.g., normality) may not hold, providing a flexible, non-parametric way to assess uncertainty 
            and construct confidence intervals. 
            <div class="proof">
                <span class="proof-title">Example:</span>
                we have a small dataset of 10 people's heights (in cm):
                \[
                x = [160,165,170,175,180,185,190,195,200,205].
                \]
                The sample mean is \(\hat{\mu} = 182.5\). Since our sample size is small, we might not be able to assume the sampling 
                distribution of the mean is normal. Instead of relying on theoretical approximations, we use bootstrap resampling to 
                approximate it empirically.
                <br>
                Here, we randomly draw 10 values from the original sample with replacement. Some values may be repeated, and others may be 
                missing in a given resample. For example, we might obtain:
                \[
                \begin{align*}
                &x_1 = [165,175,175,190,185,160,200,195,180,185], \\\\
                &\hat{\mu} = 181.0.
                \end{align*}
                \]
                Then we repeat this process many times (e.g., 10,000 times). Each time, we create a new resampled dataset, compute its mean, 
                and store it. Once we have 10,000 bootstrap sample means, we can use them to estimate the confidence interval: 
                <div style="text-align: center;">
                    <img src="Images/bootstrap.webp" alt="bootstrap"  class="responsive-image">
                </div>
            </div>
            </p>
            </section>
        </div>  
        <script src="/js/main.js"></script>
    </body>
</html>
    
    <footer>
    <div class="footer-content">
        <div class="footer-about">
            <h3>About MATH-CS COMPASS</h3>
            <p>Bridging the gap between pure mathematics and computer science applications.</p>
            <div class="contact-section">
                <strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSf3_RNkegREvfCEIQznn6SCaf-iB5c-Doxn7Ymuu78Uf-PBjg/viewform" target="_blank">
                    Submit Your Questions & Feedback <i class="fas fa-external-link-alt"></i>
                </a></strong>
            </div>
        </div>
        <div class="footer-links">
            <h3>Quick Links</h3>
            <ul>
                
                <li><a href="../../../index.html">Home</a></li>
                <li>
                <a href="../Linear_algebra/linear_algebra.html">
                    <span class="nav-number">I</span>
                    <span>Linear Algebra to Algebraic Foundations</span>
                </a>
                </li>
                <li>
                <a href="../Calculus/calculus.html">
                    <span class="nav-number">II</span>
                    <span>Calculus to Optimization & Analysis</span>
                </a>
                </li>
                <li>
                <a href="../Probability/probability.html">
                    <span class="nav-number">III</span>
                    <span>Probability & Statistics</span>
                </a>
                </li>
                <li>
                <a href="../Discrete/discrete_math.html">
                    <span class="nav-number">IV</span>
                    <span>Discrete Mathematics & Algorithms</span>
                </a>
                </li>
                <li>
                <a href="../Machine_learning/ml.html">
                    <span class="nav-number">V</span>
                    <span>Machine Learning</span>
                </a>
                </li>
            </ul>
        </div>
        <div class="footer-social">
            <h3>Connect With Me</h3>
            <p>
                <a href="https://x.com/MathCSCompass?t=Zi8nyfzszeFw8QizbJwnNg&s=09" target="_blank">
                    <i class="fab fa-x-twitter"></i> X (Twitter)
                </a>
            </p>
            <p>
                <a href="https://www.facebook.com/share/15uPaBWgQN/" target="_blank">
                    <i class="fab fa-facebook"></i> Facebook
                </a>
            </p>
      
            <h3>MATH-CS COMPASS App</h3>
            <div class="app-download-footer">
                <a href="https://play.google.com/store/apps/details?id=io.github.yusukey01.twa" target="_blank" rel="noopener">
                    <img src="../../../images/google-play-badge.png" 
                        alt="Get it on Google Play" 
                        class="google-play-badge">
                </a>
            </div>
            
        </div>

    </div>
    <div class="footer-bottom">
        <p>&copy; 2024-2025 MATH-CS COMPASS. All rights reserved.</p>
    </div>
</footer>
    <script src="../../../js/main.js?v=1.0.2"></script>
    <script src="../../../js/search.js?v=1.0.2"></script>
    

    <button id="go-to-top-btn" class="go-to-top-btn" title="Go to top">
        <i class="fas fa-arrow-up"></i>
    </button>
    <script>
        // Register the service worker
        if ('serviceWorker' in navigator) {
          window.addEventListener('load', () => {
            navigator.serviceWorker.register('/js/service-worker.js')
              .then(registration => {
                console.log('ServiceWorker registration successful with scope: ', registration.scope);
              })
              .catch(error => {
                console.log('ServiceWorker registration failed: ', error);
              });
          });
        }
      </script>
</body>
</html>