<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    
    <title>Matrix Algebra - MATH-CS COMPASS</title>
    
    
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
    </script>
    <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff" as="font" type="font/woff2" crossorigin>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff" as="font" type="font/woff2" crossorigin>
    
    
    

    <link rel="stylesheet" href="../../../css/styles.css?v=1.0.2">
  
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

    <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
    <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Learn about diagonal matrix, transpose & inverse of matrices, partitions, and LU factorization.">
    <meta name="google-site-verification" content="IieEujypYW38caEVe8ymjczouNl56yxAy27iPztcfRA" />
    

    <link rel="manifest" href="/manifest.json">

    <!-- Theme color for Chrome, Android, and other browsers -->
    <meta name="theme-color" content="#007bff">
  
    <!-- iOS specific tags -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="MATH-CS COMPASS">
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Icon references -->
    <link rel="icon" type="image/png" sizes="1280x1280" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="icon" type="image/png" sizes="512x512" href="/images//maskable_icon_x512.png?v=1.0.2">
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="apple-touch-icon" href="/images/maskable_icon_x512.png?v=1.0.2">

    <!-- For Windows -->
    <meta name="msapplication-TileImage" content="/images/test1.png?v=1.0.2">
    <meta name="msapplication-TileColor" content="#007bff">

    <!-- Schema.org Structured Data for AI Optimization -->
    

    <!-- Article Schema for content pages -->
    
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Matrix Algebra",
      "description": "Learn about diagonal matrix, transpose & inverse of matrices, partitions, and LU factorization.",
      "datePublished": "2024-01-01",
      "dateModified": "2025-01-01",
      "author": {
        "@type": "Person",
        "name": "Yusuke Yokota",
        "jobTitle": "Mathematics & Computer Science Educator",
        "knowsAbout": [
          "Linear Algebra",
          "Machine Learning",
          "Computer Science",
          "Mathematics"
        ]
      },
      "publisher": {
        "@type": "Organization",
        "name": "MATH-CS COMPASS",
        "url": "https://yusukey01.github.io",
        "logo": {
          "@type": "ImageObject",
          "url": "https://yusukey01.github.io/images/maskable_icon_x512.png"
        }
      },
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://yusukey01.github.io/Mathematics/Linear_algebra/matrix_algebra.html"
      },
      "about": [
        
        { "@type": "Thing", "name": "Linear Algebra" }
        
      ],
      "educationalLevel": "university",
      "learningResourceType": "tutorial",
      "educationalUse": "instruction"
    }
    </script>
    
</head>

<body>
    <header>
    <nav class="navbar">
        <!-- Logo as Home Button -->
        <div class="logo-home">
            <a href="../../../index.html" 
               class="logo-link " 
               title="Home - Math-CS Compass">
                <img src="../../images/icon_x512.png" 
                     alt="Math-CS Compass Logo" 
                     class="nav-logo">
            </a>
        </div>

        <div class="search-container">
            <input type="text" id="search-input" placeholder="Search keywords...">
            <button id="search-button" aria-label="Search" title="Search website"><i class="fas fa-search"></i></button>
        </div>
        
        <div class="menu-toggle">
            <i class="fas fa-bars"></i>
        </div>
        
        <ul class="nav-links">
            <li><a href="../Linear_algebra/linear_algebra.html" class="active">I - Linear Algebra to Algebraic Foundations</a></li>
            
            <li><a href="../Calculus/calculus.html" >II - Calculus to Optimization & Analysis</a></li>
            
            <li><a href="../Probability/probability.html" >III - Probability & Statistics</a></li>
            
            <li><a href="../Discrete/discrete_math.html" >IV - Discrete Mathematics & Algorithms</a></li>
            
            <li><a href="../Machine_learning/ml.html" >V - Machine Learning</a></li>
        </ul>
    </nav>
</header>
    
    <!DOCTYPE html>
<html>
    <body>
        <!-- LearningResource Schema for Content Pages -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "Matrix Algebra",
        "description": "Learn about diagonal matrix, transpose & inverse of matrices, partitions, and LU factorization.",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "active",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
        },
        "about": [
            
            { "@type": "Thing", "name": "Matrix Algebra" },
            { "@type": "Thing", "name": "Diagonal Matrix" },
            { "@type": "Thing", "name": "Matrix Transpose" },
            { "@type": "Thing", "name": "Matrix Inverse" },
            { "@type": "Thing", "name": "Elementary Matrices" },
            { "@type": "Thing", "name": "Matrix Partitions" },
            { "@type": "Thing", "name": "LU Factorization" },
            { "@type": "Thing", "name": "Matrix Operations" }
            
        ],
        "teaches": [
            "Mathematical concepts",
            "Practical applications",
            "Problem-solving techniques"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Linear Algebra",
            "description": "Explore the foundations of Linear Algebra, covering key concepts such as linear equations, vector spaces, eigenvalues, orthogonality, least squares, and stochastic matrices",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "I",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT2H",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>
        <!-- WebApplication Schema for Interactive Demos -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "WebApplication",
        "name": "Matrix Algebra Interactive Demo",
        "description": "Interactive demonstration of matrix algebra concepts",
        "applicationCategory": "EducationalApplication",
        "operatingSystem": "Web Browser",
        "url": "https://yusukey01.github.io/Mathematics/Linear_algebra/matrix_algebra.html",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota"
        },
        "applicationSubCategory": "Mathematical Visualization",
        "featureList": [
            "Interactive mathematical visualization",
            "Real-time parameter adjustment",
            "Educational demonstrations"
        ],
        "isAccessibleForFree": true,
        "educationalUse": "instruction",
        "educationalLevel": "university"
        }
        </script>
        <div class="hero-section">
            <h1 class="webpage-name">Matrix Algebra
            </h1>
        </div>

        
  <div class="quick-jump-container">
    <button type="button" id="quick-jump-toggle" class="quick-jump-toggle">
      <i class="fas fa-list"></i> <strong>Section I Navigation</strong>
    </button>
    <div id="quick-jump-menu" class="quick-jump-menu">
      <h3>Linear Algebra to Algebraic Foundations</h3>
      <div class="quick-jump-links">

        
        <a href="linear_algebra.html">‚Üê Back to Section I Overview</a>
        <hr style="margin: 8px 0; border: 1px solid #ddd;">
        
        
        <a href="linear_equations.html" >Part 1: Linear Equations</a>
        <a href="linear_transformation.html" >Part 2: Linear Transformation</a>
        <a href="matrix_algebra.html" class="current-page">Part 3: Matrix Algebra</a>
        <a href="determinants.html" >Part 4: Determinants</a>
        <a href="vectorspaces.html" >Part 5: Vector Spaces</a>
        <a href="eigenvectors.html" >Part 6: Eigenvalues & Eigenvectors</a>
        <a href="orthogonality.html" >Part 7: Orthogonality</a>
        <a href="leastsquares.html" >Part 8: Least-Squares Problems</a>
        <a href="symmetry.html" >Part 9: Symmetry</a>
        <a href="trace.html" >Part 10: Trace and Norms</a>
        <a href="kronecker.html" >Part 11: Kronecker Product & Tensor</a>
        <a href="woodbury.html" >Part 12: Woodbury Matrix Identity</a>
        <a href="stochastic.html" >Part 13: Stochastic Matrix</a>
        <a href="graph_laplacian.html" >Part 14: Graph Laplacians and Spectral Methods</a>
      </div>
    </div>
</div>


        <div class="topic-nav">
            <a href="#diag">Diagonal Matrix</a>
            <a href="#trans">Transpose</a>
            <a href="#inv">Inverse of a Matrix</a>
            <a href="#element">Elementary Matrices</a>
            <a href="#part">Partitions</a>
            <a href="#lu">LU Factorization</a>
        </div> 

        <div class="container">  
           
            <section id="diag" class="section-content">
            <h2>Diagonal Matrix</h2>
            <p>
            A <strong>diagonal matrix</strong> is \(n \times n\) square matrix whose entries outside the <strong>main diagonal</strong> are all zero.
            \[
            \begin{align*}
            AB  &= \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix}
                   \begin{bmatrix} 2 & 0 & 0 \\ 0 & 3 & 0 \\ 0 & 0 & 4 \end{bmatrix} \\\\
                &= \begin{bmatrix} 2 & 6 & 12 \\  8 & 15 & 24 \\ 14 & 24 & 36 \end{bmatrix}
            \end{align*}
            \]
            \[
            \begin{align*}
            BA   &= \begin{bmatrix} 2 & 0 & 0 \\ 0 & 3 & 0 \\ 0 & 0 & 4 \end{bmatrix}
                   \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9  \end{bmatrix} \\\\
                 &= \begin{bmatrix} 2 & 4 & 6 \\ 12 & 15 & 18 \\ 28 & 32 & 36 \end{bmatrix}
            \end{align*}
            \]
            As you can see, multiplying on the right by the diagonal matrix \(B\) results in each "column" 
            of \(A\) being scaled by the corresponding diagonal entry of \(B\). Conversely, multiplying on 
            the left by \(B\) scales each "row" of \(A\).
            <br><br> 
            A diagonal matrix with 1's on the main diagonal is called an <strong>identity matrix</strong> denoted by \(I_n\). 
            Like the above example, \(AB \neq BA\) in general, but clearly \(AI = IA\) and the resulting matix is just the original matrix \(A\). 
            For instance, 
            \[
            \begin{align*}
            AI  &= \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix}
                   \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \\\\
                &= \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}
                   \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix} \\\\
                &= \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix}.
            \end{align*}
            \]
            </p>
            </section>

            <section id="trans" class="section-content">
            <h2>Transpose</h2>
            <p>
            The <strong>transpose</strong> of an \(m \times n\) matrix \(A\) is the \(n \times m\) matrix 
            interchanging its rows and corresponding columns, and is denoted by \(A^T\). 
            \[
            A = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix} \qquad
            A^T = \begin{bmatrix} 1 & 4 & 7 \\ 2 & 5 & 8 \\ 3 & 6 & 9 \end{bmatrix}
            \]
            Note that the transpose operation does not change the main diagonal entries. 
            There are many properties related to the transpose operation. Let me introduce some of them:
            <br>
            <ol style="padding-left: 40px;">
                <li>\((A^T)^T = A\)</li>
                <li>\((A+B)^T = A^T + B^T\)</li>
                <li>\((AB)^T  = B^TA^T\)</li>
            </ol>
            <br>
            For the third property, we can state the following:
            <div class="theorem">
                <span class="theorem-title">Theorem 1:</span>
                The transpose of the product of matrices is the product of their transposes in reverse order. 
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                Let \(n\) be the number of columns of \(A\) (which equals to the number of rows of \(B\)). Then, 
                \[
                ((AB)^T)_{ij} = (AB)_{ji} =\sum_{k=1}^n a_{jk}b_{ki}.
                \]
                Also, 
                \[
                (B^TA^T)_{ij} = \sum_{k=1}^n b_{ki}a_{jk} = \sum_{k=1}^n a_{jk}b_{ki}.
                \]  
                This property extends to the product of more than two matrices.
            </div>
            </p>
            </section>

            <section id="inv" class="section-content">
            <h2>Inverse of a Matrix</h2>
            <p>
            An \(n \times n\) matrix \(A\) is said to be <strong>invertible</strong> 
            if there exists an \(n \times n\) matrix \(B\) such that \[AB = BA = I.\]
            The matrix \(B\) is the inverse of \(A\) denoted by \(A^{-1}\). Also, a matrix that is NOT invertible is 
            called a <strong>singular matrix</strong>. 
            <br><br>
            By definition, we can say that \((A^{-1})^{-1} = A \, \) and also \((AB)^{-1} = B^{-1}A^{-1}\) because 
            \[
            \begin{align*}
            (AB)(B^{-1}A^{-1}) &= A(BB^{-1})A^{-1} \\\\
                               &= AIA^{-1} \\\\
                               &= AA^{-1} \\\\
                               &= I.
            \end{align*}
            \]
            <br>
            Using Theorem 1, we obtain the following result:
            <div class="theorem">
                <span class="theorem-title">Theorem 2:</span>
                If \(A\) is invertible, then so is \(A^T\) and \((A^T)^{-1} = (A^{-1})^T \).
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                Suppose a matrix \(A\) is an invertible matrix. By Theorem 1, 
                \[(A^{-1})^TA^T = (AA^{-1})^T = I^T = I\]
                and similarly, 
                \[A^T(A^{-1})^T = (A^{-1}A)^T = I^T = I.\]
                Thus, \(A^T\) is invertible and its inverse is \((A^{-1})^T\).
            </div>

            There is a simple formula for the inverse of a \(2 \times 2\) matrix.
            Let \(A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}\). 
            If the <strong>determinant</strong> of \(A\), \(\det (A) = ad - bc\) is nonzero, then \(A\) is
            invertible and 
            \[
            A^{-1} = \frac{1}{\det (A)} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}
            \]
            So, \(\det (A) = 0\) implies the matrix \(A\) is not invertible. 

            <br>For example, 
            \[
            \begin{align*}
            &\begin{bmatrix} 1 & 9 \\ 8 & 2 \end{bmatrix}
            \frac{1}{(2 - 72)}
            \begin{bmatrix} 2 & -9 \\ -8 & 1 \end{bmatrix} \\\\
            &=
            \begin{bmatrix} 1 & 9 \\ 8 & 2 \end{bmatrix}
            \begin{bmatrix} -\frac{1}{35} & \frac{9}{70} \\ \frac{4}{35} & -\frac{1}{70} \end{bmatrix} \\\\
            &=
            \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
            \end{align*}
            \]
            <br>
            Now we can solve the matrix equation \(Ax = b\) for the vector \(x\) by using the inverse:
            \[
            \begin{align*}
            Ax=b  &\Rightarrow  A^{-1}Ax= A^{-1}b  \\\\
                  &\Rightarrow  Ix = A^{-1}b \\\\
                  &\Rightarrow x = A^{-1}b
            \end{align*}
            \]
            <br>
            Note: In practice, solving by row reduction is often faster than finding \(A^{-1}\) and can be more accurate.
            <br><br>
            Finally, let's consider an invertible <strong>linear transformation</strong> \(T:\mathbb{R}^n \to \mathbb{R}^n\).
            <br>
            \(T\) is invertible if
            \[
            \begin{align*}
            &\exists S: \mathbb{R}^n \to \mathbb{R}^n \text{ such that } \\\\
            &\forall x \in \mathbb{R}^n, S(T(x))=x \text{ and } T(S(x))=x.
            \end{align*}
            \]
            </p>
            </section>

            <section id="element" class="section-content">
            <h2>Elementary Matrices</h2>
            <p>
            An <strong>elementary matrix</strong> represents a single elementary row operation applied to an identity matrix. 
            Let
            </p>
            \[
            A = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix}
            \]
            <p>
            and 
            </p>
            \[
            \begin{align*}
            &E_1 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 0 & 1\\ 0 & 1 & 0 \end{bmatrix}, \quad
            E_2 = \begin{bmatrix} 2 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix},  \\\\
            &\text{ and } E_3 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & -3 & 1 \end{bmatrix}
            \end{align*}
            \] 
            <p>
            Then:
            </p>     
            \[
            \begin{align*}
            &E_1A = \begin{bmatrix} 1 & 2 & 3 \\ 7 & 8 & 9 \\ 4 & 5 & 6 \end{bmatrix} \\\\
            &E_2A = \begin{bmatrix} 2 & 4 & 6 \\ 4 & 5 & 6 \\ 7 & 8 & 9   \end{bmatrix} \\\\\
            &E_3A = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ -5 & -7 & -9 \end{bmatrix}
            \end{align*}
            \] 
            <p>
            \(E_1\) interchanges Row 2 and Row 3, \(E_2\) scales Row 1 by 2,
            and \(E_3\) adds (Row2 \(\times-3\)) to Row3. Moreover, we can store a "sequence" of the 
            row operations into a single matrix. For example:
            </p>
            \[
            \begin{align*}
            E_3E_2E_1A &= \begin{bmatrix} 2 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 1 & -3 \end{bmatrix}
                        \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix} \\\\
                    &= \begin{bmatrix} 2 & 4 & 6 \\ 7 & 8 & 9 \\-17 & -19 & -21 \end{bmatrix}\\\\
                    &= B
            \end{align*}
            \]
            <p>
            Since elementary row operations are "reversible", there always exists a corresponding inverse matrix. Thus, 
            using the inverse of elementary matrices, we can recover the original matrix \(A\) from \(B\). 
            </p>
            \[
            \begin{align*}
            &(E_1^{-1}E_2^{-1}E_3^{-1})E_3E_2E_1A  \\\\
            &= (E_1^{-1}E_2^{-1}E_3^{-1})B
            \end{align*}
            \]
            <p>
            Thus:
            </p>
            \[
            \begin{align*}
            A &= \begin{bmatrix} 0.5 & 0 & 0 \\ 0 & 3 & 1 \\ 0 & 1 & 0 \end{bmatrix}
                \begin{bmatrix} 2 & 4 & 6 \\ 7 & 8 & 9 \\ -17 & -19 & -21 \end{bmatrix}\\\\
            &= \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{bmatrix}
            \end{align*}
            \] 

            <p>         
            Even though \(A\) in the above example is not invertible, the process of elementary row operations gives insight 
            into how to compute the inverse of a matrix \(A^{-1}\) if it exists.
            <br><br>
            If an \(n \times n\) matrix \(A\) is invertible, the reduced row echelon form of the matrix must be \(I_n\). 
            Each step of the row reduction can be represented by an elementary matrix. 
            </p>
            \[
            (E_k \cdots E_1)A = I_n  \tag{1}
            \]
            <p>
            From equation (1), we can multiply both sides by \((E_k \cdots E_1)^{-1}\) on the left:
            </p>
            \[
            \begin{align*}
            A  &= (E_k \cdots E_1)^{-1}I_n \\\\
            &= (E_k \cdots E_1)^{-1}
            \end{align*}
            \]
            <p>
            Taking the inverse of both sides:
            </p>
            \[
            \begin{align*}
            A^{-1} &= ((E_k \cdots E_1)^{-1})^{-1}  \\\\
                &= E_k \cdots E_1  \\\\
                &= (E_k \cdots E_1 )I_n  \tag{2}
            \end{align*}
            \]
            <p>
            Equations (1) and (2) show that the same sequence of elementary matrices transforms \(A\) into \(I_n\) 
            and \(I_n\) into \(A^{-1}\). 
            <br>
            Therefore, row reduction on the augmented matrix \(\begin{bmatrix} A & I \end{bmatrix}\)
            gives us \(\begin{bmatrix} I & A^{-1} \end{bmatrix}\) if \(A\) is invertible. 
            </p>
            </section>

            <section id="part" class="section-content">
            <h2>Partitions</h2>
            <p>
            \[ 
            \begin{align*}
                &A = 
                \left[\begin{array}{ccc|cc}
                1 & 2 & -1 & 3 & 4 \\
                5 & 3 & 0 & -2 & 1 \\ \hline
                -1 & 3 & 1 & 7 & 1 \\
                \end{array}\right]
                =
                \left[\begin{array}{c|c}
                A_{11}& A_{12}  \\ \hline
                A_{21} & A_{22} \\
                \end{array}\right] \\\\
                
                &B = 
                \left[\begin{array}{}
                3 & 2 \\
                3 & -5 \\ 
                -1 & 6 \\ \hline
                4 & 7\\
                1 & 1\\ 
                \end{array}\right]
                =
                B = \left[\begin{array}{}
                B_1 \\ \hline
                B_2 \\ 
                \end{array}\right]
            \end{align*}
            \]
            The partitions of \(A\) and \(B\) are conformable for block multiplication. Partitioning is particularly 
            useful when matrices are very large, as it enables a computer to process smaller submatrices at a time, 
            improving efficiency and computational feasibility.
            \[
                AB
                =
                \left[\begin{array}{c|c}
                A_{11}B_1 + A_{12}B_2  \\
                A_{21}B_1 + A_{22}B_2 \\
                \end{array}\right]
                =
                \left[\begin{array}{}
                26 & 11 \\
                17 & -18\\ \hline
                34 & 39 \\ 
                \end{array}\right]
            \]
            </p>
            </section>

            
            <section id="lu" class="section-content">
            <h2>LU Factorization</h2>
            <p>
            A <strong>matrix factorization</strong> expresses the matrix as a product of two or more matrices.
            Since matrix multiplications corresponds to the linear transformations, matrix factorization is 
            fundamental for analyzing the properties of the original matrix (or the observed data). 
            In applied mathematics, matrix factorization is often used as a crucial <strong>preprocessing step</strong> 
            to enable more efficient computations.
            <br><br>
            Given an \(m \times n\) matrix \(A\), it can be factorized into the form
            \[A  = LU\]
            where \(L \in \mathbb{R}^{m \times m}\) is a lower triangular matrix with 1's on its main diagonal and
            \(U \in \mathbb{R}^{m \times n}\) is an echelon form of \(A\). 
            <br><br>
            For example, let
            \[A = \begin{bmatrix} 1 & 2 & -1 \\ 2 & 1 & -2\\ -3 & 1 & 1 \end{bmatrix}.\]
            The echelon form of \(A\) is 
            \[U = \begin{bmatrix} 1 & 2 & -1 \\ 0 & -3 & 0 \\ 0 & 0 & -2 \end{bmatrix}\]
            We can track the row operations used to reduce \(A\) into \(U\) as elementary matrices:
            \[
            \begin{align*}
             &E_1 = \begin{bmatrix} 1 & 0 & 0 \\ -2 & 1 & 0\\ 0 & 0 & 1 \end{bmatrix},
             \qquad 
             E_2 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0\\ 3 & 0 & 1 \end{bmatrix}, \\\\
             \qquad
             &\text{and } \quad E_3 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0\\ 0 & \frac{7}{3} & 1 \end{bmatrix}
            \end{align*}
            \]
            Since
            \[
            E_3E_2E_1A = U \Longrightarrow A = (E_1^{-1}E_2^{-1}E_3^{-1})U,
            \]
            it follows that:
            \[
            L = E_1^{-1}E_2^{-1}E_3^{-1} = \begin{bmatrix} 1 & 0 & 0 \\ 2 & 1 & 0 \\ -3 & \frac{-7}{3} & 1 \end{bmatrix} 
            \]
            Thus, 
            \[ 
            \begin{align*}
            A = LU 
                    &=  \begin{bmatrix} 1 & 0 & 0 \\ 2 & 1 & 0 \\ -3 & \frac{-7}{3} & 1 \end{bmatrix}
                        \begin{bmatrix} 1 & 2 & -1 \\ 0 & -3 & 0 \\ 0 & 0 & -2 \end{bmatrix} \\\\
                    &=   \begin{bmatrix} 1 & 2 & -1 \\ 2 & 1 & -2\\ -3 & 1 & 1 \end{bmatrix}.
            \end{align*}
            \]
            <br>
            With the \(LU\) factorization, solving \(Ax = b\) becomes more efficient:
            \[Ax = b \Longrightarrow LUx = b\]
            Let \(Ux = y\) and solve the pair of equations sequentially:
            <br>
            <ol style="padding-left: 40px;">
                <li>Solve \(Ly = b\) for \(y\)</li>
                <li>Solve \(Ux = y\) for \(x\)</li>
            </ol>
            <br>
            If \(A\) is an \(n \times n\) <strong>dense</strong> matrix with large \(n\), using LU factorization is
            faster than using \(A^{-1}\) to solve \(Ax =b\). This is especially useful when solving the 
            equation multiple times with different \(b\) vectors. Furthermore, LU factorization reduces the risk of
            numerical errors which can arise from computing both both \(A^{-1}\) and \(A^{-1}b\).
            </p>
            </section>
        </div>
        <script src="/js/main.js"></script>
    </body>
</html>
    
    <footer>
    <div class="footer-content">
        <div class="footer-about">
            <h3>About MATH-CS COMPASS</h3>
            <p>Bridging the gap between pure mathematics and computer science applications.</p>
            <div class="contact-section">
                <strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSf3_RNkegREvfCEIQznn6SCaf-iB5c-Doxn7Ymuu78Uf-PBjg/viewform" target="_blank">
                    Submit Your Questions & Feedback <i class="fas fa-external-link-alt"></i>
                </a></strong>
            </div>
        </div>
        <div class="footer-links">
            <h3>Quick Links</h3>
            <ul>
                
                <li><a href="../../../index.html">Home</a></li>
                <li>
                <a href="../Linear_algebra/linear_algebra.html">
                    <span class="nav-number">I</span>
                    <span>Linear Algebra to Algebraic Foundations</span>
                </a>
                </li>
                <li>
                <a href="../Calculus/calculus.html">
                    <span class="nav-number">II</span>
                    <span>Calculus to Optimization & Analysis</span>
                </a>
                </li>
                <li>
                <a href="../Probability/probability.html">
                    <span class="nav-number">III</span>
                    <span>Probability & Statistics</span>
                </a>
                </li>
                <li>
                <a href="../Discrete/discrete_math.html">
                    <span class="nav-number">IV</span>
                    <span>Discrete Mathematics & Algorithms</span>
                </a>
                </li>
                <li>
                <a href="../Machine_learning/ml.html">
                    <span class="nav-number">V</span>
                    <span>Machine Learning</span>
                </a>
                </li>
            </ul>
        </div>
        <div class="footer-social">
            <h3>Connect With Me</h3>
            <p>
                <a href="https://x.com/MathCSCompass?t=Zi8nyfzszeFw8QizbJwnNg&s=09" target="_blank">
                    <i class="fab fa-x-twitter"></i> X (Twitter)
                </a>
            </p>
            <p>
                <a href="https://www.facebook.com/share/15uPaBWgQN/" target="_blank">
                    <i class="fab fa-facebook"></i> Facebook
                </a>
            </p>
      
            <h3>MATH-CS COMPASS App</h3>
            <div class="app-download-footer">
                <a href="https://play.google.com/store/apps/details?id=io.github.yusukey01.twa" target="_blank" rel="noopener">
                    <img src="../../../images/google-play-badge.png" 
                        alt="Get it on Google Play" 
                        class="google-play-badge">
                </a>
            </div>
            
        </div>

    </div>
    <div class="footer-bottom">
        <p>&copy; 2024-2025 MATH-CS COMPASS. All rights reserved.</p>
    </div>
</footer>
    <script src="../../../js/main.js?v=1.0.2"></script>
    <script src="../../../js/search.js?v=1.0.2"></script>
    

    <button id="go-to-top-btn" class="go-to-top-btn" title="Go to top">
        <i class="fas fa-arrow-up"></i>
    </button>
    <script>
        // Register the service worker
        if ('serviceWorker' in navigator) {
          window.addEventListener('load', () => {
            navigator.serviceWorker.register('/js/service-worker.js')
              .then(registration => {
                console.log('ServiceWorker registration successful with scope: ', registration.scope);
              })
              .catch(error => {
                console.log('ServiceWorker registration failed: ', error);
              });
          });
        }
      </script>
</body>
</html>