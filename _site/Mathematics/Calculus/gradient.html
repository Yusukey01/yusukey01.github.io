<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    
    <title>Gradient Descent - MATH-CS COMPASS</title>
    
    
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
    </script>
    <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Main-Regular.woff" as="font" type="font/woff2" crossorigin>
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/mathjax@3/es5/output/chtml/fonts/woff-v2/MathJax_Math-Italic.woff" as="font" type="font/woff2" crossorigin>
    
    
    
    <script src="https://cdn.jsdelivr.net/pyodide/v0.23.3/full/pyodide.js" defer></script>
    

    <link rel="stylesheet" href="../../../css/styles.css?v=1.0.2">
  
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">

    <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
    <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Learn about convexity, gradient descent, and stochastic gradient descent.">
    <meta name="google-site-verification" content="IieEujypYW38caEVe8ymjczouNl56yxAy27iPztcfRA" />
    

    <link rel="manifest" href="/manifest.json">

    <!-- Theme color for Chrome, Android, and other browsers -->
    <meta name="theme-color" content="#007bff">
  
    <!-- iOS specific tags -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="MATH-CS COMPASS">
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Icon references -->
    <link rel="icon" type="image/png" sizes="1280x1280" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="icon" type="image/png" sizes="512x512" href="/images//maskable_icon_x512.png?v=1.0.2">
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/images/maskable_icon_x1280.png?v=1.0.2">
    <link rel="apple-touch-icon" href="/images/maskable_icon_x512.png?v=1.0.2">

    <!-- For Windows -->
    <meta name="msapplication-TileImage" content="/images/test1.png?v=1.0.2">
    <meta name="msapplication-TileColor" content="#007bff">

    <!-- Schema.org Structured Data for AI Optimization -->
    

    <!-- Article Schema for content pages -->
    
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "Gradient Descent",
      "description": "Learn about convexity, gradient descent, and stochastic gradient descent.",
      "datePublished": "2024-01-01",
      "dateModified": "2025-01-01",
      "author": {
        "@type": "Person",
        "name": "Yusuke Yokota",
        "jobTitle": "Mathematics & Computer Science Educator",
        "knowsAbout": [
          "Linear Algebra",
          "Machine Learning",
          "Computer Science",
          "Mathematics"
        ]
      },
      "publisher": {
        "@type": "Organization",
        "name": "MATH-CS COMPASS",
        "url": "https://math-cs-compass.com",
        "logo": {
          "@type": "ImageObject",
          "url": "https://math-cs-compass.com/images/maskable_icon_x512.png"
        }
      },
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://math-cs-compass.com/Mathematics/Calculus/gradient.html"
      },
      "about": [
        
        { "@type": "Thing", "name": "Calculus" },
        { "@type": "Thing", "name": "Optimization" }
        
      ],
      "educationalLevel": "university",
      "learningResourceType": "tutorial",
      "educationalUse": "instruction"
    }
    </script>
    
</head>

<body>
    <header>
    <nav class="navbar">
        <!-- Logo as Home Button -->
        <div class="logo-home">
            <a href="../../../index.html" 
               class="logo-link " 
               title="Home - Math-CS Compass">
                <img src="../../images/icon_x512.png" 
                     alt="Math-CS Compass Logo" 
                     class="nav-logo">
            </a>
        </div>

        <div class="search-container">
            <input type="text" id="search-input" placeholder="Search keywords...">
            <button id="search-button" aria-label="Search" title="Search website"><i class="fas fa-search"></i></button>
        </div>
        
        <div class="menu-toggle">
            <i class="fas fa-bars"></i>
        </div>
        
        <ul class="nav-links">
            <li><a href="../Linear_algebra/linear_algebra.html" >I - Linear Algebra to Algebraic Foundations</a></li>
            
            <li><a href="../Calculus/calculus.html" class="active">II - Calculus to Optimization & Analysis</a></li>
            
            <li><a href="../Probability/probability.html" >III - Probability & Statistics</a></li>
            
            <li><a href="../Discrete/discrete_math.html" >IV - Discrete Mathematics & Algorithms</a></li>
            
            <li><a href="../Machine_learning/ml.html" >V - Machine Learning</a></li>
        </ul>
    </nav>
</header>
    
    <!DOCTYPE html>
<html>
    <body> 
        <!-- LearningResource Schema for Gradient Descent -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "Gradient Descent",
        "description": "Learn about convexity, gradient descent, and stochastic gradient descent",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "active",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator",
            "knowsAbout": [
            "Gradient Descent",
            "Optimization Theory",
            "Convex Functions",
            "Stochastic Optimization",
            "First-order Methods",
            "Mathematical Analysis"
            ]
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://math-cs-compass.com"
        },
        "about": [
            { "@type": "Thing", "name": "Gradient Descent" },
            { "@type": "Thing", "name": "Stochastic Gradient Descent" },
            { "@type": "Thing", "name": "Mini-batch SGD" },
            { "@type": "Thing", "name": "Convex Functions" },
            { "@type": "Thing", "name": "Convexity" },
            { "@type": "Thing", "name": "Local Minimum" },
            { "@type": "Thing", "name": "Global Minimum" },
            { "@type": "Thing", "name": "Hessian Matrix" },
            { "@type": "Thing", "name": "First-order Methods" },
            { "@type": "Thing", "name": "Steepest Descent" },
            { "@type": "Thing", "name": "Learning Rate" },
            { "@type": "Thing", "name": "Subgradient" },
            { "@type": "Thing", "name": "Subdifferentiable" },
            { "@type": "Thing", "name": "Parameter Estimation" },
            { "@type": "Thing", "name": "Model Fitting" }
        ],
        "teaches": [
            "Understanding optimization problems in machine learning",
            "Analyzing convex functions and their properties",
            "Implementing gradient descent algorithms",
            "Understanding stochastic gradient descent",
            "Working with mini-batch optimization",
            "Handling non-smooth functions with subgradients",
            "Choosing appropriate learning rates",
            "Convergence analysis of optimization algorithms"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Calculus to Optimization & Analysis",
            "description": "Explore optimization techniques and mathematical analysis with applications",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://math-cs-compass.com"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "II",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT5H",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>

        <!-- WebApplication Schema for Interactive Code Demo -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "WebApplication",
        "name": "Mini-batch SGD Implementation Demo",
        "description": "Interactive Python implementation of mini-batch stochastic gradient descent for linear regression",
        "applicationCategory": "EducationalApplication",
        "operatingSystem": "Web Browser",
        "url": "https://math-cs-compass.com/Mathematics/Calculus/gradient.html",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota"
        },
        "applicationSubCategory": "Machine Learning Algorithm Implementation",
        "featureList": [
            "Mini-batch SGD implementation in Python",
            "Linear regression optimization example",
            "Interactive code execution",
            "Parameter estimation demonstration",
            "Convergence analysis visualization",
            "Real-time algorithm performance monitoring"
        ],
        "isAccessibleForFree": true,
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "about": [
            { "@type": "Thing", "name": "SGD Implementation Demo" },
            { "@type": "Thing", "name": "Linear Regression Optimization" },
            { "@type": "Thing", "name": "Gradient Descent Code Example" }
        ]
        }
        </script>
        <div class="hero-section">
            <h1 class="webpage-name"> Gradient Descent 
                <span class="subheading">First-order Optimization Techniques</span>
            </h1>
        </div>

        
  <div class="quick-jump-container">
    <button type="button" id="quick-jump-toggle" class="quick-jump-toggle">
      <i class="fas fa-list"></i> <strong>Section II Navigation</strong>
    </button>
    <div id="quick-jump-menu" class="quick-jump-menu">
      <h3>Calculus to Optimization & Analysis</h3>
      <div class="quick-jump-links">
        
        
        <a href="calculus.html">← Back to Section II Overview</a>
        <hr style="margin: 8px 0; border: 1px solid #ddd;">
        
        
        <a href="linear_approximation.html" >Part 1: The Derivative of f:ℝⁿ → ℝ</a>
        <a href="jacobian.html" >Part 2: The Derivative of f:ℝⁿ → ℝⁿ</a>
        <a href="matrix_cal.html" >Part 3: The Derivative of f:ℝⁿˣⁿ → ℝⁿˣⁿ</a>
        <a href="numerical_example1.html" >Part 4: Intro to Numerical Computation</a>
        <a href="det.html" >Part 5: Scalar Functions of Matrices</a>
        <a href="mvt.html" >Part 6: The Mean Value Theorem</a>
        <a href="gradient.html" class="current-page">Part 7: Gradient Descent</a>
        <a href="newton.html" >Part 8: Newton's Method</a>
        <a href="constrained_opt.html" >Part 9: Constrained Optimization</a>
        <a href="riemann.html" >Part 10: Riemann Integration</a>
        <a href="measure.html" >Part 11: Measure Theory</a>
        <a href="lebesgue.html" >Part 12: Lebesgue Integration</a>
        <a href="duality.html" >Part 13: Duality in Optimization</a>
        <a href="fourier_series.html" >Part 14: Fourier Series</a>
        <a href="fourier_transform.html" >Part 15: Fourier Transform</a>
      </div>
    </div>
</div>


        <div class="topic-nav">
            <a href="#intro">Introduction to Optimization</a>
            <a href="#convexity">Convexity</a>
            <a href="#gradient">Gradient Descent</a>
            <a href="#sgd">Stochastic Gradient Descent</a>
            <a href="#subgradient">Sub-gradient Descent</a>
        </div>  

        <div class="container">     
            <section id="intro" class="section-content">
            <h2>Introduction to Optimization</h2>
            <p>
            In machine learning, parameter estimation also known as <strong>model fitting</strong> requires solving 
            <strong>optimization problem</strong>:
            \[
            \theta^* \in \arg \min_{\theta \in \Theta} \mathcal{L}(\theta), \qquad \Theta \subset \mathbb{R}^d
            \]
            where \(\mathcal{L}(\theta)\) is a loss function(objective function),  \(\Theta\) is a parameter space, and 
            \(d\) is the number of variables being optimized over. 
            <br><br>
            Since finding a global optimum is too expensive or impossible in practice, our target will be a local optimum.
            <br>
            A point \(\theta^*\) is a local minimum if: 
            <br>
            \[
            \begin{align*}
            &\exists \, \delta > 0, \, \forall \, \theta \in \Theta  \\\\
            &\text{ s.t. } \| \theta - \theta^* \| < \delta, \, \mathcal{L}(\theta^*) \leq  \mathcal{L}(\theta).
            \end{align*}
            \]
            For a continuously twice differentiable function \(\mathcal{L}(\theta)\), to confirm that \(\theta^*\) is a local 
            minimum, following two conditions must be satisfied:
            <br>
            <ol style="padding-left: 40px;">
                <li>The <strong>gradient vector</strong> is equal to zero.</li>
                \[
                g(\theta^*) = \nabla \mathcal{L}(\theta^*) = 0
                \]
                <li>The <strong>Hessian matrix</strong> is positive definite.</li>
                \[
                H(\theta^*) = \nabla^2 \mathcal{L}(\theta^*) \succ 0
                \]
            </ol>
            </p>
        </section>
    
        <section id="convexity" class="section-content">
            <h2>Convexity</h2>
            <p>
            Usually we design models so that their training objectives are <strong>convex</strong> because in the convex optimization problem, 
            if the local minimum exists, it is actually the "global" minimum. 
            <br><br>
            A set \(\mathcal{S}\) is a convex if for any \(x, x' \in \mathcal{S}\), 
            \[
            \lambda x + (1 - \lambda) x' \in \mathcal{S}, \, \forall \lambda \in [0, 1].
            \]
            A function \(f(x)\) is said to be a <strong>convex function</strong> if it is defined on a convex set and if for any \(x, y \in \mathcal{S}\) and for any 
            \(0 \leq \lambda \leq 1\),
            \[
            f(\lambda x + (1 - \lambda)y) \leq \lambda f(x) + (1 - \lambda) f(y).
            \]
            <div class="theorem">
                <span class="theorem-title">Theorem 1:</span>
                Let \(f: \mathbb{R} \to \mathbb{R}\) be a twice differentiable function.
                Then \(f\) is a convex function if and only if \(f'' \geq 0\) for all \(x \in \mathbb{R}\).
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                Suppose that \(\forall x \in \mathbb{R}\), a function \(f: \mathbb{R} \to \mathbb{R}\) is twice differentiable and 
                \(f'' \geq 0\).
                <br>
                By Taylor's theorem, 
                \(\forall z, w \in \mathbb{R}, \, \exists c \in \mathbb{R} \) such that 
                \[
                f(w) = f(z) + f'(z)(w -z) + f''(c) \frac{(w-z)^2}{2}.
                \]
                This implies 
                \[
                f(w) \geq f(z) + f'(z)(w-z). \tag{1}
                \]
                Here, consider two point \(a, b \in \mathbb{R}\), and let \(z = \lambda a + (1-\lambda)b, \, \lambda \in [0, 1]\). By inequality (1), 
                for each point, we have 
                \[
                \begin{align*}
                &f(a) \geq f(z) + f'(z)(a-z) \\\\
                &\Longrightarrow  \lambda f(a) \geq \lambda f(z) + \lambda f'(z)(a-z) \tag{2}
                \end{align*}
                \]
                and
                \[
                \begin{align*}
                &f(b) \geq f(z) + f'(z)(b-z)  \\\\
                &\Longrightarrow  (1-\lambda )f(b) \geq (1- \lambda )f(z) + (1-\lambda )f'(z)(b-z) \tag{3}
                \end{align*}
                \]
                By (2) + (3), we obtain:
                \[
                \begin{align*}
                \lambda f(a) + (1-\lambda )f(b) &\geq f(z) + \lambda f'(z)(a-z) (1-\lambda )f(z) + (1-\lambda )f'(z)(b-z) \\\\
                                &= f(z) + f'(z)(\lambda a + b -\lambda a - b + \lambda b - \lambda b) \\\\
                                &= f(z)
                \end{align*}
                \]
                Thus,
                \[
                \lambda f(a) + (1-\lambda )f(b) \geq f(\lambda a + (1-\lambda)b).
                \]
                By definition of the convex function, \(f\) is convex. 
                <br><br>
                Next, assume that \(f\) is convex. Let \(a < b\), then since \(f\) is convex, for all \(x\),
                \[
                f(x) \geq f(a) + f'(a)(x -a) 
                \]
                Substituting \(x = b\), 
                \[
                \begin{align*}
                &f(b) \geq f(a) + f'(a)(b -a) \\\\
                &\Longrightarrow f'(a) \leq \frac{f(b) - f(a)}{b - a} \tag{4}
                \end{align*}
                \]
                and similarly, 
                \[
                f(x) \geq f(b) + f'(b)(x -b)
                \]
                Substituting \(x = a\), 
                \[
                \begin{align*}
                &f(a) \geq f(b) + f'(b)(a -b) \\\\
                &\Longrightarrow f'(b) \geq \frac{f(b) - f(a)}{b - a} \tag{5}
                \end{align*}
                \]
                (Note: Since a < b, (a-b) < 0.)
                <br>
                From (4) and (5), we get 
                \[
                f'(a) \leq \frac{f(b) - f(a)}{b - a} \leq f'(b).
                \]
                Thus, \(f'\) is <strong>monotonically increasing</strong> and therefore, \(f'' \geq 0\). 
            </div>
            <br>
            You can see convex functions everywhere in machine learning. For example, 
            the <a href="../Probability/entropy.html"><strong>cross entropy</strong></a> loss function 
            in <a href="../Machine_learning/intro_classification.html"><strong>classification</strong></a> , and the 
            ReLU (Rectified Linear Unit), which is a popular activation function in 
            <a href="../Machine_learning/neural_networks.html"><strong>neural networks</strong></a> are convex. 
            <br><br>
            For \(n\) dimensional case, following theorem is a fundamental aspect of optimization problems. 
            <div class="theorem">
                <span class="theorem-title">Theorem 2:</span>
                Suppose \(f: \mathbb{R}^n \to \mathbb{R}\) is \(C^2\). Then \(f\) is convex if and only if the Hessian matrix 
                \(H = \nabla^2 f(x)\) is positive semidefinite for all \(x \in dom(f)\). Furthermore, \(f\) is strictly convex if \(H\) 
                is positive definite. 
            </div> 
            <div class="proof">
                <span class="proof-title">Proof:</span>
                Suppose for any \(x, y \in \mathbb{R}^n\) and \(\lambda \in (0, 1)\), we define  \(h: [0, 1] \to \mathbb{R}\) 
                as follows:
                \[
                h(\lambda) = f(\lambda a + (1-\lambda)b).
                \]
                For all \(z, w, p \in [0, 1]\), let \(\lambda = pz + (1-p)w\). Then
                \[
                \begin{align*}
                h(\lambda) &= f((pz + (1-p)w) a + (1-(pz + (1-p)w))b) \\\\
                           &\leq ph(z) + (1-p)h(w).
                \end{align*}
                \]
                Thus, \(h\) is a convex function. 
                <br>
                Rewriting \(h\), we have
                \[
                h(\lambda) = f(b + \lambda(a-b)).
                \]
                Taking the second derivative with respect to \(\lambda\), we obtain:
                \[
                \begin{align*}
                &\frac{dh}{d\lambda} = (\nabla f(b + \lambda (a - b)))^T (a - b) \\\\
                &\frac{d^2h}{d\lambda^2} = (a - b)^T (\nabla^2 f(b + \lambda(a - b))) (a - b)
                \end{align*}
                \]
                Here, \(\nabla^2 f(x)\) is the Hessian matrix of \(f\) and \(\frac{d^2h}{d\lambda^2}\) is in quadratic form. 
                <br>
                For \(h\) to be a convex function, we must have:
                \[
                \frac{d^2h}{d\lambda^2} \geq 0 \quad \forall \lambda \in [0, 1].
                \]
                This implies the Hessian matrix is positive semidefinite for all \(x\).
                <br><br>
                For the sake of space, we omit the full proof.
            </div>
            The relationship between the Hessian matrix and convexity is fundamental to many optimization algorithms and 
            is widely applied in both theoretical and practical optimization problems.
            </p>
        </section>
        
        <section id="gradient" class="section-content">
            <h2>Gradient Descent</h2>
            <p>
            To find a local minimum of an objective function, we update the current point by moving in the direction that   
            the <strong>negative gradient</strong>, \(- \nabla f\). This is because the gradient, \(\nabla f\)  indicates 
            the direction of steepest increase of the function \(f\). By contrast, the negative gradient points in the 
            direction of the <strong>steepest descent</strong> of \(f\). Thus, "iteratively" moving in the direction 
            of \(- \nabla f\) reduces the value of \(f\) and the value will converge to a local minimum.
            
            <div class="pseudocode">
                <span class="pseudocode-title">Algorithm 1: GRADIENT_DESCENT</span>
                <strong>Input:</strong> objective function \(f\), tolerance \(\epsilon\), learning rate \(\eta\);
                <strong>Output:</strong> stationary point \(\theta^*\);
                <strong>begin</strong>
                &emsp;\(k \leftarrow 0\);
                &emsp;Choose an initial point \(\theta^{(0)}\);
                &emsp;<strong>repeat: </strong>
                &emsp;&emsp;&emsp;Compute gradient: \(d^{(k)} = - \nabla f(\theta^{(k)});\)
                &emsp;&emsp;&emsp;Update parameters:\(\theta^{(k+1)} = \theta^{(k)} + \eta d^{(k)};\)
                &emsp;&emsp;&emsp;\( k \leftarrow k + 1 ;\)
                &emsp;<strong>until</strong> \(\| \nabla f(\theta^{(k)}) \| < \epsilon\);
                &emsp;Output \(\theta^{(k)}\);
                <strong>end</strong>
            </div>
            Note: The gradient descent is called the <strong>first-order method</strong> since it requires only the gradient. 
            </p>
        </section>

        <section id="sgd" class="section-content">
            <h2>Stochastic Gradient Descent</h2>
            <p>
            In a <strong>stochastic optimization</strong>, we minimize the average value of an objective function:
            \[
            \mathcal{L}(\theta) = \mathbb{E }_{q(z)}[\mathcal{L}(\theta, z)]
            \]
            where \(z\) is a random input to the objective function. \(z\) can be a training example or just a random noise term.
            At each iteration, we update:
            \[
            \theta^{(k+1)} = \theta^{(k)} - \eta^{(k)} \nabla \mathcal{L}(\theta^{(k)}, z^{(k)}).
            \]
            This method is called the <strong>stochastic gradient descent</strong>.
            <br>
            Note: Assuming the distribution \(q(z)\) is independent of the parameters we want to optimize. 
            <br><br>
            On both GD and SGD, a critical issue is that at each iteration, we have to compute the gradient with respect to 
            all data points. If the given data set is huge, the algorithm becomes too expensive. 
            Instead, we introduce the <strong>mini-batch</strong>. Typical mini-batch size can be \(B = 32, 64, 128, \cdots\), 
            depending on the data size \(N\) and we compute an "approximate" gradient using only a small mini-batch(a subset of data). Intuitively, 
            we quickly find a "good enough" direction to improve the objective. 
            <div class="pseudocode">
                <span class="pseudocode-title">Algorithm 2: MINI_BATCH_SGD</span>
                <strong>Input:</strong> dataset \(X\), objective function \(f\), tolerance \(\epsilon\), batch size \(B\), learning rate \(\eta\), max_epoch;
                <strong>Output:</strong> stationary point \(\theta^*\);
                <strong>begin</strong>
                &emsp;Set \(k \leftarrow  0\);
                &emsp;Choose an initial point \(\theta^{(0)}\);
                &emsp;<strong>repeat</strong>:
                &emsp;&emsp;Shuffle the dataset \(X\) randomly;
                &emsp;&emsp;Divide \(X\) into mini-batches \(\{B_1, B_2, \cdots, B_m\}\) each of size \(B\);
                &emsp;&emsp;<strong>for</strong> each mini-batch \(B_i\):
                &emsp;&emsp;&emsp;&emsp;Compute gradient: \(d^{(k)} = - \frac{1}{|B|} \sum_{x \in B_i} \nabla f(x; \theta^{(k)});\)
                &emsp;&emsp;&emsp;&emsp;Update parameters: \(\theta^{(k+1)} = \theta^{(k)} + \eta d^{(k)};\)
                &emsp;&emsp;<strong>end for</strong>
                &emsp;&emsp;Set \( k \leftarrow k + 1;\)
                &emsp;<strong>until</strong> \(\| d^{(k)} \| < \epsilon\) or \(k \geq \) max_epoch;
                &emsp;Output \(\theta^{(k)}\);
                <strong>end</strong>
            </div>
            Note: After a training <strong>epoch</strong>, we shuffle the dataset to generate different mini-batchies.
            <br>
            A sample code for mini-batch SGD in linear regression as follows: 
            <div class="code-container">
                <div class="collapsible-section">
                <button class="collapsible-btn">Show/Hide Code</button>
                <div class="collapsible-content">
                <pre class="python-code">
                    import numpy as np

                    # Fixed parameters for mini-batch SGD
                    MAX_EPOCH = 10000
                    BATCH_SIZE = 64
                    TOLERANCE = 1e-3
                    LEARNING_RATE = 0.01

                    # Sample data dimensions
                    N_SAMPLES = 10000
                    N_FEATURES = 3

                    # Mini-batch Stochastic Gradient Descent
                    def mini_batch_sgd(X, y):
                        n_samples = X.shape[0]
                        theta = np.random.randn(X.shape[1]) * 0.01  # initial theta
                        
                        for i in range(MAX_EPOCH):
                            # Shuffling Data 
                            indices = np.random.permutation(n_samples)
                            x_shuffled = X[indices]
                            y_shuffled = y[indices]
                            
                            for j in range(0, n_samples, BATCH_SIZE):
                                end = j + BATCH_SIZE
                                x_batch = x_shuffled[j:end]
                                y_batch = y_shuffled[j:end]
                                
                                # gradient function 
                                g = grad_f(theta, x_batch, y_batch)
                                
                                # Update parameters
                                theta -= LEARNING_RATE * g
                            
                            # Check convergence
                            if np.linalg.norm(g) < TOLERANCE:
                                print(f"Converged in {i + 1} epochs.")
                                break
                        return theta

                    # Gradient of objective function for linear regression (gradient of Mean Squared Error (MSE))
                    def grad_f(theta, x_batch, y_batch):
                            grad = (1 /(x_batch.shape[0])) * x_batch.T @ ((x_batch @ theta) - y_batch)
                            return grad
                        
                    # Main 
                    if __name__ == "__main__":
                        
                        # Generate sample data and objective 
                        X = np.random.rand(N_SAMPLES, N_FEATURES) 
                        true_theta = np.array([5, -1, -9])
                        y = X @ true_theta + np.random.randn(X.shape[0]) * 0.1  # Add noise
                        
                        # Run Mini-Batch SGD
                        estimated_theta = mini_batch_sgd(X, y)
                        
                        # Calculate relative error
                        relative_error = np.linalg.norm(estimated_theta - true_theta) / np.linalg.norm(true_theta)
                        
                        print("True Parameters: ", true_theta)
                        print("Estimated Parameters: ", estimated_theta)
                        print(f"Relative Error: {relative_error:.6f}")
                    </pre>
                </div>
                </div>
                <button class="run-button" onclick="runPythonCode(this)">Run Code</button>
                <div class="python-output"></div>
            </div>
            </p>
        </section>
    
        <section id="subgradient" class="section-content">
            <h2>Sub-gradient Descent</h2>
            <p>
            Even if a objective funtion has local discontinuities(non-smooth), still we can compute its gradients. Particularly, for 
            a convex function \(f: \mathbb{R}^n \to \mathbb{R}\), we define a <strong>subgradient</strong> of \(f\) at 
            \(x \in dom(f)\): 
            \[
            f(z) \geq f(x) g^T (z - x) \tag{6}
            \]
            for all \(z \in dom(f)\).
            <br> 
            A function \(f\) is <strong>subdifferentiable</strong> at \(x\) if there exists a subgradient \(g \in \mathbb{R^n}\) at 
            \(x\). For example, \(f(x) = |x|\) is not differentiable at \(x = 0\), but it is subdifferentiable as follows:
            \[
            \partial f(x) =  \begin{cases} 
                    \{-1\} &\text{ if } x < 0 \\
                    [-1, 1] &\text{ if } x = 0 \\
                    \{1\} &\text{ if }  x > 0
                    \end{cases}.
            \]
            In <strong>sub-gradient descent</strong>, we just find a gradient that satisfies inequality (6) but it is slower 
            than GD on a convex smooth function because the gradient does not get smaller near the global minimum.
            </p>
        </section>
    </div>
    <script src="/js/main.js"></script>
    <script src="/js/runPythonCode.js"></script>
    <script src="/js/collapsible.js"></script>

    </body>
</html>
    
    <footer>
    <div class="footer-content">
        <div class="footer-about">
            <h3>About MATH-CS COMPASS</h3>
            <p>Bridging the gap between pure mathematics and computer science applications.</p>
            <div class="contact-section">
                <strong><a href="https://docs.google.com/forms/d/e/1FAIpQLSf3_RNkegREvfCEIQznn6SCaf-iB5c-Doxn7Ymuu78Uf-PBjg/viewform" target="_blank">
                    Submit Your Questions & Feedback <i class="fas fa-external-link-alt"></i>
                </a></strong>
            </div>
        </div>
        <div class="footer-links">
            <h3>Quick Links</h3>
            <ul>
                
                <li><a href="../../../index.html">Home</a></li>
                <li>
                <a href="../Linear_algebra/linear_algebra.html">
                    <span class="nav-number">I</span>
                    <span>Linear Algebra to Algebraic Foundations</span>
                </a>
                </li>
                <li>
                <a href="../Calculus/calculus.html">
                    <span class="nav-number">II</span>
                    <span>Calculus to Optimization & Analysis</span>
                </a>
                </li>
                <li>
                <a href="../Probability/probability.html">
                    <span class="nav-number">III</span>
                    <span>Probability & Statistics</span>
                </a>
                </li>
                <li>
                <a href="../Discrete/discrete_math.html">
                    <span class="nav-number">IV</span>
                    <span>Discrete Mathematics & Algorithms</span>
                </a>
                </li>
                <li>
                <a href="../Machine_learning/ml.html">
                    <span class="nav-number">V</span>
                    <span>Machine Learning</span>
                </a>
                </li>
            </ul>
        </div>
        <div class="footer-social">
            <h3>Connect With Me</h3>
            <p>
                <a href="https://x.com/MathCSCompass?t=Zi8nyfzszeFw8QizbJwnNg&s=09" target="_blank">
                    <i class="fab fa-x-twitter"></i> X (Twitter)
                </a>
            </p>
            <p>
                <a href="https://www.facebook.com/share/15uPaBWgQN/" target="_blank">
                    <i class="fab fa-facebook"></i> Facebook
                </a>
            </p>
      
            <h3>MATH-CS COMPASS App</h3>
            <div class="app-download-footer">
                <a href="https://play.google.com/store/apps/details?id=io.github.yusukey01.twa" target="_blank" rel="noopener">
                    <img src="../../../images/google-play-badge.png" 
                        alt="Get it on Google Play" 
                        class="google-play-badge">
                </a>
            </div>
            
        </div>

    </div>
    <div class="footer-bottom">
        <p>&copy; 2024-2025 MATH-CS COMPASS. All rights reserved.</p>
    </div>
</footer>
    <script src="../../../js/main.js?v=1.0.2"></script>
    <script src="../../../js/search.js?v=1.0.2"></script>
    

    <button id="go-to-top-btn" class="go-to-top-btn" title="Go to top">
        <i class="fas fa-arrow-up"></i>
    </button>
    <script>
        // Register the service worker
        if ('serviceWorker' in navigator) {
          window.addEventListener('load', () => {
            navigator.serviceWorker.register('/js/service-worker.js')
              .then(registration => {
                console.log('ServiceWorker registration successful with scope: ', registration.scope);
              })
              .catch(error => {
                console.log('ServiceWorker registration failed: ', error);
              });
          });
        }
      </script>
</body>
</html>