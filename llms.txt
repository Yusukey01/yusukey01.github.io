# MATH-CS COMPASS

> **Bridging Pure & Applied Mathematics with Computer Science and Machine Learning**

MATH-CS COMPASS is a free educational platform designed to address the gap where computer science students struggle with mathematical foundations while mathematics students lack awareness of practical applications. The ultimate goal is building rigorous mathematical foundations for Geometric Deep Learning and Physical AI—core paradigms in the AI industry.

## Philosophy

Mathematics is the study of **structure**. This platform offers an accessible yet principled look at the mathematical blueprints that power modern technology. Specific tools and frameworks become outdated, but mathematical foundations are eternal.

The curriculum spans two worlds:
- **The Continuous World** (Calculus, Topology, Analysis): Smooth functions, limits, optimization, and metric spaces.
- **The Discrete World** (Algebra, Graphs, Algorithms): Finite structures, logic, combinations, and computation.

**Machine Learning** sits at the intersection, synthesizing both worlds, guided by the rules of **Probability & Statistics**.

## Author & Meta
- **Author**: Yusuke Yokota
- **Education**: B.S. Mathematics & B.S. Computer Science, Western Washington University
- **Version**: 1.2.2 (Last Updated: February 2026)
- **Website**: [https://math-cs-compass.com](https://math-cs-compass.com)
- **GitHub**: [https://github.com/yusukey01](https://github.com/yusukey01)

## Interactive Features
- **Hexagonal Knowledge Map**: Visual navigation of all ~88 topics showing prerequisites and learning paths.
- **Tessera**: AI learning companion providing context-aware guidance.
- **Interactive Demos**: Python/JavaScript visualizations for complex concepts.
- **Code Examples**: Practical implementations connecting theory to practice.

---

## Curriculum Outline

### Section I: Linear Algebra to Algebraic Foundations (25 Pages)
**URL**: [Mathematics/Linear_algebra/linear_algebra.html](https://math-cs-compass.com/Mathematics/Linear_algebra/linear_algebra.html)
**Tagline**: From Vector Spaces to Universal Algebraic Structures

**Linear Systems & Applied Matrices**
- **Part 1: Linear Equations** — Systems, RREF, span, linear combinations, and independence.
- **Part 2: Linear Transformation** — Linearity, onto, one-to-one mapping, matrix multiplication.
- **Part 3: Matrix Algebra** — Diagonal, identity, transpose, inverse, and LU factorization.
- **Part 4: Determinants** — Cofactor expansion, Cramer's rule, adjugate inverses.
- **Part 8: Least-Squares Problems** — Normal equations, linear regression, pseudo-inverse.
- **Part 10: Trace and Norms** — Frobenius/spectral norms, metric spaces, regularization.
- **Part 11: Kronecker Product & Tensor** — Vectorization, tensor products, and ML applications.
- **Part 12: Efficient Matrix Updates** — Woodbury matrix identity, Matrix Determinant Lemma.
- **Part 13: Stochastic Matrix** — Markov chains, steady-state vectors, doubly stochastic matrices.
- **Part 14: Graph Laplacians** — Spectral analysis of networks, Fiedler vector, Dirichlet energy.

**Spaces & Spectra**
- **Part 5: Vector Spaces** — Subspaces, null/column space, basis, dimension, rank.
- **Part 6: Eigenvalues & Eigenvectors** — Characteristic equation, diagonalization, similarity.
- **Part 7: Orthogonality** — Inner product, Gram-Schmidt, QR factorization.
- **Part 9: Symmetry** — Symmetric matrices, spectral theorem, quadratic forms, SVD.

**Group, Ring & Field Theory**
- **Part 15: Intro to Abstract Algebra** — Groups, binary operations, subgroups, cyclic groups.
- **Part 16: More Finite Groups** — Permutation groups, symmetric groups, alternating groups.
- **Part 17: Structural Group Theory** — Cosets, Lagrange's theorem, normal subgroups, isomorphisms.
- **Part 18: Classification of Finite Abelian Groups** — Direct products, fundamental theorem.
- **Part 24: Geometry of Symmetry** — Dihedral groups, SO(3), SE(3), and introduction to Lie Groups.
- **Part 19: Architecture of Rings and Fields** — Integral domains, zero-divisors, fields, characteristics.
- **Part 20: Ideals and Factor Rings** — Prime/maximal ideals, factor rings, ring homomorphisms.
- **Part 21: Polynomial Rings** — Division algorithm, irreducibility, Eisenstein's criterion, cryptography.
- **Part 22: Hierarchies of Integrity** — Euclidean Domains, PIDs, UFDs, and factorization.
- **Part 23: Extension Fields** — Splitting fields, simple extensions, fundamental theorem of field theory.
- **Part 25: Algebraic Extensions** — Algebraic Extension,  Transcendental Extension, Degree of an Extension, Tower Rule, Primitive Element Theorem.

<br>

### Section II: Calculus to Optimization & Analysis (22 Pages)
**URL**: [Mathematics/Calculus/calculus.html](https://math-cs-compass.com/Mathematics/Calculus/calculus.html)
**Tagline**: The Mathematics of Change and Convergence

**Derivatives & Numerical Computation**
- **Part 1: Linear Approximations** — Differentials, linearization, gradients, quadratic forms.
- **Part 2: Jacobian** — Jacobian matrices, chain rule, forward/reverse autodiff, backpropagation.
- **Part 3: Matrix Calculus** — Derivatives of matrix-valued functions, product rules for matrices.
- **Part 5: Scalar Functions of a Matrix** — Derivatives of Frobenius norm and determinants.
- **Part 4: Intro to Numerical Computation** — Finite differences, roundoff/relative error, stability.

**Optimization**
- **Part 6: The Mean Value Theorem** — Lagrange's/Cauchy's MVT, Taylor's theorem, higher-dimensional MVT.
- **Part 7: Gradient Descent** — Convexity, learning rates, SGD, mini-batch, subgradients.
- **Part 8: Newton's Method** — Second-order optimization, line search, Wolfe conditions, BFGS, L-BFGS.
- **Part 9: Constrained Optimization** — Lagrange multipliers, KKT conditions, penalty terms.
- **Part 13: Duality** — Primal/Dual problems, strong duality, Lipschitz continuity, condition numbers.

**Integration, Measure & Fourier**
- **Part 10: Riemann Integration** — Partitions, upper/lower sums, improper integration, Dirichlet function.
- **Part 11: Measure Theory with Probability** — σ-algebras, measurable sets, Lebesgue measure.
- **Part 12: Intro to Lebesgue Integration** — Abstract integration, characteristic functions, "almost everywhere".
- **Part 14: Fourier Series** — Orthogonality of trigonometric functions, Parseval's identity.
- **Part 15: Fourier Transform** — Continuous/Discrete transforms, FFT, Convolution theorem.

**Topology & Metric Spaces**
- **Part 16: Foundations of Analysis** — Metric spaces, open/closed sets, boundaries, open balls.
- **Part 17: Convergence & Boundedness** — Cauchy sequences, total boundedness, limits.
- **Part 18: Continuity** — Uniform continuity, Lipschitz constants, contractions, isometries.
- **Part 19: Completeness** — Banach's Fixed-Point Theorem, completion, Cantor's intersection.
- **Part 20: Connectedness** — Path-connectedness, connected components, Intermediate Value Theorem.
- **Part 21: Compactness** — Open covers, Heine-Borel Theorem, Extreme Value Theorem (EVT).
- **Part 22: Metric Equivalence** — Homeomorphisms, topological equivalence, invariants.

<br>

### Section III: Probability & Statistics (21 Pages)
**URL**: [Mathematics/Probability/probability.html](https://math-cs-compass.com/Mathematics/Probability/probability.html)
**Tagline**: The Mathematics of Uncertainty and Inference

**Foundations & Information**
- **Part 1: Basic Probability Ideas** — Sample space, conditional probability, Bayes' theorem.
- **Part 2: Random Variables** — PMF, PDF, CDF, expected value, variance, standard deviation.
- **Part 12: Entropy** — Information content, joint/conditional/cross entropy, KL Divergence, Mutual Information.

**Distributions & Multivariate Statistics**
- **Part 3: Gamma & Beta Distribution** — Gamma/Beta functions, modeling waiting times and proportions.
- **Part 4: Normal (Gaussian) Distribution** — Gaussian integrals, Chi-Squared, Central Limit Theorem.
- **Part 5: Student's t-Distribution** — Degrees of freedom, Cauchy and Laplace distributions, heavy tails.
- **Part 6: Covariance** — Covariance matrices, total variance, PCA.
- **Part 7: Correlation** — Cross-covariance, correlation coefficients, standardization.
- **Part 8: Multivariate Distributions** — Multivariate Normal (MVN), Mahalanobis distance, Dirichlet, Wishart.
- **Part 15: The Exponential Family** — Natural parameters, sufficient statistics, log-partition function.

**Statistical Inference & Stochastic Processes**
- **Part 9: Maximum Likelihood Estimation** — Point estimators, bias, MSE, likelihood functions.
- **Part 10: Statistical Inference & Hypothesis Testing** — Null hypotheses, Type I/II errors, p-values, Bootstrap.
- **Part 11: Linear Regression** — Least-squares estimation from a probabilistic perspective.
- **Part 13: Convergence** — Law of Large Numbers, convergence in probability/distribution, MGFs.
- **Part 18: Markov Chains** — Transition matrices, n-grams, Probabilistic Graphical Models.
- **Part 21: Gaussian Processes** — Nonparametric models, Mercer kernels (RBF, Matérn), GP regression.

**Bayesian Methods**
- **Part 14: Intro to Bayesian Statistics** — Prior/posterior distributions, conjugate priors.
- **Part 16: Fisher Information Matrix** — Score function, natural gradients, Jeffreys prior.
- **Part 17: Bayesian Decision Theory** — MAP estimates, zero-one loss, ROC curves, Precision-Recall.
- **Part 19: Monte Carlo Methods** — Credible intervals, HPD regions, Markov Chain Monte Carlo (MCMC).
- **Part 20: Importance Sampling** — Importance weights, Effective Sample Size (ESS), Annealed IS.

<br>

### Section IV: Discrete Mathematics & Algorithms (9 Pages)
**URL**: [Mathematics/Discrete/discrete_math.html](https://math-cs-compass.com/Mathematics/Discrete/discrete_math.html)
**Tagline**: The Mathematics of Logic and Finite Structures

**Graph Theory & Combinatorics**
- **Part 1: Intro to Graph Theory** — Directed/undirected graphs, adjacency, isomorphism, subgraphs.
- **Part 8: Eulerian & Hamiltonian** — Graph traversal algorithms, cycles, paths, complexity contrast.
- **Part 2: Intro to Combinatorics** — Counting principles, combinations, binomial/multinomial coefficients.

**Logic & Computation**
- **Part 4: Boolean Logic** — Logical operations (AND/OR/XOR/NAND), functional completeness, logic gates.
- **Part 3: Intro to Theory of Computation** — Finite automata, regular languages, NFA/DFA, regular expressions.
- **Part 5: Context-Free Languages** — Context-Free Grammars (CFG), Pushdown Automata (PDA), pumping lemmas.
- **Part 6: Turing Machines** — Universal models of computation, decidability, Church-Turing thesis.
- **Part 7: Time Complexity** — Big-O/Little-o notation, asymptotic analysis, polynomial time (Class P).
- **Part 9: Class NP** — P vs NP, NP-Completeness, polynomial verifiability, polynomial-time reductions.

<br>

### Section V: Machine Learning (12 Pages)
**URL**: [Mathematics/Machine_learning/ml.html](https://math-cs-compass.com/Mathematics/Machine_learning/ml.html)
**Tagline**: The Mathematics of Synthesis and Intelligence

**ML Foundations & Unsupervised Learning**
- **Part 1: Intro to Machine Learning** — Supervised/unsupervised paradigms, regression vs classification.
- **Part 2: Regularized Regression** — Ridge/Lasso regression, bias-variance tradeoff, cross-validation.
- **Part 3: Intro to Classification** — Logistic regression, decision boundaries, the kernel trick.
- **Part 6: Support Vector Machine (SVM)** — Maximum margin classifiers, soft constraints, KKT conditions.
- **Part 7: PCA & Autoencoders** — Dimensionality reduction, Kernel PCA, double centering, manifold learning.
- **Part 8: Clustering** — K-means, K-means++, vector quantization, spectral clustering, Dirichlet energy.

**Deep Learning & Physical AI**
- **Part 4: Neural Networks Basics** — MLPs, activation functions (ReLU), vanishing/exploding gradients.
- **Part 5: Automatic Differentiation** — Computational graphs, forward vs reverse-mode AD.
- **Part 9: Intro to Deep Neural Networks** — CNNs, ResNets, Layer Normalization, Self-Attention, Transformers.
- **Part 10: Intro to Reinforcement Learning** — MDPs, Bellman equations, Q-Learning, Policy Gradients.
- **Part 11: Natural Gradient Descent** — Optimization on statistical manifolds, Fisher-Rao metric, K-FAC.
- **Part 12: Variational Autoencoder (VAE)** — Variational inference, ELBO, reparameterization trick, epistemic uncertainty.

---

## Key Connections (Why This Matters for AI/ML)
- **Linear Algebra → Neural Networks**: Weight matrices, SVD for compression, eigenvalues for stability.
- **Calculus → Optimization**: Gradient descent, backpropagation, Newton's method.
- **Probability → Learning**: Bayesian inference, uncertainty quantification, generative models.
- **Abstract Algebra → Symmetry**: Group equivariance, invariant networks, geometric deep learning.
- **Graph Theory → GNNs**: Message passing, spectral methods, graph transformers.
- **Metric Spaces → Embeddings**: Representation learning, contrastive learning, topology of data.

## Technical Details
- **Platform**: Jekyll static site hosted on GitHub Pages
- **Rendering**: MathJax for LaTeX equations
- **Interactive**: JavaScript/Python demos via Pyodide
- **Data**: Centralized `curriculum.json` for all content metadata
- **SEO**: Schema.org Course and LearningResource markup

## Contact & License
- **Feedback**: Contact form available on the website
- **License**: Educational content freely available for learning purposes.