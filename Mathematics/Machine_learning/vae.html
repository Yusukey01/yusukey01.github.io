---
layout: default
title: Variational Autoencoder 
topic_id: ml-12
level: detail
uses_math: true
uses_python: false
noindex: true
---
<!DOCTYPE html>
<html>
    <body>
        {% include learning_resource_schema.html topic_id=page.topic_id %}
        
        <div class="hero-section">
            <h1 class="webpage-name">Variational Autoencoder</h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#intro">Introduction</a>
            <a href="#vi">Variational Inference</a> 
            <a href="#vae">Variational Autoencoder (VAE)</a>   
            <a href="#demo">Physical AI - VAE Uncertainty in Robotic Manipulation</a>          
        </div>

        <div class="container">  

            <section id="intro" class="section-content">
                <h2>Introduction</h2>
                <p>
                    In the intersection of pure mathematics and autonomous systems lies the challenge of <strong>uncertainty</strong>. 
                    While classical robotics often relies on deterministic models, real-world interaction is inherently stochastic. 
                    Sensory noise, unobservable physical properties, and environmental variances require a framework that does not 
                    merely calculate values, but manages probabilities.
                </p>
                
                <p>
                    The <strong>Variational Autoencoder (VAE)</strong> represents a profound synthesis of information theory and 
                    Bayesian inference. Unlike standard autoencoders that map data to discrete points in a latent space, the VAE 
                    learns the underlying <strong>structural manifold</strong> of the data. By encoding inputs into a continuous 
                    latent distribution characterized by a mean (\(\mu\)) and a variance (\(\sigma\)), the VAE provides a principled 
                    way to quantify what the system knows - and, more importantly, what it does not.
                </p>
            </section>

            <section id="vi" class="section-content">
                <h2>Variational Inference</h2>
                <p>
                    Deterministic control algorithms assume a single point-estimate for the state (e.g., "the center of mass is at coordinate \((x, y, z)\)"). 
                    In contrast, <strong>Variational Inference (VI)</strong> treats the world as a probability distribution. This shift from "points" to "spreads" 
                    allows the AI to quantify its own confidence.
                </p>

                <p>
                    Since calculating the true posterior distribution is often computationally intractable, VI approximates it with a simpler distribution (usually Gaussian). 
                    This mathematical approximation is what allows "intelligence" to be computable in real-time. The robot doesn't just guess where the weight is; it understands 
                    the <strong>variance</strong> of its guess, which serves as a proxy for risk.
                </p>

            </section>

            <section id="vae" class="section-content">
                <h2>Variational Autoencoder (VAE)</h2>
                <p>
                    We create a non-linear extension of the factor analysis generative network. Replace 
                    \[
                    p(\boldsymbol{x} \mid \boldsymbol{z}) = \mathcal{N}(\boldsymbol{x} \mid \boldsymbol{Wz}, \sigm^2 \boldsymbol{I})
                    \]
                    with
                    \[
                    p_{\boldsymbol{\theta}}(\boldsymbol{x} \mid \boldsymbol{z}) = \mathcal{N}(\boldsymbol{x} \mid f_d (\boldsymbol{z}; \boldsymbol{\theta}), \, \sigma^2 \boldsymbol{I})
                    \]
                    where \(f_d\) is the decoder. 
                </p>
                <p>
                    Next, we create a <strong>recognition network (inference network)</strong>, which is trained simultaneously with the generative model 
                    to approximate posterior inference. Here, we assume the posterior is Gaussian with diagonal covariance. Then we obtain 
                    \[
                    q_{\boldsymbol{\phi}} (\boldsymbol{z} \mid \boldsymbol{x}) 
                    = \mathcal{N}(\boldsymbol{z} \mid f_{e, u} (\boldsymbol{x} ; \boldsymbol{\phi}), \, \text{diag}(f_{e, \sigma}(\boldsymbol{x};\boldsymbol{\phi})))
                    \]
                    where \(f_e\) is the encoder. 
                </p>
                <p>
                    In <strong>amortized inference</strong>, we train an inference network to “invert” a generative network rather than train 
                    an optimization algorithm to infer the latent code. 
                </p>
                <p>
                    Since posterior inference in a nonlinear FA model is intractable, instead of computing exact marginal likelihood \(p(\boldsymbol{x} \mid \boldsymbol{\theta})\), 
                    we can use the inference network to compute an approximate posterior \(p(\boldsymbol{z} \mid \boldsymbol{x})\), which is used to compute the 
                    <strong>evidence lower bound (ELBO)</strong>.
                    For a single example \(\boldsymbol{x}\), the ELBO is given by 
                    \[
                    \begin{align*}
                    &L(\boldsymbol{\theta}, \, \boldsymbol{\phi}\mid \boldsymbol{x}) \\\\\
                    &= \mathbb{E}_{q_{\phi}(\boldsymbol{z} \mid \boldsymbol{x})} \left[\log p_{\boldsymbol{\theta}}(\boldsymbol{x}, \boldsymbol{z}) - \log q_{\boldsymbol{\phi}}(\boldsymbol{z}, \boldsymbol{x}) \right]\\\\
                    &= \mathbb{E}_{q (\boldsymbol{z} \mid \boldsymbol{x}, \boldsymbol{\phi})} \left[\log p (\boldsymbol{x} \mid \boldsymbol{z}, \boldsymbol{\theta})\right]
                        - D_{\mathbb{KL}}(q (\boldsymbol{z} \mid \boldsymbol{x}, \boldsymbol{\phi}) \| p(\boldsymbol{z})).
                    \end{align*}
                    \]
                </p>
                <p>
                    ELBO is a lower bound of the log marginal likelihood (or evidence) as can be seen from Jensen's inequality 
                    \[
                    \begin{align*}
                    L(\boldsymbol{\theta}, \, \boldsymbol{\phi}\mid \boldsymbol{x})
                    &= \int q_{\phi}(\boldsymbol{z} \mid \boldsymbol{x}) \log \frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}, \boldsymbol{x})}{q_{\boldsymbol{\phi}}(\boldsymbol{z}, \boldsymbol{x})}\, d\boldsymbol{z} \\\\
                    &\leq \log \int q_{\phi}(\boldsymbol{z} \mid \boldsymbol{x}) \frac{p_{\boldsymbol{\theta}}(\boldsymbol{x}, \boldsymbol{x})}{q_{\boldsymbol{\phi}}(\boldsymbol{z}, \boldsymbol{x})}\, d\boldsymbol{z} \\\\
                    &= \log p_{\boldsymbol{\theta}}(\boldsymbol{x}).
                    \end{align*}
                    \]
                    So, for fixed inference network parameters \(\boldsymbol{\phi}\), increasing the ELBO implies incresing the 
                    log likelihood of the data. 
                </p>
            </section>
            


            <section id="demo" class="section-content">
                <h2>Physical AI - VAE Uncertainty in Robotic Manipulation</h2>

                <h3>Overview</h3>
                <p>
                    This simulation demonstrates how a <strong>Variational Autoencoder (VAE)</strong> can be used as a real-time safety monitor during 
                    robotic manipulation. A 2-link planar arm attempts to lift a box with an off-center mass. The VAE's posterior distribution 
                    \(q(\mathbf{z} \mid \mathbf{x})\) encodes the robot's internal uncertainty about the physical state of the grasp. When this uncertainty exceeds a 
                    learned threshold, the system aborts the lift to prevent a catastrophic drop.
                </p>

                <h3>The Physical Setup</h3>
                <p>
                    The robot is a <strong>3-DOF articulated arm</strong>. While its spatial positioning is achieved via a rotating base and two revolute joints, 
                    its reaching kinematics are governed by two primary links with lengths \(L_1 = 24\) and \(L_2 = 22\). The end-effector pose is 
                    calculated through <strong>analytic inverse kinematics</strong> that maps 3D target coordinates \((x, y, z)\) to the arm's joint angles.
                </p>
                
                <p>
                    A rigid box of adjustable mass \(m\) sits on the ground plane. Its <strong>center of mass (CoM)</strong> 
                    is offset from its geometric center by a user-controlled displacement \(\mathbf{c} = (c_x, c_y, c_z)\). 
                    This offset serves as the primary source of <strong>epistemic uncertainty</strong>: the robot 
                    cannot directly observe the true CoM location and must infer the resulting torque anomalies 
                    from sensor feedback during the initial lift phase.
                </p>

                <h3>Torque as Sensory Input</h3>
                <p>
                    Once the gripper secures the box and begins to lift, gravity acting on the offset CoM produces a <strong>torque</strong> about 
                    the grip point:
                </p>
                <p>
                    \[
                    \boldsymbol{\tau} = (\mathbf{r}_{\text{CoM}} - \mathbf{r}_{\text{grip}}) \times (-mg\,\hat{\mathbf{y}})
                    \]
                </p>
                <p>
                    where \(\mathbf{r}_{\text{CoM}}\) is the world-space CoM position and \(\mathbf{r}_{\text{grip}}\) is the grip point. 
                    This torque is the robot's primary sensory signal - it reveals how much the CoM deviates from the grip axis. 
                    The torque vector is displayed as a green arrow on the box during the lift.
                </p>

                <h3>Rotational Dynamics</h3>
                <p>
                    The torque drives the box's rotational dynamics via the damped Euler equation:
                </p>
                <p>
                    \[
                    I\,\dot{\boldsymbol{\omega}} = \boldsymbol{\tau} - C_d\,\boldsymbol{\omega}
                    \]
                </p>
                <p>
                    where \(I\) is the moment of inertia, \(\boldsymbol{\omega}\) is the angular velocity, and \(C_d\) is the damping coefficient. 
                    This produces the visible tilt of the box during lifting. Higher mass or larger CoM offset leads to larger torques, faster rotation, 
                    and more pronounced tilt - all signals that feed into the VAE.
                </p>

                <h3>VAE Posterior: \(q(\mathbf{z} \mid \mathbf{x})\)</h3>
                <p>
                    The sensory input \(\mathbf{x}\) (here, the torque feedback) is encoded into a 2D latent space \(\mathbf{z} = (z_1, z_2)\) via a 
                    diagonal Gaussian posterior:
                </p>
                <p>
                    \[
                     q(\mathbf{z} \mid \mathbf{x}) = \mathcal{N}(\mathbf{z};\; \boldsymbol{\mu}(\mathbf{x}),\; \sigma(\mathbf{x})^2 \mathbf{I})
                    \]
                </p>
                <p>
                    The encoder maps torque to the posterior parameters as follows:
                </p>
                <ul style="padding-left: 40px;">
                    <li>\(\boldsymbol{\mu} = (0.07\,\tau_x,\; 0.07\,\tau_z)\) - the posterior mean shifts proportionally to the horizontal torque components</li>
                    <li>\(\sigma = 0.011\,\|\boldsymbol{\tau}\|\) - the posterior spread grows with the torque magnitude</li>
                </ul>
                <p>
                    The key insight is that <strong>\(\sigma\) encodes uncertainty</strong>. 
                    When the torque is small (CoM near grip axis), \(\sigma\) is small and the robot is confident in its grasp. 
                    When the torque is large (CoM far off-center), \(\sigma\) grows, reflecting the robot's increasing uncertainty 
                    about whether the grasp is stable enough to complete the lift.
                </p>

                <h3>The Latent Space Visualization</h3>
                <p>
                    The top-right canvas shows the 2D latent space in real time:
                </p>
                <ul style="padding-left: 40px;">
                    <li><strong style="color:#64b4ff;">Blue dot</strong> at the origin - the prior \(p(\mathbf{z}) = \mathcal{N}(\mathbf{0}, \mathbf{I})\)</li>
                    <li><strong style="color:#ff9800;">Orange dot</strong> - the posterior mean \(\boldsymbol{\mu}\), which drifts as torque changes</li>
                    <li><strong style="color:#ff9800;">Orange circle</strong> - the 1 \(\sigma\)  contour of the posterior distribution</li>
                    <li><strong style="color:#ffa726;">Orange scatter points</strong> - stochastic samples \(\mathbf{z}^{(i)} \sim q(\mathbf{z} \mid \mathbf{x})\), visualized as ghost arms in 3D</li>
                    <li><strong style="color:#ff5252;">Red dashed circle</strong> - the abort threshold on \(\sigma\) </li>
                </ul>
                <p>
                    The display uses <strong>dynamic scaling</strong>: both the \(\sigma\)  circle and the threshold circle always fit 
                    within the canvas, preserving their true ratio. When the lift fails, the orange circle is visibly larger than the 
                    red circle, making the safety violation immediately apparent.
                </p>

                <h3>KL Divergence</h3>
                <p>
                    The telemetry panel also reports the KL divergence between the posterior and prior:
                </p>
                <p>
                    \[
                    D_{\mathrm{KL}}\!\left[\,q(\mathbf{z} \mid \mathbf{x})\;\|\;p(\mathbf{z})\,\right]
                     = \frac{1}{2}\!\left(\|\boldsymbol{\mu}\|^2 + 2\sigma^2 - 2\ln\sigma^2 - 2\right)
                    \]
                </p>
                <p>
                    This quantity measures how far the posterior has diverged from the prior. A large KL divergence indicates that the 
                    sensory feedback has pushed the robot's internal representation far from its initial beliefs - a sign of an unusual 
                    or difficult grasp configuration.
                </p>

                <h3>Ghost Arms: Sampling Uncertainty</h3>
                <p>
                    The five semi-transparent <strong>ghost arms</strong> visualize samples from the posterior. Each ghost arm \(i\) receives a 
                    perturbed end-effector target:
                </p>
                <p>
                    \[
                    \mathbf{t}^{(i)} = \mathbf{t}_{\text{primary}} + \boldsymbol{\mu} \cdot s_{\mu} + \sigma \cdot \boldsymbol{\epsilon}^{(i)} \cdot s_{\sigma}
                    \]
                </p>
                <p>
                    where \(\boldsymbol{\epsilon}^{(i)} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\) are smoothed Gaussian samples 
                    (using exponential moving average with \(\alpha = 0.92\) for visual stability). When \(\sigma\) is small, the ghosts cluster 
                    tightly around the primary arm. When \(\sigma\) is large, they splay outward, creating a visual "cloud of possible robot states" 
                    that communicates the degree of uncertainty.
                </p>

                <h3>The Safety Decision</h3>
                <p>
                    The lift sequence proceeds through a state machine:
                </p>
                <ol style="padding-left: 40px;">
                    <li><strong>APPROACH</strong> &rarr; Arm moves from home to hover above the box</li>
                    <li><strong>DESCEND</strong> &rarr; Arm lowers to grasp height</li>
                    <li><strong>GRASP</strong> &rarr; Fingers close on the box</li>
                    <li><strong>PRE_LIFT</strong> &rarr; Small test lift (5 units). During this phase, the system assesses \(\sigma\) for 0.5 seconds. If \(\sigma > \sigma_{\text{thr}}\), the lift is aborted immediately.</li>
                    <li><strong>LIFT_OK</strong> &rarr; Full lift if \(\sigma\) stayed below threshold. Continuous safety monitoring continues; an abort can still trigger if \(\sigma\) spikes during the lift.</li>
                    <li><strong>ABORT</strong> &rarr; Three-phase emergency: lower the box, release grip, return home.</li>
                </ol>
                <p>
                    The critical decision is the comparison \(\sigma \lessgtr \sigma_{\text{thr}}\). This is a direct analogy to how real-world 
                    autonomous systems use learned uncertainty estimates for <strong>out-of-distribution detection</strong>: if the VAE posterior 
                    is too diffuse, the current observation lies far from the training distribution, and the robot should not trust its control policy.
                </p>

                <h3>What the Parameters Control</h3>
                <p>
                    <strong>CoM Offset</strong> \((c_x, c_y, c_z)\): Shifts the center of mass away from the box's 
                    geometric center. Larger offsets produce larger torques, higher \(\sigma\) and a higher likelihood of abort. This simulates 
                    real-world scenarios where the load distribution inside a package is unknown.
                </p>
                <p>
                    <strong>Box Mass</strong>: Scales the gravitational force \(mg\), amplifying the torque for a given CoM offset. Heavy objects 
                    are harder to lift safely.
                </p>
                <p>
                    <strong>\(\sigma\) Threshold</strong>: The abort boundary. Lowering it makes the robot more cautious (aborting earlier); 
                    raising it makes the robot more risk-tolerant. This models the engineering trade-off between safety and task completion 
                    in autonomous systems.
                </p>
                <p>
                    <strong>Damping</strong> \(C_d\): Controls how quickly the box's rotational oscillation decays. High damping suppresses 
                    wobble; low damping allows the box to swing more freely, producing a more dynamic and potentially uncertain lift.
                </p>

                <h3>Key Takeaways</h3>
                <p>
                    This demo illustrates three interconnected ideas from modern physical AI:
                </p>
                <p>
                    <strong>1. Uncertainty quantification through latent representations:</strong><br>
                    The VAE does not output a single point estimate of the physical state - it outputs a <em>distribution</em>. 
                    The spread of this distribution (\(\sigma\)) is a principled measure of epistemic uncertainty derived from sensory feedback.
                </p>
                <p>
                    <strong>2. Safety-critical decision-making under uncertainty:</strong><br>
                    Rather than blindly executing a motion plan, the robot uses its uncertainty estimate as a gating signal. When \(\sigma\) exceeds 
                    the threshold, the system recognizes that it is operating outside its confident regime and aborts. This is directly analogous to 
                    uncertainty-aware reinforcement learning and Bayesian safe control.
                </p>
                <p>
                    <strong>3. The connection between physics and information:</strong><br>
                    The torque - a purely physical quantity governed by Newton's laws - becomes the input to a probabilistic inference engine. 
                    The KL divergence between posterior and prior quantifies how much information the robot has gained (or how surprised it is) 
                    from the physical interaction. Large KL divergence means the physical situation deviates significantly from the robot's expectations.
                </p>
                
                <div id="simulation-container"></div>

            </section>

        </div>

        <script src="/js/main.js"></script> 
        <script src="/js/sec5_p12_vae_uncertainty.js"></script>

    </body>
</html>



