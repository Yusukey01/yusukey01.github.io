---
layout: default
title: Intro to Machine Learning 
topic_id: ml-1
level: detail
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body> 
        {% include learning_resource_schema.html topic_id=page.topic_id %}
        
        <div class="hero-section">
            <h1 class="webpage-name">Intro to Machine Learning 
            </h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#intro">The Law of Intelligence</a>
            <a href="#sup">Supervised vs Unsupervised</a>
            <a href="#basic">Basic Categories of ML</a>
            <a href="#process">Standard Process of ML</a>
        </div> 

        <div class="container">  
            <section id="intro" class="section-content">
                <h2>The Law of Intelligence</h2>

                <p>
                    <strong>Artificial intelligence (AI)</strong> has become one of the most influential technologies of our time, powering 
                    applications from search engines to self-driving cars. Before diving into its technical details, it is worth stepping back 
                    and asking: what is <strong>intelligence</strong> itself, and what does it mean to replicate it artificially?
                </p>

                <p>
                    Consider an analogy from physics. The laws of motion and aerodynamics govern both natural and human-made flight. 
                    We accept without hesitation that birds can fly through the air, and we trust airplanes to carry us safely across continents. 
                    This shared trust comes from our understanding of the same physical principles that explain both. Similarly, if we could uncover 
                    the fundamental laws of intelligence, we might someday build machines that "think" with the same confidence we have in machines 
                    that fly.
                </p>

                <p>
                    Creating a truly intelligent system - one that rivals the flexibility and generality of the human mind - remains an 
                    open scientific challenge. Nevertheless, we do have guiding principles. Modern approaches to AI are built on frameworks like 
                    <a href="../Probability/bayesian.html"><strong>Bayesian decision theory</strong></a> 
                    and <a href="../Probability/entropy.html"><strong>information processing</strong></a>. These form the theoretical foundation 
                    for <strong>machine learning (ML)</strong>, a subfield of artificial intelligence that focuses on developing algorithms 
                    enabling computers to learn from data and improve their performance on specific tasks over time.
                </p>

                <p>
                    A widely cited formal definition comes from computer scientist Tom M. Mitchell:
                </p>

                <blockquote>
                    <p>
                        <strong>A computer program is said to learn from experience \(E\), with respect to some class of tasks \(T\) and 
                        performance measure \(P\), if its performance at tasks in \(T\), as measured by \(P\), improves with experience \(E\).</strong>
                        <small>(T. Mitchell, <em>Machine Learning</em>, McGraw Hill, 1997)</small>
                    </p>
                </blockquote>  

                <p>
                    Mathematically, this definition encapsulates the core loop of machine learning: 
                </p>

                <div class="theorem">
                    <span class="theorem-title">Defintion: Learning</span>
                    <p>
                        Given a <strong>hypothesis space</strong> \(\mathcal{H}\) of candidate models, an <strong>objective function</strong> 
                        \(J(\theta)\) measuring prediction quality, and a <strong>dataset</strong> \(\mathcal{D} = \{(x_i, y_i)\}_{i=1}^{N}\), 
                        the learner seeks parameters \(\theta^*\) that optimize \(J\):
                        \[
                        \theta^* = \arg\min_{\theta \in \Theta} \; J(\theta; \mathcal{D}).
                        \]
                    </p>
                </div>

                <p>
                    Every component of this formulation draws on earlier sections: the parameter space \(\Theta\) lives in a 
                    <a href="../Linear_algebra/vectorspaces.html"><strong>vector space</strong></a>, 
                    the optimization is driven by <a href="../Calculus/gradient.html"><strong>gradient-based methods</strong></a>, 
                    the objective often involves a <a href="../Probability/mle.html"><strong>likelihood or posterior</strong></a>, 
                    and the algorithmic procedure has a well-defined 
                    <a href="../Discrete/time_complexity.html"><strong>computational complexity</strong></a>.
                </p>

                <p>
                    One branch of machine learning, called <a href="deep_nn.html"><strong>deep learning</strong></a>, utilizes large 
                    <a href="neural_networks.html"><strong>neural networks</strong></a> to perform complex tasks such as:   
                    <ul style="padding-left: 40px;">
                      <li><strong>Autonomous vehicles</strong>: Self-driving cars and drones leverage deep learning to interpret sensor data, navigate environments, and make real-time decisions.</li>
                      <li><strong>Medical diagnostics</strong>: Deep learning models analyze medical images and patient data to detect diseases such as cancer and heart conditions, enabling early diagnosis and personalized treatment.</li>
                      <li><strong>Scientific discovery</strong>: AI accelerates research in fields like materials science and genomics by predicting molecular structures, leading to breakthroughs in drug development.</li>
                    </ul>
                </p>

                <p>
                    One of the most impactful applications of deep learning today is the development of <strong>Large Language Models (LLMs)</strong>. 
                    These models are built using deep neural networks - specifically the <a href="deep_nn.html#transformer"><strong>transformer</strong></a> architecture - and 
                    are trained on massive text datasets. LLMs have demonstrated remarkable capabilities in language understanding, text generation, translation, 
                    and even <strong>reasoning</strong>.
                </p>

                <p>
                    Beyond digital text processing, modern AI is increasingly extending into <strong>Physical AI</strong> and autonomous systems. While classical robotics often 
                    relies on deterministic models, real-world interaction is inherently stochastic. Modern frameworks must go beyond calculating point-estimates; they must 
                    quantify <strong>epistemic uncertainty</strong>. By treating system states as probability distributions, an AI can rigorously measure its own uncertainty, 
                    establishing a mathematical foundation for real-time safety and risk management.
                </p>

                <p>
                    With this broad motivation in hand, we now turn to the fundamental distinction that organizes the field: 
                    the difference between <strong>supervised</strong> and <strong>unsupervised</strong> learning.
                </p>

            </section>

            <section id="sup" class="section-content">
                <h2>Supervised vs Unsupervised</h2>

                <p>
                    Machine learning encompasses various approaches, primarily distinguished by the presence or absence of 
                    <strong>labeled data</strong>. This distinction determines the mathematical formulation of the 
                    learning problem.
                </p>

                <p>
                    <ul style="padding-left: 40px;">
                        <li><strong>Supervised Learning:</strong><br>
                            The model is trained on a labeled dataset \(\mathcal{D} = \{(x_i, y_i)\}_{i=1}^{N}\), where each input 
                            \(x_i \in \mathbb{R}^D\) is paired with an output label \(y_i\). The goal is to learn a mapping 
                            \(f: \mathbb{R}^D \to \mathcal{Y}\) that generalizes well to unseen data. From a probabilistic perspective, 
                            we model the conditional distribution \(p(y \mid x; \theta)\) and optimize parameters via 
                            <a href="../Probability/mle.html"><strong>maximum likelihood</strong></a> or 
                            <a href="../Probability/bayesian.html"><strong>Bayesian inference</strong></a>. 
                            Common applications include image classification, spam detection, and medical diagnosis.
                        </li>

                            <li><strong>Unsupervised Learning:</strong><br>
                            Here the dataset consists only of inputs \(\mathcal{D} = \{x_i\}_{i=1}^{N}\) with no target labels. 
                            The model attempts to uncover hidden patterns or intrinsic structures — for instance, by modeling the 
                            data-generating distribution \(p(x; \theta)\) or by discovering a low-dimensional 
                            <a href="pca.html"><strong>latent representation</strong></a>. 
                            Techniques like <a href="clustering.html"><strong>clustering</strong></a> and dimensionality reduction fall under this category, with applications in 
                            customer segmentation, anomaly detection, and exploratory data analysis.
                        </li>
                    </ul>          
                </p>

                <p>
                    Beyond these two core paradigms, modern machine learning has introduced hybrid approaches:
                    <ul style="padding-left: 40px;">
                        <li><strong>Semi-Supervised Learning:</strong><br>
                            Combines a small amount of labeled data with a large amount of unlabeled data during training. This method is 
                            particularly useful when labeling data is expensive or time-consuming, and it leverages the geometric structure 
                            of the unlabeled data to improve generalization.
                        </li>
                        
                        <li><strong>Self-Supervised Learning:</strong><br>
                            A form of unsupervised learning where the system generates its own supervisory signal from the input data 
                            (e.g., predicting masked tokens in a sentence or reconstructing missing image patches). This approach 
                            has become central to training large language models and modern computer vision systems.
                        </li>

                        <li><a href="intro_RL.html"><strong>Reinforcement Learning:</strong></a><br>
                            Rather than learning from a fixed dataset, an agent interacts with an environment and receives scalar reward signals. 
                            The objective is to learn a policy that maximizes expected cumulative reward - a fundamentally different formulation 
                            from supervised or unsupervised learning. In modern physical systems, this formulation increasingly incorporates 
                            <strong>uncertainty-aware</strong> constraints, ensuring safety-critical decision-making when the agent encounters 
                            out-of-distribution states.
                        </li>
                    </ul>
                </p>

                <p>
                    With these learning paradigms established, we can now classify the concrete <strong>tasks</strong> that machine learning 
                    algorithms are designed to solve.
                </p>

            </section>

            <section id="basic" class="section-content">
                <h2>Basic Categories of Machine Learning</h2>

                <p>
                    The learning paradigms above (supervised, unsupervised, reinforcement) describe <em>how</em> a model learns. 
                    Orthogonal to this is the question of <em>what</em> the model predicts. Machine learning tasks are broadly 
                    categorized based on the nature of the output space:
                </p>

                <p>
                    <ul style="padding-left: 40px;">
                        <li><strong>Regression</strong>:<br>
                            Predicts a continuous numerical value \(y \in \mathbb{R}\). The model learns a function \(f: \mathbb{R}^D \to \mathbb{R}\) 
                            that minimizes a loss such as the squared error. This is where <a href="../Linear_algebra/leastsquares.html"><strong>least-squares theory</strong></a> 
                            and <a href="../Calculus/gradient.html"><strong>gradient descent</strong></a> find their most direct application.
                        </li>
                        &nbsp;&nbsp;Examples: Forecasting stock prices, estimating real estate values, predicting temperature changes.
                        <br>
                        &nbsp;&nbsp;Methods: <a href="regression.html"><strong>Linear regression, polynomial regression, Ridge regression</strong></a>.

                        <li><strong>Classification</strong>:<br>
                            Assigns inputs into predefined discrete categories \(y \in \{1, \ldots, K\}\). The model typically outputs a probability distribution 
                            over classes via the softmax function, connecting directly to <a href="../Probability/mle.html"><strong>maximum likelihood estimation</strong></a>.
                        </li>
                        &nbsp;&nbsp;Examples: Email spam detection, handwriting recognition, disease diagnosis.
                        <br>
                        &nbsp;&nbsp;Methods: <a href="intro_classification.html"><strong>Logistic regression</strong></a>, <a href="svm.html"><strong>support vector machines</strong></a>, decision trees, and <a href="neural_networks.html"><strong>neural networks</strong></a>.

                        <li><strong>Clustering</strong>:<br>
                            Groups similar data points without predefined labels, effectively partitioning the input space into coherent regions. 
                            The notion of "similarity" relies on <a href="../Calculus/metric_space.html"><strong>distance metrics</strong></a> and the 
                            <a href="../Probability/covariance.html"><strong>covariance structure</strong></a> of the data.
                        </li>
                        &nbsp;&nbsp;Examples: Customer segmentation, document categorization, image grouping.
                        <br>
                        &nbsp;&nbsp;Methods: <a href="clustering.html"><strong>K-means clustering</strong></a>, hierarchical clustering, spectral clustering.

                        <li><strong>Dimensionality Reduction</strong>:<br>
                            Reduces the number of input variables while preserving essential information. Mathematically, this seeks a low-dimensional 
                            subspace (or manifold) that captures the dominant variation in the data, drawing on <a href="../Linear_algebra/eigenvectors.html"><strong>eigenvalue decomposition</strong></a>.
                        </li>
                        &nbsp;&nbsp;Examples: Data visualization, noise reduction, feature extraction.
                        <br>
                        &nbsp;&nbsp;Methods: <a href="pca.html"><strong>Principal Component Analysis (PCA), Kernel PCA, Autoencoders.</strong></a>

                        <li><strong>Dimensionality Reduction</strong>:<br>
                            Reduces the number of input variables while preserving essential information. Mathematically, this seeks a low-dimensional subspace 
                            (or manifold) that captures the dominant variation in the data, drawing on <a href="../Linear_algebra/eigenvectors.html"><strong>eigenvalue decomposition</strong></a>.
                        </li>
                        &nbsp;&nbsp;Examples: Data visualization, noise reduction, feature extraction.
                        <br>
                        &nbsp;&nbsp;Methods: <a href="pca.html"><strong>Principal Component Analysis (PCA), Kernel PCA, Autoencoders.</strong></a>

                        <li><strong>Generative Modeling</strong>:<br>
                            Learns the underlying data distribution to generate new, synthetic samples that share the same statistical properties as 
                            the training set. Moving beyond deterministic dimensionality reduction, approaches like the <a href="vae.html"><strong>Variational Autoencoder (VAE)</strong></a> 
                            map data to a continuous latent distribution characterized by a mean and variance. This balances data reconstruction fidelity 
                            with topological regularization via Kullback-Leibler (KL) divergence.
                        </li>
                        &nbsp;&nbsp;Examples: Image synthesis, text generation, uncertainty quantification in robotic manipulation.
                        <br>
                        &nbsp;&nbsp;Methods: <a href="vae.html"><strong>VAEs</strong></a>, Generative Adversarial Networks (GANs), Diffusion Models.

                        <li><a href="intro_RL.html"><strong>Reinforcement Learning</strong></a>:<br> 
                            An agent interacts with an environment and learns a policy \(\pi(a \mid s)\) that maximizes expected cumulative reward. Unlike the 
                            categories above, RL does not operate on a fixed dataset - the agent generates its own experience through exploration.
                        </li>
                        &nbsp;&nbsp;Examples: Robotics control, game playing, autonomous driving, LLM alignment via RLHF.
                        <br>
                        &nbsp;&nbsp;Methods: Q-Learning, Deep Q-Networks (DQN), Proximal Policy Optimization (PPO).
                    </ul>      
                </p>

                <p>
                    It is crucial to recognize that these categories are not mutually exclusive; in practice, they frequently <strong>overlap</strong>. 
                    For instance, a Variational Autoencoder (VAE) simultaneously performs non-linear <strong>dimensionality reduction</strong> and 
                    <strong>generative modeling</strong>. Modern architectures often integrate multiple paradigms to handle complex, high-dimensional data.
                </p>

                <p>
                    Each of these categories is explored in dedicated pages within this section. 
                    Regardless of the specific task, all machine learning methods share a common workflow, which we outline next.
                </p>
                
            </section>

            <section id="process" class="section-content">
                <h2>Standard Process of ML</h2>

                <p>
                    Regardless of whether we are performing regression, classification, or clustering, 
                    every machine learning project follows a common pipeline. Understanding this pipeline is important 
                    because each step introduces its own mathematical and practical considerations - from the 
                    statistical properties of the data to the convergence guarantees of the optimizer.
                </p>

                <div class="theorem">
                    <p>
                        <ol style="padding-left: 40px;">
                            <li><strong>Problem Definition:</strong><br>
                                Clearly articulate the problem and determine whether machine learning is an appropriate solution. 
                                This includes specifying the input space \(\mathcal{X}\), the output space \(\mathcal{Y}\), and the 
                                performance criterion.
                            </li>

                            <li><strong>Data Collection:</strong><br>
                                Gather relevant data from various sources, ensuring quality and representativeness. 
                                The data must be sufficiently rich to capture the underlying distribution \(p(x, y)\) 
                                that we wish to model.
                            </li>

                            <li><strong>Data Preprocessing:</strong><br>
                                Clean and prepare the data by handling missing values, encoding categorical variables, and 
                                normalizing features. Feature scaling, for example, ensures that 
                                <a href="../Calculus/gradient.html"><strong>gradient descent</strong></a> 
                                converges efficiently by improving the 
                                <a href="../Calculus/duality.html"><strong>condition number</strong></a> 
                                of the optimization landscape.
                            </li>

                            <li><strong>Data Splitting:</strong><br>
                                Divide the dataset into <strong>training</strong>, <strong>validation</strong>, and <strong>test</strong> sets. 
                                This separation is essential for estimating generalization performance and is formalized through 
                                <a href="regression.html"><strong>cross-validation</strong></a> techniques.
                            </li>

                            <li><strong>Model and Optimization Procedure Selection:</strong><br>
                                Choose a hypothesis class \(\mathcal{H}\) and an optimization algorithm based on the problem type and 
                                data characteristics. This step involves the fundamental 
                                <a href="regression.html"><strong>bias-variance tradeoff</strong></a>: 
                                a more expressive model can fit the training data better (lower bias) but may generalize poorly (higher variance).
                            </li>

                            <li><strong>Training:</strong><br>
                                Optimize the model parameters \(\theta\) by minimizing the empirical loss on the training set. 
                                For <a href="neural_networks.html"><strong>neural networks</strong></a>, this involves 
                                <a href="autodiff.html"><strong>backpropagation</strong></a> - an efficient application of the 
                                chain rule — combined with stochastic gradient descent or its variants.
                            </li>

                            <li><strong>Evaluation:</strong><br>
                                Assess the model's performance using the validation set and appropriate metrics (e.g., accuracy, precision, recall).
                                For regression, common choices are mean squared error.
                            </li>

                            <li><strong>Hyperparameter Tuning:</strong><br>
                                Optimize hyperparameters (e.g., 
                                <a href="regression.html"><strong>regularization strength \(\lambda\)</strong></a>, 
                                learning rate, network depth) using grid search, random search, or Bayesian optimization.
                            </li>

                            <li><strong>Testing:</strong><br>
                                Evaluate the final model on the held-out test set to obtain an unbiased estimate of generalization performance. 
                                This test set must remain untouched until this stage to preserve statistical validity.
                            </li>
                            
                            <li><strong>Deployment and Monitoring:</strong><br>
                                Integrate the model into a production environment. In practice, the data distribution may shift over time (<strong>distribution shift</strong>), 
                                requiring continuous monitoring and periodic retraining. For safety-critical systems, this phase relies heavily on <strong>out-of-distribution detection</strong>: 
                                if a model's estimated epistemic uncertainty exceeds a learned threshold, the system recognizes it is operating outside its confident regime and can trigger 
                                immediate safety aborts.
                            </li>
                            
                            <li><strong>Deployment and Monitoring:</strong><br>
                                Integrate the model into a production environment. In practice, the data distribution may shift over time 
                                (<strong>distribution shift</strong>), requiring continuous monitoring and periodic retraining.
                            </li>
                        </ol>   
                    </p>
                </div>

                <p>
                    The ML pipeline is a concrete synthesis of every section in this website. 
                    <strong>Data representation</strong> relies on 
                    <a href="../Linear_algebra/linear_algebra.html"><strong>Linear Algebra to Algebraic Foundations (Section I)</strong></a> -
                    each data point is a vector, each dataset is a matrix, and transformations like PCA are eigenvalue problems. 
                    <strong>Optimization</strong> is governed by <a href="../Calculus/calculus.html"><strong>Calculus to Optimization & Analysis (Section II)</strong></a> -
                    gradient descent, convexity, and convergence rates determine whether training succeeds. 
                    <strong>Generalization</strong> is a question of <a href="../Probability/probability.html"><strong>Probability & Statistics (Section III)</strong></a> -
                    from the bias-variance trade-off to the law of large numbers justifying empirical risk minimization. 
                    Finally, the <strong>computational feasibility</strong> of each algorithm depends on 
                    <a href="../Discrete/discrete_math.html"><strong>Discrete Mathematics & Algorithms (Section IV)</strong></a>. 
                    In the pages that follow, we explore each of these connections in depth.
                </p>

            </section>

        </div>
        <script src="/js/main.js"></script> 
    </body>
</html>