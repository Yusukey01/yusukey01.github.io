---
layout: default
title: Classification
level: detail
description: Learn about classification methods such as logistic regression.
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body> 
        <div class="hero-section">
            <h1 class="webpage-name"> Classification</h1>
        </div>

        <div class="topic-nav">
            <a href="#intro">Logistic Regression</a>
            <a href="#demo">Binary Logistic Regression Demo</a>
            <a href="#"></a>
            <a href="#"></a>
            <a href="#"></a>
        </div> 

        <div class="container">  
            <section id="intro" class="section-content">
                <h2>Binary Logistic Regression</h2>
                <p>
                    Consider discriminative <strong>classification</strong> model: 
                    \[
                    p(y \mid x, \theta)  
                    \]
                    where \(x \in \mathbb{R}^D\) is an input vector, \(y \in \{1, \cdots, C\}\) is the class label, 
                    and \(\theta\) are the parameters.
                </p>

                <p>
                    When \(C = 2\), it is known as <strong>binary logistic regression</strong>. The mode can be represented by: 
                    \[
                     p(y \mid x, \theta) = \text{Ber }(y \mid \sigma(w^\top x + b))
                    \]
                    where \(\sigma\) is the <strong>sigmoid(logistic) function</strong>, \(w\) are the weights, \(b\) is a bias, 
                    and \(\theta = (w, b)\) are all the parameters. 
                </p>
                <p>
                    Thus, 
                    \[
                    p(y = 1 \mid x, \theta) = \sigma(a) = \frac{1}{1 + e^{-a}}
                    \]
                    where \(a\) is called the <strong>logit</strong>(or the <strong>pre-activation</strong>): 
                    \[
                     a = w^\top x + b = \log (\frac{p}{1-p}), \quad p = p(y = 1 \mid x, \theta).
                    \]
                </p>

                <p>
                    Note: Often instead of \(y \in \{0, 1\}\), we use the labels \(\tilde{y} \in \{-1, 1\}\). In this case, 
                    \[
                    \sigma(-a) = 1 - \sigma(a)
                    \]
                    and then: 
                    \[
                    p(\tilde{y} \mid x, \theta) = \sigma(\tilde{y}a).
                    \]
                </p>
                    <a href="../Probability/.html"><strong></strong></a>
                    <a href="../Probability/.html"><strong></strong></a>. 
                    <a href="../Probability/.html"><strong></strong></a>. 
                    
                </p>
                   
                
            <section id="" class="section-content">
                <h2></h2>

            </section>

             <section id="demo" class="section-content">
                <h2>Binary Logistic Regression Demo</h2>
                <div id="logistic_regression_visualizer"></div>

            </section>

             <section id="" class="section-content">
                <h2></h2>

            </section>
            
        </div>
        <script src="/js/main.js"></script> 
        <script src="/js/logistic_regression.js"></script>
    </body>
</html>