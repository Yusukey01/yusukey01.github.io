<!DOCTYPE html>
<html>
    <head> 
        <title>Linear Algebra</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Linear Algebra</h1>
        <blockquote>
            <p style="text-indent: 40px;">
             <strong>Linear Algebra</strong> is one of the most foundational areas of modern mathematics, widely valued 
            by scientists and engineers for its diverse and powerful applications. Rather than focusing solely on manual computations—something 
            that first-time learners may emphasize, as they often have in other math classes—linear algebra encourages a deep 
            understanding of concepts and structures. While solving problems by hand is a useful exercise, large-scale computations are 
            typically handled by computers. This conceptual approach is crucial for leveraging linear algebra in both practical applications 
            and theoretical explorations. Moreover, linear algebra serves as a gateway to modern algebra, also known as <strong>abstract algebra</strong>, which provides 
            a "common language" across various branches of mathematics. For enthusiasts of pure mathematics, studying linear algebra offers 
            an excellent introduction to the broader world of contemporary mathematical thought.
            </p>
        </blockquote>
        <section>
            <h2><a href="linear_equations.html"><strong>Part 1: Linear Equations</strong></a></h2>
                    
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>System of linear equations</span>
                    <span>Reduced row echelon form</span>
                    <span>Linear combination</span>
                    <span>Span</span>
                    <span>Matrix equation</span>
                    <span>Homogeneous & nonhomogeneous system</span>
                    <span>Linear independence & dependence</span>
                    <span>Parametric vector form</span>
                </div>
            <h2><a href="linear_transformation.html"><strong>Part 2: Linear Transformation</strong></a></h2> 
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Linear transformation</span>
                    <span>Linearity</span>
                    <span>Onto</span>
                    <span>One-to-one</span>
                    <span>Matrix multiplication</span>
                </div>
                    
            <h2><a href="matrix_algebra.html"><strong>Part 3: Matrix Algebra</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Diagonal matrix</span>
                    <span>Identity matrix</span>
                    <span>Transpose of a matrix</span>
                    <span>Invertible matrix</span>
                    <span>Singular matrix</span>
                    <span>Elementary matrix</span>
                    <span>Partitioned Matrix</span>
                    <span>LU Factorization</span>
                </div>
                    

            <h2><a href="determinants.html"><strong>Part 4: Determinant</strong></a></h2>         
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Determinant</span>
                    <span>Cofactor expansion</span>
                    <span>Cramer's rule</span>
                    <span>Adjugate</span>
                    <span>Inverse formula</span>
                    <span>Invertible matrix </span>
                </div>
                
            <h2><a href="vectorspaces.html"><strong>Part 5: Vector Spaces</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Vector space</span>
                    <span>Subspace</span>
                    <span>Null space</span>
                    <span>Kernel</span>
                    <span>Column space</span>
                    <span>Row space</span>
                    <span>Basis</span>
                    <span>Spanning set</span>
                    <span>Coordinate systems</span>
                    <span>Dimention</span>
                    <span>Rank</span>
                </div>
                
            <h2><a href="eigenvectors.html"><strong>Part 6: Eigenvalues & Eigenvectors </strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Eigenvalues</span>
                    <span>Eigenvectors</span>
                    <span>Eigenspace</span>
                    <span>Characteristic equation</span>
                    <span>Similarity</span>
                    <span>Diagonalization</span>
                    <span>Complex eigenvalues & eigenvectors</span>
                </div>
                
            <h2><a href="orthogonality.html"><strong>Part 7: Orthogonality </strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Inner product</span>
                    <span>Euclidean norm</span>
                    <span>Orthogonality</span>
                    <span>Orthogonal complement</span>
                    <span>Orthogonal & Orthonormal set</span>
                    <span>Orthogonal projection(decomposition)</span>
                    <span>Orthogonal matrix</span>
                    <span>Gram-Schmidt algorithm</span>
                    <span>QR factorization </span>
                </div>
            
            <h2><a href="leastsquares.html"><strong>Part 8: Least-Squares Problems </strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Least-squares solution</span>
                    <span>Normal equation</span>
                    <span>Least-squares Error</span>
                    <span>Linear regression</span>
                </div>
            
            <h2><a href="symmetry.html"><strong>Part 9: Symmetry</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Symmetric matrix</span>
                    <span>Orthogonally diagonalizable matrix</span>
                    <span>Spectrum</span>
                    <span>Quadratic form</span>
                    <span>Singular value decomposition(SVD)</span>
                </div>
            
            <h2><a href="trace.html"><strong>Part 10: Trace and Norms</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Trace</span>
                    <span>Frobenius norm</span>
                    <span>Nuclear norm(Trace norm)</span>
                    <span>Induced norm</span>
                    <span>Spectral norm</span>
                    <span>p-norm</span>
                    <span>Manhattan norm</span>
                    <span>Maximum norn</span>
                    <span>Normalization</span>
                    <span>Regularization</span>
                    <span>Metric space</span>
                    <span>Normed vector space</span>
                    <span>Inner product space</span>
                    <span>Euclidean space</span>
                </div>

                <h2><a href="kronecker.html"><strong>Part 11: Kronecker Product & Tensor</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Vectorization</span>
                    <span>Kronecker product</span>
                    <span>Tensor</span>
                    <span>Tensor Product</span>
                </div>

                <h2><a href="woodbury.html"><strong>Part 12: Woodbury Matrix Identity</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Woodbury matrix identity</span>
                    <span>Sherman-Morrison formula</span>
                </div>

                <h2><a href="stochastic.html"><strong>Part 13: Stochastic Matrix</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Stochastic Matrix</span>
                    <span>Column-stochastic Matrix</span>
                    <span>Row-stochastic Matrix</span>
                    <span>Probability Vector</span>
                    <span>Markov Chain</span>
                    <span>Steady-state Vector</span>
                    <span>Spectral Radius</span>
                    <span>Doubly Stochastic Matrix</span>
                </div>
        </section>
        <br>
        <a href="../../index.html">Back to Home </a>
    </body>
</html>