<!DOCTYPE html>
<html>
    <head> 
        <title>Stochastic Matrix</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css"> 
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Stochastic Matrix</h1>
        <blockquote>
            A <strong>probability vector</strong> \(x \in \mathbb{R}^n\) is a vetor with nonnegative entries that add up 
            to 1, and A <strong>stochastic matrix</strong>(or <strong>transition matrix</strong>) \(P \in \mathbb{R}^{n \times n}\) is 
            a square matrix whose "columns" are probability vectors. 
            <br><br>
            Note: In this page, we will use the <strong>column-stochastic matrix</strong>, but we can also use the 
            <strong>row-stochastic matrix</strong>. Essentially, the choice between a row-stochastic and a column-stochastic 
            matrix is a matter of convention and convenience, and both formulations are equivalent up to taking a transpose. 
            Using the row-stochastic matrix is often natural in Markov chains because each row directly tells 
            you the probabilities of transitioning from a given state to all other states. In linear algebra context, due to 
            the form of \(Ax = b\), the column-stochastic matrix can be chosen more often. (Also, many programming environments 
            default to column vectors.)
            <br><br>
            A <a href="../Probability/markov.html"><strong>Markov chain</strong></a> is a sequence of probability 
            vectors \(x_0, x_1, x_2, \cdots \) together with a stochastic matrix \(P\) 
            such that 
            \[
            x_1 = P x_0, \quad x_2 = P x_1, \quad x_3 = P x_2, \quad \cdots.
            \]
            So, the Markov chain is explained by the first-order difference equation:
            \[
            x_{k+1} = P x_k \quad \text{for } k = 0, 1, 2, \cdots.
            \]
            Here, \(x_k\) is called a <strong>state vector</strong> and we have:
            \[
            x_k = P^k x_0  \quad \text{for } k = 0, 1, 2, \cdots.
            \]

            <div class="proof">
                <span class="proof-title">Example: </span>
                Consider the following two states:
                <ul>
                    <li> State 1: a student is sick</li>
                    <li> State 2: a student is not sick</li>
                </ul>
                We obserbed an initial state distribution:
                \[
                x_0 = \begin{bmatrix} 0.1 \\ 0.9 \end{bmatrix}
                \]
                which means now, 10 % of students are 90 % are not.
                <br><br>
                Moreover, we assume the following conditions:
                <ul>
                    <li> 70% of sick students recover the next day and 30 % remain sick.</li>
                    <li> 5 % of not sick students become sick the next day and 95 % remain not sick</li>
                </ul>
                So, our stochastic matrix can be written as 
                \[
                P = \begin{bmatrix} 0.3 & 0.05 \\ 0.7 & 0.95 \end{bmatrix}.
                \]
                Then, 
                \[
                x_1 = P x_0 = \begin{bmatrix} 0.3 & 0.05 \\ 0.7 & 0.95 \end{bmatrix} \begin{bmatrix} 0.1 \\ 0.9 \end{bmatrix} = \begin{bmatrix} 0.075 \\ 0.925 \end{bmatrix}
                \]
                This means that on the next day, approximately 7.5 % students are expected to be sick and 92.5 % are not.
                <br><br>
                We can keep going this process:
                \[
                \begin{align*}
                &x_2 = P x_1 = \begin{bmatrix} 0.3 & 0.05 \\ 0.7 & 0.95 \end{bmatrix} \begin{bmatrix} 0.075 \\ 0.925 \end{bmatrix} = \begin{bmatrix} 0.06875 \\ 0.93125 \end{bmatrix} \\\\
                &x_3 = P x_2 = \begin{bmatrix} 0.3 & 0.05 \\ 0.7 & 0.95 \end{bmatrix} \begin{bmatrix} 0.06875 \\ 0.93125 \end{bmatrix} = \begin{bmatrix} 0.0671875 \\ 0.9328125 \end{bmatrix}
                \end{align*}
                \]
                and so on. 
            </div>
        </blockquote>

        <h1>Steady-state Vector</h1>
        <blockquote>
            A <strong>steady-state vector</strong> \(q\) for a stochastic matrix \(P\) is defined as 
            \[
            P q = q.
            \]
            In statistics, we also call it <strong>stationary distribution</strong>. 
            <br><br>
            The Markov chain, a sequence of vectors \(\{x_k : k = 1, 2, \cdots\}\) converges to the unique steady-state 
            vector \(q\) as \(k \to \infty\). Importantly, the initial state does not effect on the long-term behavior of the 
            Markov chain. 
            <br><br>
            In short, the reason why it happens is related to the fact that the steady-state vector \(q\) is 
            an <strong>eigenvector</strong> of the stochastic matrix corresponding to the largest eigenvalue \(\lambda_1 = 1\). Let's 
            dig a little deeper. 
            <br><br>
            For any matrix \(A\), the <strong>spectral radius</strong> \(\rho(A)\) is defined by the maximum absolute value of its 
            eigenvalues. It satisfies
            \[
            \rho(A) \leq \| A \|
            \]
            for any submultiplicative matrix norm \(\| \cdot \| \).
            <br><br>
            Remember, by definition, every column of a column-stochastic matrix sums to 1, which means the maximum absolute 
            column sum (<strong>1-norm</strong>, \(\| P \|_1\)) is always 1. Thus:
            \[
            \rho(P) \leq \| P \|_1 = 1
            \]
            (For the row-stochastic matrix, we use the <strong>infinity norm</strong> \(\| P \|_{\infty} =1\).)
            <br>
            Since we already know that 1 is an eigenvalue of \(P\), the spectral radius must be exactly 1, and no eigenvalue 
            can have greater than 1. 
            <br><br>
            Now, suppose \(P\) has a <strong>spectral decomposition</strong>(We will discuss later.):
            \[
            P = v_1 w_1^\top + \sum_{i = 2}^n \lambda_i v_i w_i^\top
            \]
            where \(v_1\) is is the dominant eigenvector corresponds to the eigenvalue \(\lambda_1 = 1\) and all other 
            eigenvalues \(\lambda_i , \, (\text{for } i = 2, \cdots, n) \) satisfy \(\|\lambda_i \| < 1\).
            <br><br>
            If we compute the \(k\)-step transition, we have:
            \[
            P^n = v_1 w_1^\top + \sum_{i = 2}^n \lambda_i^k v_i w_i^\top
            \]
            This means that the contribution from all components other than the one corresponding to \(\lambda_1 =1\) decays 
            exponentially fast. Therefore, the convergence of the state distribution to the stationary distribution is primarily due to 
            the spectral properties of the transition matrix.
            <br>
            <div class="proof">
                <span class="proof-title">Example: </span>
                In our example, 
                \[
                \begin{align*}
                & P q = q \\\\
                &\begin{bmatrix} 0.3 & 0.05 \\ 0.7 & 0.95 \end{bmatrix} \begin{bmatrix} q_1 \\ q_2 \end{bmatrix} = \begin{bmatrix} q_1 \\ q_2 \end{bmatrix}\\\\
                & q_1 + q_2 = 1 \\\\
                &\Longrightarrow q = \begin{bmatrix} \frac{1}{15} \\ \frac{14}{15} \end{bmatrix}
                \end{align*}
                \]
                which means that in the long run, about 6.67 % of the students will be sick and about 93.33 % will be not sick.
                <br><br>
                Find eigenvalues and corresponding eigenvectors:
                \[
                \begin{align*}
                &\det(P - \lambda I) = 0 \\\\
                &\Longrightarrow \lambda^2 - 1.25\lambda + 0.25 = 0 \\\\
                &\Longrightarrow (\lambda -1)(\lambda -0.25) = 0 \\\\
                &\Longrightarrow \lambda_1 = 1, \quad \lambda_2 = 0.25.
                \end{align*}
                \]
                For \(\lambda_1 = 1\), solving \((P -I)v_1 = 0\), we obtain the corresponding eigenvector:
                \[
                v_1 = \begin{bmatrix} 1 \\ 14 \end{bmatrix}.
                \]
                (Scaling by \(\frac{1}{15}\), we can get the stationary distribution \(q = \frac{1}{15}v_1\)).
                <br><br>
                For \(\lambda_2 = 0.25\), solving \((P -I)v_2 = 0\), we obtain the corresponding eigenvector:
                \[
                v_2 =  \begin{bmatrix} - 1 \\  1 \end{bmatrix}.
                \]
                So, 
                \[
                V = \begin{bmatrix} 1 & - 1 \\ 14 & 1 \end{bmatrix}, \quad V^{-1} = \frac{1}{15} \begin{bmatrix}  1 & 1 \\ -14 & 1 \end{bmatrix}, 
                \]
                and 
                \[
                D = \begin{bmatrix} \lambda_1 & 0\\ 0 & \lambda_2 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 0 & 0.25 \end{bmatrix}
                \]
                Thus, the transition matrix \(P\) after \(k\) steps can be written as: 
                <br>
                \[
                \begin{align*}
                P^n &= V D^n V^{-1} \\\\
                    &= \begin{bmatrix} 1 & - 1 \\ 14 & 1 \end{bmatrix} 
                      \begin{bmatrix} 1^k & 0 \\ 0 & (0.25)^k \end{bmatrix} 
                      \frac{1}{15}\begin{bmatrix} 1 & 1 \\ -14 & 1 \end{bmatrix}.
                \end{align*}
                \]
                <br>
                The error in the state distribution after \(k\) steps is dominated by the term \(\lambda_2^k = (0.25)^k\). Thus, the 
                convergence rate of the Markov chain toward the stationary distribution is exponential, with each additional step reducing 
                the error roughly by a factor of \(0.25\):
                <br>
                \[
                e_k \approx e_0 (0.25)^k
                \]
                where \(e_0\) is the initial error.
            </div>
             In this example, \(P\) is <a href="eigenvectors.html"><strong>diagonalizable</strong></a>, but in general, the stochastic matrices are not always 
             diagonalizable. In such a case, we need to use the <strong>spectral decomposition</strong>.
        </blockquote>

        <h1>Spectral Decomposition</h1>
        <blockquote>
            The spectral decomposition for a square matrix \(A\) can be written as 
            \[
            A = \sum_{i =1}^n \lambda_i v_i w_i 
            \]
            where \(v_i\) are the <strong>right eigenvectors</strong> of \(A\) and \(w_i\) are the <strong>left eigenvectors</strong> of \(A\) both are computed by 
            \(Av_i = \lambda_i v_i\) and \(w_i^\top A = \lambda_i w_i^\top\) respectively.
            <br><br>
            As we have seen, for the stochastic matrix \(P\), we have 
            \[
            P = v_1 w_1^\top + \sum_{i = 2}^n \lambda_i v_i w_i^\top
            \]
            where \(\lambda_1\) is the dominant eigenvalue corresponding to the stationary distribution eigenvector \(v_1 = q\).
            <br><br>
            At \(k\) steps, the spectral decomposition represents \(P\) as a sum of rank-one matrices \(v_i w_i^\top\), and then we have:
            \[
            x_k = P^k x_0 = \sum_{i = 1}^n \lambda_i^k v_i (w_i^\top x_0).
            \]
            Here, \(w_i^\top x_0\) gives the projection of the initial state onto the eigenvector directions.
            <br><br>
            In our example, 
            \[
            \begin{align*}
            P &= \lambda_1 v_1 w_1^\top + \lambda_2 v_2 w_2^\top \\\\
              &= 1 \times \begin{bmatrix} \frac{1}{15} \\ \frac{14}{15} \end{bmatrix} \begin{bmatrix} 1 & 1 \end{bmatrix} 
                    + 0.25 \times \begin{bmatrix} -1 \\ 1 \end{bmatrix} \begin{bmatrix} \frac{14}{15} & -\frac{1}{15} \end{bmatrix} 
            \begin{align*}
            \]
        </blockquote>

        <a href="../../index.html">Back to Home </a>
        <br> <a href="linear_algebra.html">Back to Linear Algebra </a>
    </body>
</html>