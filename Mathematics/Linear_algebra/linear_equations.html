---
layout: default
title: System of Linear Equations
level: detail
description: Learn about the system of Linear equations, matrix equations, and linear independence.
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body>
        <!-- LearningResource Schema for Content Pages -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "{{ page.title }}",
        "description": "{{ page.description }}",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "{% if page.content contains 'Interactive Demo' or page.content contains 'demo' %}active{% else %}expositive{% endif %}",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
        },
        "about": [
            {% if page.url contains 'linear_equations' %}
            { "@type": "Thing", "name": "Linear Equations" },
            { "@type": "Thing", "name": "System of Linear Equations" },
            { "@type": "Thing", "name": "Matrix Equation" },
            { "@type": "Thing", "name": "Linear Independence" },
            { "@type": "Thing", "name": "Homogeneous System" },
            { "@type": "Thing", "name": "Nonhomogeneous System" },
            { "@type": "Thing", "name": "Row Echelon Form" },
            { "@type": "Thing", "name": "RREF" },
            { "@type": "Thing", "name": "Linear Combinations" }
            {% elsif page.url contains 'eigenvectors' %}
            { "@type": "Thing", "name": "Eigenvalues" },
            { "@type": "Thing", "name": "Eigenvectors" }
            {% elsif page.url contains 'symmetry' %}
            { "@type": "Thing", "name": "Symmetric Matrices" },
            { "@type": "Thing", "name": "Quadratic Forms" }
            {% else %}
            { "@type": "Thing", "name": "Linear Algebra" },
            { "@type": "Thing", "name": "Mathematics" }
            {% endif %}
        ],
        "teaches": [
            "Mathematical concepts",
            "Practical applications",
            "Problem-solving techniques"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "{% if page.url contains 'Machine_learning' %}Machine Learning{% elsif page.url contains 'Linear_algebra' %}Linear Algebra{% elsif page.url contains 'Calculus' %}Calculus to Optimization & Analysis{% elsif page.url contains 'Probability' %}Probability & Statistics{% elsif page.url contains 'Discrete' %}Discrete Mathematics & Algorithms{% endif %}",
            "description": "{% if page.url contains 'Machine_learning' %}Explore machine learning ideas and applications with mathematical foundations{% elsif page.url contains 'Linear_algebra' %}Explore the foundations of Linear Algebra, covering key concepts such as linear equations, vector spaces, eigenvalues, orthogonality, least squares, and stochastic matrices{% elsif page.url contains 'Calculus' %}Explore key calculus concepts essential for optimization, analysis, and machine learning{% elsif page.url contains 'Probability' %}Explore fundamental concepts of probability and statistics essential for machine learning{% elsif page.url contains 'Discrete' %}Explore the foundations of discrete mathematics and algorithms, covering graph theory, combinatorics, and the theory of computation{% endif %}",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "{% if page.url contains 'Machine_learning' %}V{% elsif page.url contains 'Linear_algebra' %}I{% elsif page.url contains 'Calculus' %}II{% elsif page.url contains 'Probability' %}III{% elsif page.url contains 'Discrete' %}IV{% endif %}",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "{% if page.url contains 'Machine_learning' %}PT5H{% elsif page.url contains 'Linear_algebra' %}PT2H{% elsif page.url contains 'Calculus' %}PT3H{% elsif page.url contains 'Probability' %}PT2H30M{% elsif page.url contains 'Discrete' %}PT4H{% endif %}",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>
        <!-- WebApplication Schema for Interactive Demos -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "WebApplication",
        "name": "{{ page.title }} Interactive Demo",
        "description": "Interactive demonstration of {{ page.title | downcase }} concepts",
        "applicationCategory": "EducationalApplication",
        "operatingSystem": "Web Browser",
        "url": "https://yusukey01.github.io{{ page.url }}",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota"
        },
        "applicationSubCategory": "Mathematical Visualization",
        "featureList": [
            "Interactive mathematical visualization",
            "Real-time parameter adjustment",
            "Educational demonstrations"
        ],
        "isAccessibleForFree": true,
        "educationalUse": "instruction",
        "educationalLevel": "university"
        }
        </script>
        <div class="hero-section">
            <h1 class="webpage-name">Linear Equations
            </h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#system">System of Linear Equations</a>
            <a href="#m_eq">Matrix Equations</a>
            <a href="#independence">Linear Independence</a>
            <a href="#homo">Nonhomogeneous System vs Homogeneous System</a>
        </div> 

        <div class="container">  
           
            <section id="system" class="section-content">
            <h2>System of Linear Equations</h2>
            <p>
            A <strong>linear equation</strong> can be expressed in the form 
            \[
            a_1x_1 + a_2x_2 + \cdots + a_nx_n = b
            \]
            where \(x_1 \cdots x_n \) are variables and \(b\) and the coefficients \(a_1 \cdots a_n\) are real or complex numbers.
            In practice, \(n\) would be more than thousands or more. 
            <br> We refer to a collection of linear equations involving the same variables as a <strong>system of linear equations</strong>. 
            A system is called <strong>consistent</strong> if it has either <strong>exactly one solution</strong> or <strong>infinitely many solutions</strong>
            Also, if a system of linear equations has <strong>no solution</strong>, it is considered <strong>inconsistent</strong>.
            <br><br>
            We want to store the essential information of a system such as the values of each coefficient, the number of equations, and
            the number of variables into a rectangular array called a <strong>matrix</strong>.
            <br>For example, consider the linear system: 
            \[
            \begin{align}
             x_1\phantom{+a_20x_2}-3x_3 + \phantom{0}x_4 &= 10 \\
            4x_1 -5x_2 + 6x_3 -2x_4 &= -8 \\
            \phantom{a_3x_1+} 2x_2 + 2x_3 +5x_4 &=6
            \end{align}
            \]
            This syatem can be represented as the <strong>coefficient matrix</strong>:
            \[
            \begin{bmatrix} 1 & 0 & -3  & 1\\ 4 & -5 & 6  & -2\\ 0 & 2 & 2  & 5 \end{bmatrix}
            \] 
            This is a \(3 \times 4\) (read"3 by 4") matrix. Note: The number of rows always comes first.
            <br>Alternatively, we can represent it as the <strong>augmented matrix</strong>:
            \[
            \begin{bmatrix} 1 & 0 & -3 & 1 & 10\\ 4 & -5 & 6 & -2 & -8\\ 0 & 2 & 2 &  5 & 6 \end{bmatrix}
            \]
            This is a \(3 \times 5\) matrix which includes the constants from the right-hand side of the equations. 
            Here, the number of rows is 3, and the number of columns is 5.
            <br><br>
            How can we solve the linear system? The key idea is to replace the system with an equivalent system
            that is easier to solve. What does "equivalent" mean here? Two matrices are considered <strong>row equivalent</strong>
            if there is a sequence of elementary row operations that transforms one matrix into the other.
            The three elementary row operations are as follows.
            <ol style="padding-left: 40px;">
                <li>Replacing one row by the sum of itself and a multiple of another row.</li>
                <li>Swapping two rows.</li>
                <li>Multiplying all entries in a row by a nonzero scalar.</li>
            </ol>
            <br>
            First, we want to transform our augmented matrix into <strong>row echelon form</strong>, which satisfies 
            following conditions: 
            <br><br>
            <ol style="padding-left: 40px;">
                <li>All nonzero rows are above any rows of all zeros.</li>
                <li>The first nonzero entry in each row appears further to the right than the first nonzero 
                    entry in the row directly above it.</li>
                <li>All entries in a column below a leading entry are zero.</li>
            </ol>
            <br>
            We apply elementary row operations to the matrix:
            \[
            \begin{align*}
            &\begin{bmatrix} 
            1 & 0 & -3 & 1 & 10 \\ 
            4 & -5 & 6 & -2 & -8 \\ 
            0 & 2 & 2 & 5 & 6 
            \end{bmatrix} \\\\
            &\begin{bmatrix} 
            1 & 0 & -3 & 1 & 10 \\ 
            0 & -5 & 18 & -6 & -48 \\ 
            0 & 2 & 2 & 5 & 6 
            \end{bmatrix}  \quad (\text{Row2 $\leftrightarrow$ Row2 - 4*Row1}) \\\\
            &\begin{bmatrix} 
            1 & 0 & -3 & 1 & 10 \\ 
            0 & -5 & 18 & -6 & -48 \\ 
            0 & 0 & \frac{46}{5} & \frac{13}{5} & \frac{-66}{5} 
            \end{bmatrix} \quad (\text{Row3 $\leftrightarrow$ Row3 + (2/5)*Row2})
            \end{align*}
            \]
            
            <br>The matrix is now in row echelon form. Next, we transform it into <strong>reduced row echelon form(RREF)</strong>. 
            A matrix in row echelon form is RREF if it satisfies the following conditions additionally:
            <br><br>
            <ol style="padding-left: 40px;">
                <li>The leading entry in each nonzero row is 1.</li>
                <li>Each leading 1 is the only nonzero entry in its column. </li>
            </ol>
            \[
            \begin{align*}
            &\begin{bmatrix}
                1 & 0 & -3 & 1 & 10\\
                0 & 1 & \frac{-18}{5} & \frac{6}{5} & \frac{48}{5}\\
                0 & 0 & \frac{46}{5} & \frac{13}{5}& \frac{-66}{5}\\
            \end{bmatrix} \quad  (\text{Row2 $\leftrightarrow$ (Row2 / -5)}) \\\\
            &\begin{bmatrix}
                1 & 0 & -3 & 1 & 10\\
                0 & 1 & \frac{-18}{5} & \frac{6}{5} & \frac{48}{5}\\
                0 & 0 & 1 & \frac{13}{46}& \frac{-33}{23}\\
            \end{bmatrix} \quad   (\text{Row3 $\leftrightarrow$ (Row3 * 5/46)}) \\\\
            &\begin{bmatrix}
                1 & 0 & 0 & \frac{85}{46} & \frac{131}{23}\\
                0 & 1 & \frac{-18}{5} & \frac{6}{5} & \frac{48}{5}\\
                0 & 0 & 1 & \frac{13}{46}& \frac{-33}{23}\\
            \end{bmatrix} \quad  (\text{Row1 $\leftrightarrow$ (Row1 + 3*Row3)}) \\\\
            &\begin{bmatrix}
                1 & 0 & 0 & \frac{85}{46} & \frac{131}{23}\\
                0 & 1 & 0 & \frac{51}{23} & \frac{102}{23}\\
                0 & 0 & 1 & \frac{13}{46}& \frac{-33}{23}\\
            \end{bmatrix} \quad   (\text{Row2 $\leftrightarrow$ (Row2 + 18/5*Row3)}) 
            \end{align*}
            \]
            <br>Finally, we get the solution of the linear system as follows. 
            \[
            \begin{align}
                x_1 &= -\frac{85}{46}x_4 + \frac{131}{23}\\\\
                x_2 &= -\frac{51}{23}x_4 + \frac{102}{23}\\\\
                x_3 &= -\frac{13}{46}x_4 - \frac{33}{23}\\\\
                x_4 & \text{ is a free variable.}
            \end{align}
            \]
            <br>
            In this system, any solution is determined by a choice of the <strong>free variable</strong> \(x_4\). 
            </p>
            </section>

            <section id="m_eq" class="section-content">
            <h2>The Matrix Equation</h2>
            <p>
            To get a new perspective on the system of linear equations, we would like to 
            describe it using the concept of <strong>vectors</strong>. 
            <br>Given vectors \(v_1, v_2,\cdots, v_p \in \mathbb{R}^n \) and scalars \(c_1, c_2,\cdots, c_p\), 
            the vector \(y\) defined as

            \[
            y = c_1v_1 + c_2v_2 + \cdots + c_pv_p
            \]

            which is called a <strong>linear combination</strong> of \(v_1, v_2,\cdots, v_p\) with 
            <strong>weights</strong> \(c_1, c_2,\cdots, c_p\).
            <br><br>Let's reconsider the augmented matrix 

            \[
            \begin{bmatrix} 1 & 0 & -3 & 1 & 10 \\ 
                            4 & -5 & 6 & -2 & -8 \\
                            0 & 2 & 2 &  5 & 6 
            \end{bmatrix}.
            \]

            Define its column vectors: 
            \[
            \begin{align*}
            &a_1 = \begin{bmatrix} 1 \\ 4 \\ 0 \end{bmatrix}, \quad a_2 = \begin{bmatrix} 0 \\ -5 \\ 2 \end{bmatrix}, \\\\
            &a_3 = \begin{bmatrix} -3 \\ 6 \\ 2  \end{bmatrix}, \quad  a_4 = \begin{bmatrix} 1 \\ -2 \\ 5 \end{bmatrix} \\\\
            &\text{and } b =\begin{bmatrix} 10 \\ -8 \\ 6  \end{bmatrix} \in \mathbb{R}^3.
            \end{align*}
            \]
            Then \(b\) is generated("<strong>spanned</strong>") by a linear combination of \(a_1, \cdots, a_4\) because 
            there exist weights \(x_1, \cdots, x_4\) such that 

            \[
            x_1a_1 + x_2a_2 + x_3a_3 + x_4a_4 = b
            \]

            This is equivalent to the solution set we found earlier using the augmented matrix.
            In other words, the vector \(b\) lies in the span of \(\{a_1, a_2, a_3, a_4\}\), which is 
            a subset of \( \mathbb{R}^3\).
            \[
            b \in \text{Span } \{a_1, a_2, a_3, a_4\}
            \]
            <br>
            Here, we reinterpret the linear combination of vectors as the product of a 
            matrix \(A \in \mathbb{R}^{3\times4}\) and a vector \(x\in\mathbb{R}^4\). 
            \[
            \begin{align*}
            Ax &= \begin{bmatrix} a_1 & a_2 & a_3 & a_4 \end{bmatrix}
                 \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} \\\\ 
               &= x_1a_1 + x_2a_2 + x_3a_3 + x_4a_4  \\\\
               &= b
            \end{align*}
            \]
            Hence, the matrix equation \(Ax = b\) has a solution if and only if \(b\) is a linear combination of 
            the columns of \(A\). 
            </p>
            </section>

            <section id="independence" class="section-content">
            <h2>Linear Independence</h2>
            <p>
            A set of vectors \(\{v_1, v_2, \cdots, v_p\}\in \mathbb{R}^n \) is called <strong>linearly independent</strong> if
            \[x_1v_1 + x_2v_2 + \cdots + x_pv_p = 0\]
            has "only" the <strong>trivial solution</strong>(the zero vector in \(\mathbb{R}^n\)). 
            <br><br>
            Consider a matrix \(A\) with columns \(\{v_1, v_2, \cdots, v_p\}\). The matrix equation \(Ax =0\) is called the <strong>homogeneous equation</strong>, 
            and it always has at least one solution: the trivial solution \(x=0\). By definition, the columns of \(A\) are linearly independent
            if and only if \(Ax =0\) has "only" the trivial solution. 
            <br><br>
            On the other hand, the equation \(Ax =0\) has a <strong>nontrivial solution</strong> if and only if
            the columns of \(A\) are <strong>linearly dependent</strong>. 
            <br><br>
            When are the columns of \(A\) linearly dependent? Remember, if a linear system has a free variable,
            basic variables "depend" on the choice of the free variable. Thus, the homogeneous equation \(Ax =0\) has a nontrivial solution 
            if and only if the equation has <strong>at least one free variable</strong>, which means the columns of \(A\) are linearly dependent.
            <br><br>
            Warning: 
            <br>Consider the vectors
            \[
            u = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix} \qquad
            v = \begin{bmatrix} 2 \\ 4 \\ 6 \end{bmatrix} \qquad
            w = \begin{bmatrix} 7 \\ -9 \\ 7 \end{bmatrix} 
            \]
            The set \(\{u, v, w\}\) is a linearly "dependent" set because \(v = 2u\), but the vector \(w\) is NOT 
            a linear combination of \(u\) and \(v\). In other words, \(w \notin \text{Span }\{u, v\}\).
            Even in a linearly dependent set, some vectors might not be expressible as a combination of the others.
            </p>
            </section>

            <section id="homo" class="section-content">
            <h2>Nonhomogeneous System vs Homogeneous System</h2>
            <p>
            You might wonder about the relationship between a homogeneous equation \(Ax = 0\) and a 
            <strong>nonhomogeneous</strong> equation \(Ax = b\), where \(b\) is a nonzero vector. 
            Indeed, there is an important connection between them. Let's revisit the solution of our nonhomogeneous system:
            \[\begin{align}
                x_1 &= -\frac{85}{46}x_4 + \frac{131}{23}\\\\
                x_2 &= -\frac{51}{23}x_4 + \frac{102}{23}\\\\
                x_3 &= -\frac{13}{46}x_4 - \frac{33}{23}\\\\
                x_4 & \text{ is a free variable.}
            \end{align}\]
            As a "vector", the <strong>general solution</strong> of \(Ax = b\) can be written in 
            <strong>parametric vector form</strong> as:
            \[
                x = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} 
                = \begin{bmatrix} \frac{131}{23}\\ \frac{102}{23}\\ - \frac{33}{23}\\ 0 \end{bmatrix}
                    + x_4\begin{bmatrix} -\frac{85}{46}\\ -\frac{51}{23} \\ -\frac{13}{46}\\ 1 \end{bmatrix}
                = p + x_4v
            \]
            where \(p\) is a <strong>particular solution</strong> to  \(Ax = b\) (when \(x_4 =0\)), and \(x_4v\) represents the 
            general solution to the corresponding homogeneous system \(Ax = 0\).
            <br>
            Let's solve the homogeneous system \(Ax = 0\) using the same matrix \(A\).
            \[
            \begin{align*}
            &\begin{bmatrix} 1 & 0 & -3 & 1 & 0\\ 4 & -5 & 6 & -2 & 0\\ 0 & 2 & 2 &  5 & 0 \end{bmatrix} \\\\
            &\xrightarrow{\text{rref}}
            \begin{bmatrix} 1 & 0 & 0 & \frac{85}{46} & 0\\ 0 & 1 & 0 & \frac{51}{23} & 0\\ 0 & 0 & 1 & \frac{13}{46}& 0 \end{bmatrix} 
            \end{align*}
            \]
            <br>Then the solution is 
            \[
            \begin{align}
            x_1 &= -\frac{85}{46}x_4 \\\\ x_2 &= -\frac{51}{23}x_4 \\\\ x_3 &= -\frac{13}{46}x_4 \\\\ x_4 & \text{ is a free variable.}
            \end{align}
            \]
            In parametric vector form, this solution becomes: 
            \[x = x_4\begin{bmatrix} -\frac{85}{46}\\ -\frac{51}{23} \\ -\frac{13}{46}\\ 1 \end{bmatrix}
                = x_4v
            \]
            This is the <strong>general solution</strong> to  \(Ax = 0\) where \(p = 0\).
            <br>So, the solutions of the nonhomogeneous system \(Ax =b\) can be obtained by adding the particular solution \(p\) 
            to the general solution of the homogeneous system \(Ax =0\).
            Geometrically, you can imagine that the solution set of \(Ax = 0\) and \(Ax = b\) are "parallel." 
            This relationship leads us to an important result:
            <div class="theorem">
                <span class="theorem-title">Theorem 1:</span>
                Suppose the system \(Ax = b\) is consistent for some vector \(b\).
                Let \(p\) be a solution of the system. Then the solution set of \(Ax = b\) consists of 
                the set of all vectors of the form \(w = p + v_h\), where \(v_h\) is any solution of 
                the homogeneous system \(Ax = 0\).
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                Let \(p\) be a particular solution of the nonhomogeneous system \(Ax = b\) and let \(v_h\) be 
                any solution of the homogeneous system \(Ax = 0\). Also, let \(w = p + v_h\).
                \[
                \begin{align*}
                Aw  &= A(p+v_h)  \\\\
                    &= Ap + Av_h \\\\
                    &= b + 0     \\\\
                    &= b.
                \end{align*}
                \] 
                Thus \(w = p + v_h\) is a solution of \(Ax = b\).
                <br>Also, let \(w\) be any solution of \(Ax = b\), and define \(v_h = w -p\). Then
                \[ 
                \begin{align*}
                Av_h &= A(w-p) \\\\
                     &= Aw - Ap \\\\
                     &= b -b  \\\\
                     &= 0.
                \end{align*}
                \]
                Thus \(v_h = w -p\) satisfies \(Ax = 0\). 
                <br>Therefore, every solution of \(Ax = b\) has the form \(w = p + v_h\).
            </div>
            This theorem is not only crucial in understanding linear systems but is also highly useful 
            in solving <strong>differential equations</strong>.
            </p>
            </section>
        </div> 
        <script src="/js/main.js"></script>
    </body>
</html>