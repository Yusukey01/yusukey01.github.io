---
layout: default
title: Graph Laplacians and Spectral Methods
level: detail
description: Learn about graph Laplacians, spectral properties, graph signal processing, and their applications in Graph Neural Networks and modern machine learning.
uses_math: true
uses_python: true
---
<!DOCTYPE html>
<html>
    <body>
        <!-- LearningResource Schema for Graph Laplacians -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "Graph Laplacians and Spectral Methods",
        "description": "Learn about graph Laplacians, spectral properties, graph signal processing, and their applications in Graph Neural Networks and modern machine learning",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "active",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
        },
        "about": [
            { "@type": "Thing", "name": "Graph Laplacian" },
            { "@type": "Thing", "name": "Spectral Graph Theory" },
            { "@type": "Thing", "name": "Normalized Laplacian" },
            { "@type": "Thing", "name": "Random Walk Laplacian" },
            { "@type": "Thing", "name": "Fiedler Vector" },
            { "@type": "Thing", "name": "Spectral Gap" },
            { "@type": "Thing", "name": "Cheeger Inequality" },
            { "@type": "Thing", "name": "Graph Signal Processing" },
            { "@type": "Thing", "name": "Graph Fourier Transform" },
            { "@type": "Thing", "name": "Graph Neural Networks" },
            { "@type": "Thing", "name": "Spectral Clustering" }
        ],
        "teaches": [
            "Graph Laplacian fundamentals and variants",
            "Spectral properties and their interpretations",
            "Graph signal processing techniques",
            "Efficient computation methods",
            "Applications to Graph Neural Networks",
            "Connections to clustering and embeddings"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Linear Algebra",
            "description": "Explore the foundations of Linear Algebra, covering key concepts such as linear equations, vector spaces, eigenvalues, orthogonality, least squares, and stochastic matrices",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "I",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT2H30M",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>
        
        <div class="hero-section">
            <h1 class="webpage-name">Graph Laplacians and Spectral Methods</h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#fundamentals">Graph Laplacian Fundamentals</a>
            <a href="#spectral">Spectral Properties</a>
            <a href="#signal">Graph Signal Processing</a>
            <a href="#computation">Practical Computations</a>
            <a href="#applications">Modern Applications</a>
            <a href="#interactive">Interactive Visualizer</a>
        </div> 

        <div class="container">
            
            <section id="fundamentals" class="section-content">
                <h2>Graph Laplacian Fundamentals</h2>
                <p>
                    The <strong>graph Laplacian</strong> is a matrix representation that captures the structure of a graph 
                    and plays a central role in spectral graph theory. Building on your knowledge of 
                    <a href="../Discrete/intro_graph.html">graph theory</a> and <a href="eigenvectors.html">eigenvalues</a>, 
                    we'll explore how the Laplacian encodes connectivity patterns and enables powerful analytical techniques.
                </p>
                <p> 
                    If \(G\) is a graph with vertex set \(\{1, 2, \ldots, n-1, n\}\). Let \(D(G)\) be the \(n \times n\) diagonal 
                    matrix of vertex degrees of \(G\). The <strong>Laplacian matrix</strong> is defined as 
                    \[
                    L(G) = D(G) - A(G)
                    \]
                    where \(A(G)\) is the adjacency matrix of \(G\).
                     <div style="text-align: center;">
                    <img src="images/laplacian.jpg" alt="laplacian"  class="responsive-image">
                    </div>
                    \[
                    \begin{bmatrix} 2 & 0 & 0 & 0 & 0 \\ 
                                    0 & 2 & 0 & 0 & 0 \\
                                    0 & 0 & 4 & 0 & 0 \\
                                    0 & 0 & 0 & 1 & 0 \\
                                    0 & 0 & 0 & 0 & 1 \\
                    \end{bmatrix}
                    - 
                    \begin{bmatrix} 0 & 1 & 1 & 0 & 0 \\ 
                                    1 & 0 & 1 & 0 & 0 \\
                                    1 & 1 & 0 & 1 & 1 \\
                                    0 & 0 & 1 & 0 & 0 \\
                                    0 & 0 & 1 & 0 & 0 \\
                    \end{bmatrix}
                    = 
                    \begin{bmatrix} 2 & -1 & -1 & 0 & 0 \\ 
                                    -1 & 2 & -1 & 0 & 0 \\
                                    -1 & -1 & 4 & -1 & -1 \\
                                    0 & 0 & -1 & 1 & 0 \\
                                    0 & 0 & -1 & 0 & 1 \\
                    \end{bmatrix}
                    \]
                </p>

                <p>
                    Moreover, the <strong>spectral decomposition</strong> of the Laplacian matrix \(\boldsymbol{L}\) reveals deeper structure and provides a 
                    spectral interpretation of smoothness on graphs. 
                    Since \(\boldsymbol{L}\) is symmetric and positive semi-definite, it admits an orthonormal eigendecomposition:
                    \[
                    \boldsymbol{L} = \boldsymbol{V}\,\boldsymbol{\Lambda}\,\boldsymbol{V}^\top, 
                    \quad
                    \boldsymbol{\Lambda} = \mathrm{diag}(\lambda_1, \lambda_2, \dots, \lambda_N),
                    \]
                    with ordered eigenvalues
                    \[
                    0 = \lambda_1 \le \lambda_2 \le \cdots \le \lambda_N,
                    \]
                    and orthonormal eigenvectors \(\boldsymbol{v}_1, \dots, \boldsymbol{v}_N\) forming a complete basis for functions defined on the graph.
                </p>

                <p>
                    Several important spectral properties follow:
                    <ul>
                    <li>
                        The <strong>multiplicity of the zero eigenvalue</strong> equals the number of connected components in the graph.  
                        For a connected graph, \(\lambda_1 = 0\) is simple, and its eigenvector is proportional to the constant vector \(\boldsymbol{1}\).
                    </li>
                    <li>
                        The <strong>second smallest eigenvalue</strong>, \(\lambda_2\), known as the <strong>algebraic connectivity</strong> (or <strong>Fiedler value</strong>), 
                        quantifies the graph's overall connectivity: larger \(\lambda_2\) implies stronger connectivity and fewer natural partitions.
                    </li>
                    <li>
                        For any unit-norm eigenvector \(\boldsymbol{v}_k\),
                        \[
                        \boldsymbol{v}_k^\top \boldsymbol{L}\, \boldsymbol{v}_k = \lambda_k,
                        \]
                        meaning that eigenvectors with larger eigenvalues correspond to functions of higher “energy” (less smoothness) on the graph.
                    </li>
                    <li>
                        If an arbitrary function \(\boldsymbol{f}\) is expanded in this eigenbasis as
                        \[
                        \boldsymbol{f} = \sum_{k=1}^N \alpha_k \boldsymbol{v}_k,
                        \]
                        its Dirichlet energy decomposes as
                        \[
                        \boldsymbol{f}^\top \boldsymbol{L}\, \boldsymbol{f} = \sum_{k=1}^N \alpha_k^2 \lambda_k.
                        \]
                        Hence, components along higher-\(\lambda\) eigenvectors contribute more to the overall roughness of \(\boldsymbol{f}\).
                    </li>
                    </ul>
                </p>
            </section>

            <section id="" class="section-content">
                <h2></h2>
            </section>



        </div>
          
        <script src="/js/main.js"></script>

    </body>
</html>