---
layout: default
title: Context-Free Languages
topic_id: disc-5
level: detail
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body> 
        {% include learning_resource_schema.html topic_id=page.topic_id %}
       
        <div class="hero-section">
            <h1 class="webpage-name">Context-Free Languages</h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#CFG">Context-Free Grammar</a>
            <a href="#Pumping">Pumping Lemma</a>
            <a href="#push">Pushdown Automata</a>
            <a href="#NCF">Non-Context-Free Languages</a>
            <a href="#DPDA">Deterministic Pushdown Automata (DPDAs)</a>
        </div> 

        <div class="container">  
           
            <section id="CFG" class="section-content">
                <h2>Context-Free Grammar (CFG)</h2>
                <p>
                    In <a href="intro_automata.html"><strong>Part 3</strong></a>, we saw that <strong>finite automata</strong> recognize 
                    exactly the regular languages. However, many important languages - including the syntax of most programming 
                    languages - have recursive, nested structure that regular languages cannot capture. 
                    <strong>Context-free grammars</strong> provide a more powerful formalism for describing such languages.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Context-Free Grammar (CFG)</span>
                    <p>
                        A <strong>context-free grammar</strong> is a 4-tuple \((V, \Sigma, R, S)\) where
                    </p>
                    <ul style="padding-left: 40px;">
                        <li>\(V\) is a finite set called the <strong>variables</strong>,</li>
                        <li>\(\Sigma\) is a finite set disjoint from \(V\), called the <strong>terminals</strong>,</li>
                        <li>\(R\) is a finite set of <strong>production rules</strong>, each of the form \(A \to w\) where \(A \in V\) and \(w \in (V \cup \Sigma)^*\),</li>
                        <li>\(S \in V\) is the <strong>start variable</strong>.</li>
                    </ul>
                    <p>
                        A language that can be generated by some context-free grammar is called a <strong>context-free language (CFL)</strong>.
                    </p>
                </div>

                <div class="proof">
                    <span class="proof-title">Example:</span> 
                    <p>
                        \[
                        \begin{align*}
                        &X \to 00X1 \, | \, Y01 \\\\
                        &Y \to $
                        \end{align*}
                        \]
                        In this grammar, \(V = \{X, Y\}, \, \Sigma = \{0, 1, $\}, \, S = X\), and \(R\) is the collection of above rules.
                    </p>
                    <p>
                        For example, this grammar generates the string \(0000$0111\). The <strong>derivation</strong> of the string in this grammar is 
                        \[
                        X \Rightarrow 00X1 \Rightarrow 0000X11 \Rightarrow 0000Y0111 \Rightarrow 0000$0111.
                        \]
                        Note: \( X \to 00X1 \, | \, Y01\) means \( X \to 00X1\) OR \(X \to  Y01\).
                    </p>
                </div>

                <p>
                    Context-free grammars are strictly more powerful than <a href="intro_automata.html#r_exp"><strong>regular expressions</strong></a>: 
                    every regular language is context-free, but not vice versa. The key advantage is that CFGs can describe <strong>recursive</strong> 
                    and <strong>nested</strong> structures.
                </p>
                <p>
                    Consider the language 
                    \[
                    L_1 = \{0^n 1^n \mid n \geq 0\}.
                    \]
                    This language is <strong>not regular</strong> - no finite automaton can recognize it, because a finite 
                    automaton cannot "count" an unbounded number of 0s and then match them with the same number of 1s. 
                    To prove this rigorously, we use the <strong>Pumping Lemma</strong>.
                </p>

            </section>

            <section id="Pumping" class="section-content">
                <h2>Pumping Lemma</h2>

                 <p>
                    The Pumping Lemma is the standard tool for proving that a language is <em>not</em> regular. 
                    The idea is that any sufficiently long string in a regular language must contain a substring 
                    that can be "pumped" (repeated any number of times) while remaining in the language - a 
                    consequence of the pigeonhole principle applied to the finite number of states.
                </p>
                
                <div class="theorem">
                    <span class="theorem-title">Theorem: Pumping Lemma for Regular Languages</span>
                    <p>
                        If \(L\) is a regular language, then there exists \(p \in \mathbb{N}\) where if any string \(s \in L\) of 
                        length at least \(p\), then \(s\) may be divided into three pieces, \(s = xyz\), satisfying the following conditions:
                    </p>

                    <ul style="padding-left: 40px;">
                        <li>\(\forall i \geq 0, \, xy^i z \in L\)</li>
                        <li>\(|y| > 0\)</li>
                        <li>\(|xy| \leq p\)</li>
                    </ul>
                    <p>
                        Note: \(p\) is called the <strong>pumping length</strong>.
                    </p>
                </div>

                <p>
                    For example, assume \(L_1\) is regular. Choose \(s\) to be the string \(0^p1^p\), where \(p\) is the pumping length. Then 
                    \(s\) must be split into three pieces, \(s = xyz\), where for any \(i \geq 0\) the string \(xy^iz \in L_1\).  If we pump \(y\), 
                    the number of \(0\)s and \(1\)s become unequal, producing a string not in \(L_1\). (Check when \(y\) consists only of \(0\)s, only of \(1\)s, or 
                    of both \(0\)s & \(1\)s). Thus, by contradiction, \(L_1\) is not regular.
                </p>

                <p>
                    However, \(L_1\) <em>is</em> context-free. It can be generated by the grammar
                    \[
                    S \to 0S1 \mid \epsilon.
                    \]
                    For example, \(S \Rightarrow 0S1 \Rightarrow 00S11 \Rightarrow 0011\). 
                    The recursive rule \(S \to 0S1\) ensures that every 0 is matched by a corresponding 1 - exactly the kind 
                    of nested structure that a CFG can capture but a finite automaton cannot.
                </p>

            </section>

            <section id="push" class="section-content">
                <h2>Pushdown Automata</h2>

                <p>
                    The Pumping Lemma showed that finite automata lack the memory to handle languages like \(L_1 = \{0^n 1^n\}\). 
                    To recognize context-free languages, we need a computational model with auxiliary storage. 
                    A <strong>pushdown automaton (PDA)</strong> extends a finite automaton with a <strong>stack</strong> - 
                    an unbounded last-in, first-out memory - that provides exactly the right amount of additional power.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Pushdown Automaton (PDA)</span>
                    <p>
                        A <strong>pushdown automaton</strong> is a 6-tuple \((Q, \Sigma, \Gamma, \delta, q_0, F)\) where
                    </p>
                    <ul style="padding-left: 40px;">
                        <li>\(Q\) is a finite set of states,</li>
                        <li>\(\Sigma\) is the input alphabet,</li>
                        <li>\(\Gamma\) is the <strong>stack alphabet</strong>,</li>
                        <li>\(\delta: Q \times \Sigma_{\epsilon} \times \Gamma_{\epsilon} \to \mathcal{P}(Q \times \Gamma_{\epsilon})\) is the transition function,</li>
                        <li>\(q_0 \in Q\) is the start state,</li>
                        <li>\(F \subseteq Q\) is the set of accept states.</li>
                    </ul>
                </div>

                <p>
                    A PDA is similar to an NFA but can additionally push symbols onto and pop symbols from its stack at each step. 
                    This extra memory allows PDAs to recognize some nonregular languages.
                </p>

                <p>
                    Again, consider the language: 
                    \[
                    L_1 = \{0^n 1^n \, | \, n \geq 0\}.
                    \]
                    The PDA \(M_1\) reads symbols from the input string as follows: 
                </p>

                <ul style="padding-left: 40px;">
                    <li>As each \(0\) is read, pushes it onto the stack.</li>
                    <li>After reading the sequence of \(0\)s, pops a \(0\) off the stack for each \(1\) that is read.</li>
                    <li>If reading the string is finished exactly when the stack becomes empty, accepts the string, otherwise rejects the input.</li>
                </ul>

                <p>
                    Let's build the state diagram for \(M_1\) that recognizes \(L_1\).
                    \[
                    \begin{align*}
                    &Q = \{q_1, q_2, q_3, q_4\} \\\\
                    &\Sigma = \{0, 1\} \\\\
                    &\Gamma = \{0, \$\} \\\\
                    &F = \{q_1, q_4\}
                    \end{align*}
                    \]
                    Note: A special symbol \(\$\) is used as a bottom-of-stack marker.
                </p> 

                <div style="text-align: center;">
                    <img src="Images/PDA.jpg" alt="PDA"  class="responsive-image">
                </div>

                <p>
                    The edge labels have the form \(a,\, b \to c\), meaning: read \(a\) from the input, pop \(b\) from 
                    the top of the stack, and push \(c\) onto the stack. For example, \(1,\, 0 \to \epsilon\) means 
                    "read a 1, pop a 0, and push nothing" (effectively removing the 0).
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: CFG-PDA Equivalence</span>
                    <p>
                        A language is context-free if and only if some pushdown automaton recognizes it.
                    </p>
                </div>
                <p>
                    We omit the proof, which proceeds by constructing a PDA from a given CFG and vice versa. 
                    The key insight is that the PDA's stack can simulate the derivation process of the grammar.
                </p>

                <p>
                    Moreover, <strong>every regular language is context-free</strong>, because every regular language 
                    is recognized by a finite automaton, and every finite automaton is automatically a pushdown automaton 
                    (one that simply ignores its stack).
                </p>

            </section>

            <section id="NCF" class="section-content">
                <h2>Non-Context-Free Languages</h2>

                <p>
                    Just as the Pumping Lemma for regular languages lets us prove that certain languages are not regular, 
                    there is an analogous result for context-free languages. This time, a sufficiently long string can be 
                    divided into <strong>five</strong> pieces, where the 2nd and 4th pieces may be "pumped" together 
                    while the resulting string remains in the language.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Pumping Lemma for Context-Free Languages</span>
                    <p>
                        If \(L\) is a context-free language, then there exists a <strong>pumping length</strong> 
                        \(p \in \mathbb{N}\) such that every string \(s \in L\) with \(|s| \geq p\) can be divided into 
                        five pieces, \(s = uvxyz\), satisfying:
                    </p>
                    <ol style="padding-left: 40px;">
                        <li>\(\forall\, i \geq 0, \quad uv^i x y^i z \in L\),</li>
                        <li>\(|vy| > 0\),</li>
                        <li>\(|vxy| \leq p\).</li>
                    </ol>
                </div>

                <p>
                    Consider the language 
                    \[
                    L_2 = \{a^n b^n c^n \mid n \geq 0\}.
                    \]
                    This is <strong>not</strong> a context-free language. Intuitively, recognizing \(L_2\) requires maintaining 
                    two independent counts simultaneously (matching \(a\)'s with \(b\)'s <em>and</em> \(b\)'s with \(c\)'s), 
                    which exceeds the capability of a single stack. 
                    More precisely, for any decomposition \(s = uvxyz\) satisfying condition 3 (\(|vxy| \leq p\)), 
                    the substring \(vxy\) can span at most two of the three symbol types. Pumping then disrupts the 
                    balance among \(a\)'s, \(b\)'s, and \(c\)'s, violating condition 1 in both cases â€” whether \(v\) and \(y\) 
                    each contain a single symbol type, or one of them contains mixed symbols.
                </p>

                <p>
                    Recognizing \(L_2\) requires more computational power than a PDA - it requires a 
                    <a href="turing_machine.html"><strong>Turing machine</strong></a>.
                </p>

            </section>

            <section id="DPDA" class="section-content">
                <h2>Deterministic Pushdown Automata (DPDAs)</h2>

                <p>
                    Recall that for finite automata, deterministic (DFA) and nondeterministic (NFA) models recognize 
                    the same class of languages. For pushdown automata, however, the situation is different: 
                    nondeterministic PDAs are strictly more powerful than deterministic ones. Some context-free 
                    languages cannot be recognized by any DPDA.
                </p>
                <p>
                    Nevertheless, <strong>deterministic context-free languages (DCFLs)</strong> - those recognizable 
                    by DPDAs - are of great practical importance. Most programming languages are designed to be 
                    DCFLs precisely so that efficient <strong>parsers</strong> (syntax analyzers) can be constructed 
                    for their compilers.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Deterministic Pushdown Automaton (DPDA)</span>
                    <p>
                        A <strong>deterministic pushdown automaton</strong> is a PDA whose transition function
                        \[
                        \delta: Q \times \Sigma_{\epsilon} \times \Gamma_{\epsilon} \to (Q \times \Gamma_{\epsilon}) \cup \{\emptyset\}
                        \]
                        satisfies the following condition: for every \(q \in Q\), \(a \in \Sigma\), and \(x \in \Gamma\), 
                        exactly one of 
                        \[
                        \delta(q, a, x), \quad \delta(q, a, \epsilon), \quad \delta(q, \epsilon, x), \quad \delta(q, \epsilon, \epsilon)
                        \]
                        is not \(\emptyset\).
                    </p>
                </div>

                <p>
                    Note that DPDAs still permit \(\epsilon\)-transitions - the determinism condition requires that 
                    at most one transition applies in each situation, not that every transition must read input and stack simultaneously:
                </p>
                <ul style="padding-left: 40px;">
                    <li>\(\delta(q, a, \epsilon)\): read input \(a\) without inspecting the stack,</li>
                    <li>\(\delta(q, \epsilon, x)\): pop \(x\) from the stack without reading input,</li>
                    <li>\(\delta(q, \epsilon, \epsilon)\): neither read input nor inspect the stack.</li>
                </ul> 
                <p>
                    The language \(L_1 = \{0^n 1^n \mid n \geq 0\}\) from our earlier example is a DCFL - the PDA 
                    we constructed for it is in fact deterministic, since at each step the current state, input symbol, 
                    and top-of-stack symbol uniquely determine the next move.
                </p>

                <p>
                    We have now established the hierarchy: regular languages \(\subsetneq\) DCFLs \(\subsetneq\) CFLs. 
                    In the next pages, we move beyond context-free languages to the most powerful standard computational model - 
                    the <a href="turing_machine.html"><strong>Turing machine</strong></a> - which defines the boundary of 
                    what is computable.
                </p>
            </section>
        </div>
        <script src="/js/main.js"></script>
    </body>
</html>