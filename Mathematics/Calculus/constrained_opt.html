<!DOCTYPE html>
<html>
    <head> 
        <title>Constrained Optimization</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Constrained Optimization Problem</h1>
        <blockquote>
            Consider the <strong>constrained optimization problem</strong>: 
            \[
            \theta^* \in \arg \min_{\theta \in \mathcal{C}} \mathcal{L}(\theta).
            \]
            Here, \(\mathcal{C}\) is the <strong>feasible set</strong> \(\mathcal{C}\) as the subset of the parameter space \(\Theta \in \mathbb{R}^D\) that 
            satisfies a set of <strong>constraints</strong>:
            \[
            \mathcal{C} = \{\theta \in \mathbb{R}^D :  h_i (\theta) = 0, i \in \mathcal{E},  g_j (\theta) \leq 0,  j \in \mathcal{I} \}
            \]
            Note: Usually, we convert the constrained optimization problem into an unconstrained problem by introducing <strong>penalty 
            terms</strong> that measure how much we violate each constraint and adding them to the objective function. 
        </blockquote>

        <h1>Lagrange multipliers</h1>
        <blockquote>
            Assume we have only one equaly constrain \(h(\theta) = 0\). For any point on the constrain surface, \(\nabla h\(\theta)\) is 
            orthogonal to the constraint surface. Consider another point, \(\theta + \epsilon\), which is close enough the point \(\theta\) and 
            lies on the same constraint surface. By the firtst-order Taylor expansion, 
            \[
            h(\theta + \epsilon) \approx h(\theta) + \epsilon^T \lambda h(\theta).
            \]
            Since both points are on the same constraint surface, \(\epsilon^T \lambda h(\theta) \approx 0\). So, the gradient 
            \(\nabla h(theta)\) must be perpendicular to constraint surface.
            <br>
            Note: The vector \(\epsilon\) is parallel to the constraint surface.
            <br>
            Hence, there exists a constant \(\lambda^* \in \mathbb{R}\) such that 
            \[
            \nabla \mathcal{L}(\theta^*) = \lambda^* \nabla h(\theta^*)
            \]
            and an objective(\<strong>Lagrangian</strong>) is given by 
            \[
            L(\theta, \lambda) = \mathcal{L}(\theta) + \lambda h(\theta).
            \]
            We call the constant \(\lambda^*\) a <strong>Lagrange multiplier</strong>. 
            <br>
            At the <strong>critical point</strong>, 
            \[
            \nabla_{\theta, \lambda}  L(\theta, \lambda) = 0
            \]
            which means
            \[
            \lambda \nabla_{\theta} h(\theta) = \nabla \mathcal{L}(\theta), \qquad h(\theta) = 0.
            \]
            Note: For \(m\) constraints, \(L(\theta, \lambda) = \mathcal{L}(\theta) + \sum_{j=1}^m \lambda_j h_j(\theta)\).
        </blockquote>

        <h1></h1>
        <blockquote>
        </blockquote>

        <a href="../../index.html">Back to Home </a>
        <br> <a href="calculus.html">Back to Calculus </a>
    </body>
</html>