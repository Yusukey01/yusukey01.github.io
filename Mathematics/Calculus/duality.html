<!DOCTYPE html>
<html>
    <head> 
        <title>Duality in Optimization & Analysis</title>
        <link rel="stylesheet" href="../styles.css">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <div class="toc-container">
            <h2>Contents</h2>
            <ul>
                <li><a href="#duality">Duality</a></li>
                <li><a href="#Lip">Lipschitz Continuity</a></li>
                <li><a href="#"></a></li>
            </ul>
        </div> 
            
        <h1 id="duality">Duality</h1>
        <blockquote>
            <strong>Duality</strong> arises in optimization models in a wide variety of settings. For example, in 
            <a href="constrained_opt.html"><strong>KKT conditions</strong></a> the optimal solution to the dual problem 
            is a vector of KKT multipliers. 
            <br><br>
            Given a <strong>primal problem</strong>
            \[
            \min_x f(x) \, \text{ subject to } g_i (x) \leq 0,  \, h_j (x) = 0
            \]
            where \(f(x)\) is the objective function, \(g_i(x)\) are inequality constranints, and \(h_i(x)\) are equality 
            constraints, and we define the Lagrangian:
            \[
            L(x, \lambda, \nu) = f(x) + \sum_i \lambda_i g_i(x) + \sum_j \nu_j h_j(x)
            \]
            where \(\lambda_i \geq 0\) are the Lagrange multipliers (dual variables).
            <br><br>
            Then its <strong>dual problem</strong> is 
            \[
            \max_{\lambda \geq 0, \nu} \, \inf_x L( x, \lambda, \nu).
            \]
            The optimal value of this dual problem \(d^*\) provides a <strong>lower bound</strong> on the optimal value of the primal problem \(p^*\):
            \[
            d^* \leq p^*.
            \]
            we call this condition <strong>weak duality</strong>. Weak duality always holds for any optimization problem where a valid dual problem is 
            formulated. The difference between the primal and dual optimal values, \(p^* - d^*\) is called <strong>duality gap</strong>.  When the 
            primal and dual optimal values are equal,\(p^* =  d^*\), in other words, the duality gap is zero, we call it <strong>strong duality</strong>.
        </blockquote>
        
        <h1 id="Lip">Lipschitz Continuity</h1>
        <blockquote>
            In convex optimization and machine learning, strong duality and efficient optimization often require certain regularity conditions, such 
            as <strong>Lipschitz continuity</strong> (smoothness condition) of the objective function or its gradient. These conditions impact the stability and 
            convergence of optimization algorithms.
            <br><br>
            A function \(f(x)\) is said to be <strong>Lipschitz continuous</strong> if there exists a constant \(L > 0\) such that: 
            \[
            | f(x) - f(y) | \leq L \| x - y \|
            \]
            for all \(x, y\) in the domain. The constat \(L\) is called <strong>Lipschitz constant</strong>.
            <br>
            Moreover, a function is <strong>\(L\)-smooth</strong> if its gradient \(\nabla f(x)\) is Lipschitz continuous:
            \[
            \| \nabla f(x) \ \nabla f(y) \| \leq L \|x -y\|.
            \]
            This smoothness condition ensures that gradient-based optimization behaves predictably.
            <br><br>
            If the gradient is Lipschitz continuous, gradient descent converges at a linear rate. That is, 
            there exists \( 0 < \mu < 1 \) such that:
            \[
            |\mathcal{L}(\theta_{t+1}) - \mathcal{L}(\theta_*) | \leq \mu | \mathcal{L}(\theta_t) - \mathcal{L}(\theta_*)|. 
            \]
            Here, \(\mu\) is called the <strong>rate of convergence</strong>.
            <br><br>
            For example, consider a quadratic loss function:
            \[
            \mathcal{L}(\theta) = \frac{1}{2}\theta^T A \theta + b^T \theta  + c 
            \]
            where \(A\) is positive definite. 
            <br><br>
            The convergence rate is given by 
            \[
            \mu = \left(\frac{\lambda_{\max} - \lambda_{\min}}{\lambda_{\max} + \lambda_{\min}}\right)^2.
            \]
            The convergence rate is determined by the <strong>condition number</strong>:
            \[
            \kappa = \frac{\lambda_{\max}}{\lambda_{\min}}, \quad \mu = \left(\frac{\kappa -1}{\kappa + 1}\right)^2.
            \]
            where \(\lambda_{\max}\) is the largest eigenvalue of \(A\) and \(\lambda_{\min}\) is the smallest eigenvalue 
            of \(A\). 
            <br>
            In general, Problems with **low** condition numbers converge(or train) faster.
        </blockquote>
    <a href="../../index.html">Back to Home </a>
    <br> <a href="calculus.html">Back to Calculus </a>
</body>
</html>