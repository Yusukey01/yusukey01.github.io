---
layout: default
title: Intro to Numerical Computation
level: detail
description: Introduction to numerical computation with coding.
uses_math: true
uses_python: true
---
<!DOCTYPE html>
<html> 
    <body>
        <!-- LearningResource Schema for Intro to Numerical Computation -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "Intro to Numerical Computation",
        "description": "Introduction to numerical computation with coding",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "active",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator",
            "knowsAbout": [
            "Numerical Computation",
            "Finite Difference Methods",
            "Matrix Calculus",
            "Numerical Analysis",
            "Computational Mathematics",
            "Scientific Computing"
            ]
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
        },
        "about": [
            { "@type": "Thing", "name": "Numerical Computation" },
            { "@type": "Thing", "name": "Finite Difference Methods" },
            { "@type": "Thing", "name": "Forward Difference" },
            { "@type": "Thing", "name": "Backward Difference" },
            { "@type": "Thing", "name": "Matrix Derivatives" },
            { "@type": "Thing", "name": "Numerical Differentiation" },
            { "@type": "Thing", "name": "Relative Error" },
            { "@type": "Thing", "name": "Floating-point Arithmetic" },
            { "@type": "Thing", "name": "Machine Epsilon" },
            { "@type": "Thing", "name": "Numerical Accuracy" },
            { "@type": "Thing", "name": "Frobenius Norm" },
            { "@type": "Thing", "name": "Matrix Functions" },
            { "@type": "Thing", "name": "Computational Validation" },
            { "@type": "Thing", "name": "Random Testing" },
            { "@type": "Thing", "name": "Numerical Stability" }
        ],
        "teaches": [
            "Understanding finite difference approximations",
            "Computing numerical derivatives of matrix functions",
            "Comparing analytical vs numerical differentiation",
            "Understanding relative error calculations",
            "Working with floating-point arithmetic limitations",
            "Validating mathematical computations with code",
            "Understanding machine epsilon and numerical precision",
            "Testing algorithms with random non-integer values"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Calculus to Optimization & Analysis",
            "description": "Explore optimization techniques and mathematical analysis with applications",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "II",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT2H",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>

        <!-- WebApplication Schema for Interactive Code Demo -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "WebApplication",
        "name": "Matrix Derivative Numerical Validation",
        "description": "Interactive numerical computation example validating matrix derivative formulas using finite difference methods",
        "applicationCategory": "EducationalApplication",
        "operatingSystem": "Web Browser",
        "url": "https://yusukey01.github.io/Mathematics/Calculus/numerical_example1.html",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota"
        },
        "applicationSubCategory": "Numerical Methods Demonstration",
        "featureList": [
            "Matrix derivative computation example",
            "Forward and backward finite difference implementation",
            "Relative error analysis between methods",
            "Interactive Python code execution",
            "Numerical validation of analytical formulas",
            "Floating-point precision demonstration"
        ],
        "isAccessibleForFree": true,
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "about": [
            { "@type": "Thing", "name": "Numerical Differentiation Demo" },
            { "@type": "Thing", "name": "Matrix Calculus Validation" },
            { "@type": "Thing", "name": "Finite Difference Example" }
        ]
        }
        </script>
        <div class="hero-section">
            <h1 class="webpage-name">Intro to Numerical Computation
            </h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#ex1">Numerical Computation Example</a>
        </div> 

        <div class="container">        
            <section id="ex1" class="section-content">
            <h2>Example: \(df = X(dx)+(dX)X\) for \(f(X) = X^2\)</h2>
            <p>
            In this example, we numerically compute the derivative of the matrix equation \(f(X) = X^2\). Defining 
            differentiation rules, such as the general chain rule and vector-Jacobian product can significantly enhance 
            computational performance.
            <br>
            To validate your differentiation rules, comparing them with the <strong>finite-difference approximation</strong> 
            is a practical approach. Two common methods for finite-difference approximation are:
            \[
            f(x+dx) - f(x) \text{ (Forward Difference)}
            \]
            \[
            f(x) - f(x-dx) \text{ (Backward Difference)}
            \]
            When evaluating the accuracy of your results, it is essential to use <strong>relative error</strong> as a metric. 
            A small simple difference between two quantities does not always imply that the error is negligible. Instead, relative 
            error is calculated as:
            \[
            Relative Error = \frac{\| True - Approximation \|}{\|True \|}
            \]
            Theoritically, as \(dx \to 0\), the approximation of \(df\) becomes more accurate. However, this is not always true in 
            practice due to the limitations of floating-point arithmetic. When \(dx\) becomes too small, the computed difference 
            \(f(x+dx) - f(x) \) may be rounded off to zero by the computer, leading to a loss of accuracy and an increase in the error.
            <br><br>
            In the example, we set dX = np.random.randn(2, 2) * <strong>1e-8</strong>. This is small enough to approximate the derivative 
            but not so small that numerical rounding errors dominate the computation. (Check <strong>machine epsilon</strong>)
            <br><br>
            Finally, to ensure the reliability of your code, avoid choosing arbitrarily "nice" numbers. Instead, generate random 
            <strong>non-integer</strong> values to test the robustness of your implementation and minimize bias in your results.
            <div class="code-container">
                <div class="collapsible-section">
                <button class="collapsible-btn">Show/Hide Code</button>
                <div class="collapsible-content">
                <pre class="python-code">
                    import numpy as np
                    # Matrix X 
                    X = np.random.randn(2, 2)

                    # Differential matrix dX
                    dX = np.random.randn(2, 2) * 1e-8

                    # Define f(X) = X^2
                    f_X = X @ X  

                    # Forward Difference Approximation: f(X + dX) - f(X) 
                    f_approx = (X + dX) @ (X + dX) - f_X

                    # Backward Difference Approximation: f(X) - f(X - dX)
                    b_approx = f_X - (X - dX) @ (X - dX) 

                    # Exact: X dX + dX X
                    exact = X @ dX + dX @ X

                    # Relative errors (by Frobenius norm)
                    f_relative_error =  np.linalg.norm(f_approx - exact, 'fro')  / np.linalg.norm(exact, 'fro')
                    b_relative_error =  np.linalg.norm(b_approx - exact, 'fro')  / np.linalg.norm(exact, 'fro')

                    # Print the results
                    print(f"Input Matrix X:\n {X} \n")
                    print(f"Differential dX:\n {dX}\n")
                    print(f"Foward Difference (f(X + dX) - f(X)):\n {f_approx}\n")
                    print(f"Backward Difference (f(X) - f(X - dX)):\n {b_approx}\n")
                    print(f"Exact (X dX + dX X):\n {exact}\n")
                    print(f"\nRelative Error(Forward): {f_relative_error:.2e}")
                    print(f"\nRelative Error(Backward): {b_relative_error:.2e}")
                </pre>
            </div>
            <button class="run-button" onclick="runPythonCode(this)">Run Code</button>
            <div class="python-output"></div>
            </p>
            </section>
        </div>
        <script src="/js/main.js"></script>
        <script src="/js/runPythonCode.js"></script>
        <script src="/js/collapsible.js"></script>
        
    </body>
</html>