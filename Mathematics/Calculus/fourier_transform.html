---
layout: default
title: Fourier Transform
topic_id: calc-15
level: detail
uses_math: true
uses_python: true
---
<!DOCTYPE html>
<html>
    <body>
        {% include learning_resource_schema.html topic_id=page.topic_id %}
        <div class="hero-section">
            <h1 class="webpage-name">Fourier Transform</h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#continuous">Continuous Fourier Transform</a>
            <a href="#properties">Properties of Fourier Transform</a>
            <a href="#convolution">Convolution Theorem</a>
            <a href="#discrete">Discrete Fourier Transform</a>
            <a href="#fft">Fast Fourier Transform</a>
            <a href="#ml">Applications in Machine Learning</a>
            <a href="#demos">Interactive Demos</a>
        </div>  

        <div class="container">     
            <section id="continuous" class="section-content">
                <h2>Continuous Fourier Transform</h2>
                <p>
                    <a href="fourier_series.html"><strong>Fourier series</strong></a> decompose periodic functions into discrete frequency components. 
                    However, most signals in practice - a spoken sentence, a transient pulse, a neural network's activation - are not periodic. The 
                    <strong>Fourier transform</strong> generalizes the Fourier series to arbitrary functions on \(\mathbb{R}\), replacing the discrete 
                    spectrum with a continuous one. This generalization is the mathematical backbone of signal processing, spectral analysis, and 
                    frequency-domain methods throughout machine learning.
                </p>
                
                <p>
                    To see how this arises, consider a function \(f_L\) periodic with period \(2L\). Its complex Fourier series is:
                    \[
                    f_L(x) = \sum_{n=-\infty}^{\infty} c_n e^{-i\frac{n\pi x}{L}}, \quad c_n = \frac{1}{2L}\int_{-L}^{L} f_L(x)e^{i\frac{n\pi x}{L}} \, dx.
                    \]
                    As \(L \to \infty\), the discrete frequencies \(\omega_n = \frac{n\pi}{L}\) become densely packed with spacing 
                    \(\Delta\omega = \frac{\pi}{L} \to 0\), and the sum approaches an integral. This limiting process yields the 
                    Fourier transform.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Fourier Transform</span> 
                    <p>
                        For a function \(f: \mathbb{R} \to \mathbb{C}\), we define:
                        \[
                        \hat{f}(\xi) = \mathcal{F}\{f\}(\xi) = \int_{-\infty}^{\infty} f(x)e^{i x\xi} \, dx
                        \]
                        where \(\xi \in \mathbb{R}\) is the <strong>frequency variable</strong>.
                    </p>
                    <p>
                        The <strong>inverse Fourier transform</strong> recovers \(f\) from \(\hat{f}\):
                        \[
                        f(x) = \mathcal{F}^{-1}\{\hat{f}\}(x) = \frac{1}{2\pi}\int_{-\infty}^{\infty} \hat{f}(\xi)e^{-i x\xi} \, d\xi.
                        \]
                    </p>
                </div>

                <p>
                    <strong>Note on Conventions:</strong><br>
                    As discussed in <a href="fourier_series.html#convention">Part 14</a>, we use the mathematical/PDE convention 
                    with positive sign in the forward transform and negative in the inverse. Engineering and physics often use the 
                    opposite convention: \(\hat{f}(\omega) = \int_{-\infty}^{\infty} f(t)e^{-i\omega t} \, dt\).
                    Both are mathematically equivalent, just be consistent within your work.
                </p>

                <p>
                    The Fourier transform is well-defined for different function classes:
                </p>
                <ul style="padding-left: 40px;">
                    <li><strong>For \(f \in L^1(\mathbb{R})\)</strong> (absolutely integrable):<br>
                        The integral defining \(\hat{f}\) converges absolutely, and \(\hat{f}\) is bounded and continuous 
                        with \(|\hat{f}(\xi)| \leq \|f\|_{L^1}\).
                    </li>
                    <li><strong>For \(f \in L^2(\mathbb{R})\)</strong> (square-integrable):<br>
                        The transform is defined via limiting procedures (e.g., truncating \(f\) to compact support, then taking limits). 
                        The result satisfies Plancherel's theorem (see Properties section).
                    </li>
                    <li><strong>For tempered distributions:</strong><br>
                        The theory extends to generalized functions, allowing transforms of \(\delta\)-functions, polynomials, 
                        and other non-integrable functions important in applications.
                    </li>
                </ul>

                <div class="proof">
                    <span class="proof-title">Example: Gaussian Function</span>
                    <p>
                        Consider the Gaussian function:
                        \[
                        f(x) = e^{-\frac{x^2}{2\sigma^2}}.
                        \]
                        Its Fourier transform (using the mathematical convention) is:
                        \[
                        \begin{align*}
                        \hat{f}(\xi) &= \int_{-\infty}^{\infty} e^{-\frac{x^2}{2\sigma^2}}e^{i\xi x} \, dx \\\\
                        &= \int_{-\infty}^{\infty} e^{-\frac{x^2}{2\sigma^2} + i\xi x} \, dx.
                        \end{align*}
                        \]
                        Complete the square in the exponent:
                        \[
                        -\frac{x^2}{2\sigma^2} + i\xi x = -\frac{1}{2\sigma^2}(x^2 - 2i\sigma^2\xi x) = -\frac{1}{2\sigma^2}((x - i\sigma^2\xi)^2 + \sigma^4\xi^2).
                        \]
                        Therefore:
                        \[
                        \hat{f}(\xi) = e^{-\frac{\sigma^2\xi^2}{2}} \int_{-\infty}^{\infty} e^{-\frac{(x-i\sigma^2\xi)^2}{2\sigma^2}} \, dx.
                        \]
                        By contour integration (the integrand is analytic and decays exponentially), shifting the path doesn't change the value:
                        \[
                        \int_{-\infty}^{\infty} e^{-\frac{(x-i\sigma^2\xi)^2}{2\sigma^2}} \, dx = \int_{-\infty}^{\infty} e^{-\frac{u^2}{2\sigma^2}} \, du = \sigma\sqrt{2\pi}.
                        \]
                        Thus:
                        \[
                        \boxed{\hat{f}(\xi) = \sigma\sqrt{2\pi} \cdot e^{-\frac{\sigma^2\xi^2}{2}}}.
                        \]
                    </p>
                    <p>
                        This shows that the Gaussian is essentially an eigenfunction of the Fourier transform: its transform is also 
                        Gaussian, with inverse width (narrow in space \(\leftrightarrow\) wide in frequency). This property makes Gaussians 
                        fundamental in uncertainty principles, quantum mechanics, and signal processing.
                    </p>
                </div>
            </section>

            <section id="properties" class="section-content">
                <h2>Properties of Fourier Transform</h2>

                <p>
                    The Fourier transform has several important properties that make it a powerful tool for analysis. 
                    We state these using the mathematical convention \(\hat{f}(\xi) = \int_{-\infty}^{\infty} f(x)e^{ix\xi} \, dx\):
                </p>
                <p>
                    <strong>1. Linearity:</strong><br>
                    \[
                    \mathcal{F}\{\alpha f + \beta g\} = \alpha \mathcal{F}\{f\} + \beta \mathcal{F}\{g\}
                    \]
                    for constants \(\alpha, \beta \in \mathbb{C}\).
                </p>
                <p>
                    <strong>2. Translation (Shift) Property:</strong><br>
                    \[
                    \mathcal{F}\{f(x - a)\}(\xi) = e^{-ia\xi}\hat{f}(\xi)
                    \]
                    A shift in space corresponds to a phase shift in frequency.
                </p>
                <p>
                    <strong>3. Scaling Property:</strong><br>
                    \[
                    \mathcal{F}\{f(ax)\}(\xi) = \frac{1}{|a|}\hat{f}\left(\frac{\xi}{a}\right), \quad a \neq 0
                    \]
                    This embodies the <strong>uncertainty principle</strong>: compressing a signal in time stretches its frequency 
                    spectrum, and vice versa. One cannot localize a signal arbitrarily well in both time and frequency simultaneously.
                </p>
                <p>
                    <strong>4. Differentiation Property:</strong><br>
                    \[
                    \mathcal{F}\{f'(x)\}(\xi) = -i\xi \hat{f}(\xi)
                    \]
                    More generally, for the \(n\)-th derivative:
                    \[
                    \mathcal{F}\{f^{(n)}(x)\}(\xi) = (-i\xi)^n \hat{f}(\xi)
                    \]
                    This transforms differentiation into algebraic multiplication, which is why Fourier methods are powerful for 
                    solving differential equations. Note the sign difference from the engineering convention.
                </p>
                <p>
                    <strong>5. Plancherel's Theorem (Parseval for Non-periodic Functions):</strong><br>
                    <br>
                    For \(f, g \in L^2(\mathbb{R})\):
                    \[
                    \int_{-\infty}^{\infty} f(x)\overline{g(x)} \, dx = \frac{1}{2\pi}\int_{-\infty}^{\infty} \hat{f}(\xi)\overline{\hat{g}(\xi)} \, d\xi.
                    \]
                    In particular, setting \(f = g\):
                    \[
                    \boxed{\|f\|_{L^2}^2 = \int_{-\infty}^{\infty} |f(x)|^2 \, dx = \frac{1}{2\pi}\int_{-\infty}^{\infty} |\hat{f}(\xi)|^2 \, d\xi = \frac{1}{2\pi}\|\hat{f}\|_{L^2}^2}
                    \]
                    This generalizes <a href="fourier_series.html#parseval"><strong>Parseval's identity</strong></a> and shows that the Fourier 
                    transform preserves the \(L^2\) norm up to a constant factor. Equivalently, the normalized map \(f \mapsto \frac{1}{\sqrt{2\pi}}\hat{f}\) 
                    is a unitary (norm-preserving) operator on \(L^2(\mathbb{R})\).
                </p>
                <p>
                    <strong>6. Fourier Inversion Theorem:</strong><br>
                    For suitable functions (e.g., \(f \in L^1(\mathbb{R})\) with \(\hat{f} \in L^1(\mathbb{R})\)), the original function 
                    can be recovered from its Fourier transform:
                    \[
                    f(x) = \frac{1}{2\pi}\int_{-\infty}^{\infty} \hat{f}(\xi)e^{-ix\xi} \, d\xi.
                    \]
                    A useful corollary: applying the Fourier transform twice yields
                    \[
                    \mathcal{F}\{\mathcal{F}\{f\}\}(x) = 2\pi f(-x)
                    \]
                    demonstrating deep symmetry between spatial and frequency domains.
                </p>
            </section>

            <section id="convolution" class="section-content">
                <h2>Convolution Theorem</h2>
                <p>
                    The <strong>convolution</strong> of two functions \(f, g: \mathbb{R} \to \mathbb{C}\) is defined as:
                    \[
                    (f * g)(x) = \int_{-\infty}^{\infty} f(y)g(x-y) \, dy = \int_{-\infty}^{\infty} f(x-y)g(y) \, dy
                    \]
                    (The second equality shows convolution is commutative.)
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Convolution Theorem</span> 
                    <p>
                        The Fourier transform converts convolution into pointwise multiplication:
                        \[
                        \mathcal{F}\{f * g\}(\xi) = \hat{f}(\xi) \cdot \hat{g}(\xi)
                        \]
                        and conversely, the Fourier transform of a product is a (scaled) convolution:
                        \[
                        \mathcal{F}\{f \cdot g\}(\xi) = \frac{1}{2\pi}(\hat{f} * \hat{g})(\xi).
                        \]
                    </p>
                </div>

                <p>
                    This is one of the most important results in applied mathematics. It allows us to:
                </p>

                <ul style="padding-left: 40px;">
                    <li>Replace expensive convolution operations (\(O(n^2)\) for discrete signals) with multiplication after 
                    FFT (\(O(n \log n)\))</li>
                    <li>Understand filtering as multiplication in frequency domain</li>
                    <li>Analyze linear time-invariant systems through their frequency response</li>
                </ul>
                
                <strong>Applications in Computer Science and ML:</strong>

                <ul style="padding-left: 40px;">
                    <li><strong>Signal filtering:</strong> 
                    Low-pass, high-pass, and band-pass filters are convolutions in time domain but simple multiplications in frequency domain</li>
                    <li><strong>Image processing:</strong> Gaussian blur, edge detection (Sobel, Canny), and sharpening are 
                    convolution operations efficiently computed via FFT for large kernels</li>
                    <li><strong>Deep learning:</strong> While CNNs typically use small kernels \((3 \times 3, 5 \times 5)\) where direct convolution 
                    is efficient, FFT-based convolution is useful for:
                        <ul style="padding-left: 40px;">
                            <li>Large kernels in certain architectures</li>
                            <li>Global convolutions in some vision transformers</li>
                            <li>Efficient implementation of depthwise separable convolutions</li>
                        </ul>
                    </li>
                    <li><strong>Probability:</strong> The PDF of \(X + Y\) for independent random variables is 
                    \(f_{X+Y} = f_X * f_Y\), computed efficiently via FFT</li>
                </ul>

                <div class="proof">
                    <span class="proof-title">Proof of Convolution Theorem:</span>
                    <p>
                        Using the mathematical convention with \(\hat{f}(\xi) = \int f(x)e^{ix\xi} \, dx\):
                        \[
                        \begin{align*}
                        \mathcal{F}\{f * g\}(\xi) &= \int_{-\infty}^{\infty} (f * g)(x)e^{ix\xi} \, dx \\\\
                        &= \int_{-\infty}^{\infty} \left(\int_{-\infty}^{\infty} f(y)g(x-y) \, dy\right) e^{ix\xi} \, dx \\\\
                        &= \int_{-\infty}^{\infty} f(y) \left(\int_{-\infty}^{\infty} g(x-y)e^{ix\xi} \, dx\right) dy.
                        \end{align*}
                        \]
                        Substituting \(u = x - y\) (so \(x = u + y\) and \(dx = du\)):
                        \[
                        \begin{align*}
                        &= \int_{-\infty}^{\infty} f(y) \left(\int_{-\infty}^{\infty} g(u)e^{i(u+y)\xi} \, du\right) dy \\\\
                        &= \int_{-\infty}^{\infty} f(y)e^{iy\xi} \left(\int_{-\infty}^{\infty} g(u)e^{iu\xi} \, du\right) dy \\\\
                        &= \left(\int_{-\infty}^{\infty} f(y)e^{iy\xi} \, dy\right) \cdot \left(\int_{-\infty}^{\infty} g(u)e^{iu\xi} \, du\right) \\\\
                        &= \hat{f}(\xi) \cdot \hat{g}(\xi).
                        \end{align*}
                        \]
                        The interchange of integration order is justified by Fubini's theorem when \(f, g \in L^1(\mathbb{R})\).
                    </p>
                </div>
            </section>

            <section id="discrete" class="section-content">
                <h2>Discrete Fourier Transform (DFT)</h2>
                <p>
                    In computational applications, we work with discrete, finite sequences rather than continuous functions. 
                    The <strong>Discrete Fourier Transform (DFT)</strong> is the discrete analog of the continuous Fourier transform.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: DFT & IDFT</span> 
                    <p>
                        For a sequence \(\{x_0, x_1, \ldots, x_{N-1}\}\) of \(N\) complex numbers, the DFT is:
                        \[
                        X_k = \sum_{n=0}^{N-1} x_n e^{-\frac{2\pi i}{N}kn}, \quad k = 0, 1, \ldots, N-1.
                        \]
                        The <strong>inverse DFT (IDFT)</strong> is:
                        \[
                        x_n = \frac{1}{N}\sum_{k=0}^{N-1} X_k e^{\frac{2\pi i}{N}kn}, \quad n = 0, 1, \ldots, N-1.
                        \]
                    </p>
                </div>

                <p>
                    <strong>Connection to Continuous Transform:</strong> The DFT can be viewed as:
                </p>

                <ul style="padding-left: 40px;">
                    <li>Sampling a periodic function at \(N\) equally spaced points</li>
                    <li>Computing Fourier series coefficients for the periodized version</li>
                    <li>Approximating the continuous Fourier transform for band-limited signals (via Shannon-Nyquist sampling theorem)</li>
                </ul>

                <p>
                    <strong>Matrix Formulation:</strong><br>
                    Define \(\omega = e^{-\frac{2\pi i}{N}}\), a primitive \(N\)-th root of unity 
                    (so \(\omega^N = 1\)). The DFT matrix is:
                    \[
                    W = \begin{bmatrix}
                    1 & 1 & 1 & \cdots & 1 \\
                    1 & \omega & \omega^2 & \cdots & \omega^{N-1} \\
                    1 & \omega^2 & \omega^4 & \cdots & \omega^{2(N-1)} \\
                    \vdots & \vdots & \vdots & \ddots & \vdots \\
                    1 & \omega^{N-1} & \omega^{2(N-1)} & \cdots & \omega^{(N-1)^2}
                    \end{bmatrix}
                    \]
                    where \(W_{kn} = \omega^{kn}\). Then:
                    \[
                    \mathbf{X} = W\mathbf{x}, \quad \mathbf{x} = \frac{1}{N}W^*\mathbf{X}
                    \]
                    where \(W^*\) is the conjugate transpose.
                </p>

                <p>
                    <strong>Properties of the DFT Matrix:</strong>
                </p>

                <ul style="padding-left: 40px;">
                    <li><strong>Orthogonality:</strong> \(W^*W = NI\), so \(W^{-1} = \frac{1}{N}W^*\)</li>
                    <li><strong>Symmetry:</strong> \(W\) is symmetric: \(W^T = W\)</li>
                    <li><strong>Eigenvalues:</strong> The eigenvalues of the DFT matrix are \(\pm 1, \pm i\) (for \(N = 4k\))</li>
                    <li><strong>Circulant diagonalization:</strong> The DFT matrix diagonalizes all circulant matrices</li>
                </ul>

                <p>
                    <strong>Computational Complexity:</strong>
                </p>
                   
                <ul style="padding-left: 40px;">
                    <li><strong>Direct computation:</strong> \(O(N^2)\) complex multiplications and additions</li>
                    <li><strong>Fast Fourier Transform:</strong> \(O(N \log N)\) operations (see next section)</li>
                </ul>
                <p>
                    <strong>Practical Considerations for CS/ML:</strong>
                </p>
                    
                <ul style="padding-left: 40px;">
                    <li><strong>Zero-padding:</strong> Padding sequences to powers of 2 enables efficient radix-2 FFT algorithms</li>
                    <li><strong>Windowing:</strong> Applying window functions (Hamming, Hann, Blackman) reduces spectral leakage from finite-length effects</li>
                    <li><strong>Real-valued signals:</strong> For real inputs, \(X_{N-k} = \overline{X_k}\) (Hermitian symmetry), 
                    allowing optimization to compute only half the spectrum using rfft</li>
                    <li><strong>Normalization:</strong> Different software uses different conventions; NumPy uses \(\frac{1}{N}\) in IFFT only</li>
                </ul>
            </section>

            <section id="fft" class="section-content">
                <h2>Fast Fourier Transform (FFT)</h2>

                <p>
                    The <strong>Fast Fourier Transform (FFT)</strong> is not a different transform but an efficient algorithm for 
                    computing the DFT, reducing complexity from \(O(N^2)\) to \(O(N \log N)\).
                </p>

                <p>
                    <strong>Cooley-Tukey Algorithm (Radix-2 FFT):</strong><br>
                    The key insight is to exploit the structure of the DFT matrix using divide-and-conquer. For \(N = 2^m\), 
                    split the input into even and odd indices:
                    \[
                    \begin{align*}
                    X_k &= \sum_{n=0}^{N-1} x_n \omega^{kn} \\\\
                    &= \sum_{j=0}^{N/2-1} x_{2j} \omega^{k(2j)} + \sum_{j=0}^{N/2-1} x_{2j+1} \omega^{k(2j+1)} \\\\
                    &= \sum_{j=0}^{N/2-1} x_{2j} (\omega^2)^{kj} + \omega^k \sum_{j=0}^{N/2-1} x_{2j+1} (\omega^2)^{kj}.
                    \end{align*}
                    \]
                    Note that \(\omega^2 = e^{-\frac{4\pi i}{N}} = e^{-\frac{2\pi i}{N/2}}\) is a primitive \((N/2)\)-th root of unity.
                </p>
                <p>
                    Let \(E_k\) be the DFT of the even-indexed subsequence and \(O_k\) the DFT of odd-indexed subsequence. 
                    Using the periodicity of the DFT, for \(k = 0, 1, \ldots, N/2-1\):
                    \[
                    X_k = E_k + \omega^k O_k
                    \]
                    \[
                    X_{k+N/2} = E_k - \omega^k O_k
                    \]
                    (using the fact that \(\omega^{k+N/2} = -\omega^k\) since \(\omega^{N/2} = e^{-i\pi} = -1\)).
                </p>
                
                <p>
                    This gives the recurrence \(T(N) = 2T(N/2) + O(N)\), yielding \(T(N) = O(N \log N)\) by the Master theorem.
                </p>

                <p>
                    <strong>Other FFT Algorithms:</strong>
                </p>

                <ul style="padding-left: 40px;">
                    <li><strong>Radix-4, Radix-8:</strong> Reduce the number of complex multiplications by processing 4 or 8 points at once</li>
                    <li><strong>Split-radix FFT:</strong> Combines radix-2 and radix-4 for optimal operation count</li>
                    <li><strong>Prime-factor algorithm (Good-Thomas):</strong> For \(N = N_1 N_2\) with \(\gcd(N_1, N_2) = 1\)</li>
                    <li><strong>Chirp Z-transform (Bluestein):</strong> Computes DFT of any size via convolution</li>
                </ul>

                <P>
                    <strong>Implementation Considerations:</strong>
                </P>
               
                <ul style="padding-left: 40px;">
                    <li><strong>Bit-reversal permutation:</strong> Required for in-place Cooley-Tukey algorithm</li>
                    <li><strong>Twiddle factors:</strong> Precomputing \(\omega^k = e^{-2\pi ik/N}\) reduces trigonometric computations</li>
                    <li><strong>Cache optimization:</strong> FFTW uses self-tuning to optimize for specific hardware</li>
                    <li><strong>SIMD vectorization:</strong> Modern CPUs can compute multiple FFT butterflies in parallel</li>
                    <li><strong>Numerical stability:</strong> Use of split-radix reduces roundoff error accumulation</li>
                </ul>
                
                <h3><strong>Python Example:</strong></h3>
                <div class="code-container">
                    <div class="collapsible-section">
                        <button class="collapsible-btn">Show/Hide Code</button>
                        <div class="collapsible-content">
                            <pre class="python-code">
                                import numpy as np
                                import matplotlib.pyplot as plt

                                # Generate a signal with multiple frequency components
                                fs = 1000  # Sampling frequency (Hz)
                                t = np.linspace(0, 1, fs, endpoint=False)
                                signal = (np.sin(2*np.pi*50*t) +           # 50 Hz component
                                        0.5*np.sin(2*np.pi*120*t) +      # 120 Hz component
                                        0.3*np.cos(2*np.pi*200*t))       # 200 Hz component

                                # Add some Gaussian noise
                                np.random.seed(42)  # For reproducibility
                                signal += 0.3 * np.random.randn(len(t))

                                # Compute FFT
                                fft_vals = np.fft.fft(signal)
                                fft_freq = np.fft.fftfreq(len(signal), d=1/fs)

                                # Only plot positive frequencies (due to Hermitian symmetry for real signals)
                                pos_mask = fft_freq >= 0
                                plt.figure(figsize=(12, 4))

                                plt.subplot(1, 2, 1)
                                plt.plot(t[:100], signal[:100])
                                plt.xlabel('Time (s)')
                                plt.ylabel('Amplitude')
                                plt.title('Signal (first 100 samples)')
                                plt.grid(True, alpha=0.3)

                                plt.subplot(1, 2, 2)
                                plt.plot(fft_freq[pos_mask], np.abs(fft_vals[pos_mask])/len(signal)*2)
                                plt.xlabel('Frequency (Hz)')
                                plt.ylabel('Magnitude')
                                plt.title('Frequency Spectrum (Single-sided)')
                                plt.xlim(0, 300)
                                plt.grid(True, alpha=0.3)
                                plt.tight_layout()
                                plt.show()

                                # Verify Parseval's theorem
                                energy_time = np.sum(np.abs(signal)**2)
                                energy_freq = np.sum(np.abs(fft_vals)**2) / len(signal)
                                print(f"Energy in time domain: {energy_time:.2f}")
                                print(f"Energy in frequency domain: {energy_freq:.2f}")
                                print(f"Relative error: {abs(energy_time - energy_freq)/energy_time:.2e}")
                            </pre>
                        </div>
                    </div>
                </div>

            </section>

            <section id="ml" class="section-content">
                <h2>Applications in Machine Learning</h2>
                <p>
                    Fourier methods are fundamental to modern machine learning, particularly in areas requiring efficient computation, 
                    signal processing, and function approximation. Here we highlight three significant applications.
                </p>
                    
                <h3><strong>1. Audio and Speech Processing:</strong></h3>
                <p>
                    Modern speech recognition models like <strong>Whisper</strong> (OpenAI, 2022) fundamentally rely on Fourier transforms 
                    for feature extraction. Raw audio waveforms are converted into <strong>log-Mel spectrograms</strong> using the Short-Time 
                    Fourier Transform (STFT): the audio is windowed into overlapping segments, each transformed via FFT to obtain frequency 
                    content, then mapped to the Mel scale (which approximates human auditory perception). This frequency-domain representation 
                    serves as input to the neural network, enabling robust transcription across languages and noisy environments.
                </p>
                <p>
                    <strong>Reference:</strong> <a href="https://openai.com/index/whisper/">Radford et al., "Robust Speech Recognition via Large-Scale Weak Supervision" (2022)</a>
                </p>
                    
                <h3><strong>2. Fourier Neural Operators (FNO) for Scientific Computing:</strong></h3>
                <p>
                    Introduced by Li et al. (NeurIPS 2020), FNOs learn operators directly in Fourier space, achieving 
                    1000x speedup over traditional PDE solvers. The key idea: parameterize the kernel \(\hat{k}(\xi)\) 
                    in frequency domain, then multiply with the Fourier transform of the input.
                </p>

                <strong>Architecture sketch:</strong>
                <ol style="padding-left: 40px;">
                    <li>Lift input to higher-dimensional channel space</li>
                    <li>Apply spectral convolution: \(\text{FFT} \to \text{multiply weights} \to \text{IFFT}\)</li>
                    <li>Add local convolution \((1\times 1)\) for high-frequency details</li>
                    <li>Project to output</li>
                </ol>
                <p>
                    <strong>Reference:</strong> <a href="https://arxiv.org/abs/2010.08895">Li et al., "Fourier Neural Operator for Parametric PDEs"</a>
                </p>
                    
                <h3><strong>3. Positional Encoding in Neural Networks:</strong></h3>
                <p>
                    Neural networks have a <strong>spectral bias</strong>â€”they tend to learn low-frequency functions more easily than 
                    high-frequency ones. Fourier feature mappings overcome this limitation by lifting low-dimensional inputs into 
                    higher-dimensional spaces via sinusoidal functions. For instance, the positional encoding used in 
                    <strong>Neural Radiance Fields (NeRF)</strong> maps a scalar coordinate \(p\) to:
                    \[
                    \gamma(p) = \left[\sin(2^0 \pi p), \cos(2^0 \pi p), \ldots, \sin(2^{L-1} \pi p), \cos(2^{L-1} \pi p)\right]
                    \]
                    This enables the network to capture fine geometric details essential for photorealistic 3D scene reconstruction.
                    Similar Fourier-based encodings appear in Transformers (sinusoidal positional encoding) and modern LLMs 
                    (Rotary Position Embedding/RoPE).
                </p>
                <p>
                    <strong>References:</strong> 
                    <a href="https://arxiv.org/abs/2003.08934">Mildenhall et al., "NeRF: Representing Scenes as Neural Radiance Fields" (ECCV 2020)</a>;
                    <a href="https://arxiv.org/abs/2006.10739">Tancik et al., "Fourier Features Let Networks Learn High Frequency Functions" (NeurIPS 2020)</a>
                </p>
            </section>
       
            <section id="demos" class="section-content">
                <h2>Interactive Demos</h2>
                <p>
                    Now that we've covered the theory, let's see the Fourier Transform in action.
                    We will start with a simple 1D signal to understand the core principles, then move to a 2D image
                    to see a practical application (and a great example of the Convolution Theorem).
                </p>


                <div class="tab-content" id="demoTabContent" style="padding: 20px; border: 1px solid rgba(255, 255, 255, 0.1); border-radius: 8px; background: transparent;">
                    
                    <div class="demo-section" id="demo1d-pane">
                        <h3 style="color: #66bb6a;">1D Signal & Frequency Spectrum</h3>
                        <p>
                            This demo shows how several sine waves (+ noise) are combined in the <strong>Time Domain</strong> to create a complex signal.
                            Simultaneously, it computes the Fourier Transform (FFT) of that combined signal to show which frequencies are dominant in the <strong>Frequency Domain</strong> (the spectrum).
                            Move the sliders to see how the two domains are linked in real-time. This is the fundamental concept of Fourier Analysis.
                        </p>
                        <div id="fourier_visualizer_1d"></div>
                    </div>

                    <div class="demo-section" id="demo2d-pane" style="margin-top: 40px;">
                        <h3 style="color: #66bb6a;">2D Image & Frequency Domain Filtering</h3>
                        <p>
                            An image is just a 2D signal. This demo computes the 2D FFT of an image to show its <strong>Frequency Spectrum</strong>.
                            The center of the spectrum represents low frequencies (blurry parts of the image), while the edges represent high frequencies (edges and details).
                            As you learned in the "Convolution Theorem" section, multiplying in the frequency domain is equivalent to convolution in the spatial domain.
                            Try applying a <strong>Low-pass filter</strong> (which only keeps the center) to see the image blur, or a <strong>High-pass filter</strong> (which only keeps the edges) to extract details.
                        </p>
                        <div id="fourier_visualizer_2d"></div>
                    </div>
                </div>
            </section>      

        </div>

        <script src="/js/collapsible.js"></script>
        <script src="/js/main.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
        <script src="/js/sec2_p15_fft.js"></script>
    </body>
</html>