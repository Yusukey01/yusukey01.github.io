---
layout: default
title: Fourier Transform
level: detail
description: Learn about the Fourier transform, its properties, and applications to signal processing and machine learning.
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body>
        <!-- LearningResource Schema for Fourier Transform -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "Fourier Transform",
        "description": "Learn about the Fourier transform, its properties, and applications to signal processing and machine learning",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "active",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator",
            "knowsAbout": [
            "Fourier Transform",
            "Signal Processing",
            "Frequency Analysis",
            "Fast Fourier Transform",
            "Convolution Theorem",
            "Machine Learning",
            "Harmonic Analysis"
            ]
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
        },
        "about": [
            { "@type": "Thing", "name": "Fourier Transform" },
            { "@type": "Thing", "name": "Discrete Fourier Transform" },
            { "@type": "Thing", "name": "Fast Fourier Transform" },
            { "@type": "Thing", "name": "Convolution Theorem" },
            { "@type": "Thing", "name": "Frequency Domain" },
            { "@type": "Thing", "name": "Plancherel Theorem" },
            { "@type": "Thing", "name": "Random Fourier Features" }
        ],
        "teaches": [
            "Understanding the continuous Fourier transform",
            "Computing discrete Fourier transforms efficiently",
            "Applying the convolution theorem",
            "Working in frequency domain representation",
            "Understanding the Fast Fourier Transform algorithm",
            "Connecting Fourier methods to machine learning",
            "Applying Fourier analysis to signal processing"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Calculus to Optimization & Analysis",
            "description": "Explore optimization techniques and mathematical analysis with applications",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "II",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT4H",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>
        <div class="hero-section">
            <h1 class="webpage-name">Fourier Transform
            </h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#continuous">Continuous Fourier Transform</a>
            <a href="#properties">Properties of Fourier Transform</a>
            <a href="#convolution">Convolution Theorem</a>
            <a href="#discrete">Discrete Fourier Transform</a>
            <a href="#fft">Fast Fourier Transform</a>
            <a href="#ml">Applications in Machine Learning</a>
        </div>  

        <div class="container">     
            <section id="continuous" class="section-content">
            <h2>Continuous Fourier Transform</h2>
            <p>
            The <strong>Fourier transform</strong> extends the ideas of <a href="fourier_series.html">Fourier series</a> 
            from periodic functions to non-periodic functions defined on \(\mathbb{R}\). While Fourier series decompose 
            periodic signals into discrete frequency components, the Fourier transform decomposes general signals into 
            a continuous spectrum of frequencies.
            <br><br>
            For a function \(f: \mathbb{R} \to \mathbb{C}\) (or \(\mathbb{R} \to \mathbb{R}\)), the <strong>Fourier transform</strong> 
            \(\hat{f}\) is defined by:
            \[
            \hat{f}(\omega) = \mathcal{F}\{f\}(\omega) = \int_{-\infty}^{\infty} f(x)e^{-i\omega x} \, dx
            \]
            where \(\omega \in \mathbb{R}\) is the <strong>frequency variable</strong> (or <strong>angular frequency</strong>).
            <br><br>
            The <strong>inverse Fourier transform</strong> recovers \(f\) from \(\hat{f}\):
            \[
            f(x) = \mathcal{F}^{-1}\{\hat{f}\}(x) = \frac{1}{2\pi}\int_{-\infty}^{\infty} \hat{f}(\omega)e^{i\omega x} \, d\omega
            \]
            <br>
            Note: Different conventions exist for the placement of the factor \(\frac{1}{2\pi}\). Some authors place 
            \(\frac{1}{\sqrt{2\pi}}\) in both the forward and inverse transforms to make them symmetric. The convention 
            above is common in mathematics and engineering.
            <br><br>
            The Fourier transform is well-defined for functions in \(L^1(\mathbb{R})\) (absolutely integrable functions):
            \[
            \int_{-\infty}^{\infty} |f(x)| \, dx < \infty
            \]
            and can be extended to \(L^2(\mathbb{R})\) (square-integrable functions) using limiting procedures.
            <div class="proof">
                <span class="proof-title">Example: Gaussian Function</span>
                Consider the Gaussian function:
                \[
                f(x) = e^{-\frac{x^2}{2}}
                \]
                Its Fourier transform is:
                \[
                \begin{align*}
                \hat{f}(\omega) &= \int_{-\infty}^{\infty} e^{-\frac{x^2}{2}}e^{-i\omega x} \, dx \\\\
                &= \int_{-\infty}^{\infty} e^{-\frac{x^2}{2} - i\omega x} \, dx
                \end{align*}
                \]
                Complete the square in the exponent:
                \[
                -\frac{x^2}{2} - i\omega x = -\frac{1}{2}(x^2 + 2i\omega x) = -\frac{1}{2}\left((x + i\omega)^2 - (i\omega)^2\right) = -\frac{(x + i\omega)^2}{2} - \frac{\omega^2}{2}
                \]
                Therefore:
                \[
                \hat{f}(\omega) = e^{-\frac{\omega^2}{2}} \int_{-\infty}^{\infty} e^{-\frac{(x+i\omega)^2}{2}} \, dx
                \]
                By Cauchy's integral theorem (contour integration in the complex plane), shifting the contour of 
                integration does not change the value of the integral, so:
                \[
                \int_{-\infty}^{\infty} e^{-\frac{(x+i\omega)^2}{2}} \, dx = \int_{-\infty}^{\infty} e^{-\frac{x^2}{2}} \, dx = \sqrt{2\pi}
                \]
                Thus:
                \[
                \hat{f}(\omega) = \sqrt{2\pi} \cdot e^{-\frac{\omega^2}{2}}
                \]
                This remarkable result shows that the Gaussian function is an <strong>eigenfunction</strong> of the Fourier 
                transform: its transform is also a Gaussian (up to a constant). This property makes Gaussian functions 
                fundamental in signal processing, probability theory, and quantum mechanics.
            </div>
            </p>
            </section>

            <section id="properties" class="section-content">
            <h2>Properties of Fourier Transform</h2>
            <p>
            The Fourier transform has several important properties that make it a powerful tool for analysis:
            <br><br>
            <strong>1. Linearity:</strong>
            \[
            \mathcal{F}\{\alpha f + \beta g\} = \alpha \mathcal{F}\{f\} + \beta \mathcal{F}\{g\}
            \]
            for constants \(\alpha, \beta \in \mathbb{C}\).
            <br><br>
            <strong>2. Translation (Shift) Property:</strong>
            \[
            \mathcal{F}\{f(x - a)\}(\omega) = e^{-i\omega a}\hat{f}(\omega)
            \]
            A shift in time corresponds to a phase shift in frequency.
            <br><br>
            <strong>3. Modulation Property:</strong>
            \[
            \mathcal{F}\{e^{i\omega_0 x}f(x)\}(\omega) = \hat{f}(\omega - \omega_0)
            \]
            Multiplication by a complex exponential shifts the frequency spectrum.
            <br><br>
            <strong>4. Scaling Property:</strong>
            \[
            \mathcal{F}\{f(ax)\}(\omega) = \frac{1}{|a|}\hat{f}\left(\frac{\omega}{a}\right), \quad a \neq 0
            \]
            Compressing a signal in time stretches its frequency spectrum, and vice versa. This is known as the 
            <strong>uncertainty principle</strong> in signal processing.
            <br><br>
            <strong>5. Differentiation Property:</strong>
            \[
            \mathcal{F}\{f'(x)\}(\omega) = i\omega \hat{f}(\omega)
            \]
            More generally, for the \(n\)-th derivative:
            \[
            \mathcal{F}\{f^{(n)}(x)\}(\omega) = (i\omega)^n \hat{f}(\omega)
            \]
            This transforms differentiation into multiplication, which is why Fourier transforms are useful for solving 
            differential equations.
            <br><br>
            <strong>6. Plancherel's Theorem (Generalized Parseval):</strong>
            \[
            \int_{-\infty}^{\infty} |f(x)|^2 \, dx = \frac{1}{2\pi}\int_{-\infty}^{\infty} |\hat{f}(\omega)|^2 \, d\omega
            \]
            This generalizes <a href="fourier_series.html#parseval">Parseval's identity</a> to the continuous case, 
            showing energy conservation between time and frequency domains. The Fourier transform is a 
            <strong>unitary operator</strong> on \(L^2(\mathbb{R})\) (up to normalization).
            <br><br>
            <strong>7. Duality (Fourier Inversion):</strong>
            \[
            \mathcal{F}\{\mathcal{F}\{f\}\}(x) = 2\pi f(-x)
            \]
            Applying the Fourier transform twice (up to normalization and sign change) returns the original function, 
            demonstrating a deep symmetry between time and frequency domains.
            </p>
            </section>

            <section id="convolution" class="section-content">
            <h2>Convolution Theorem</h2>
            <p>
            The <strong>convolution</strong> of two functions \(f\) and \(g\) is defined as:
            \[
            (f * g)(x) = \int_{-\infty}^{\infty} f(t)g(x-t) \, dt
            \]
            <br>
            The <strong>convolution theorem</strong> states that the Fourier transform converts convolution into pointwise 
            multiplication:
            \[
            \mathcal{F}\{f * g\}(\omega) = \hat{f}(\omega) \cdot \hat{g}(\omega)
            \]
            and conversely:
            \[
            \mathcal{F}\{f \cdot g\}(\omega) = \frac{1}{2\pi}(\hat{f} * \hat{g})(\omega)
            \]
            <br>
            This is one of the most important properties of the Fourier transform. In many applications, computing 
            a convolution directly is computationally expensive (\(O(n^2)\) operations for discrete signals), but 
            using the FFT to compute the transform, multiplying in frequency domain, and transforming back can be 
            much faster (\(O(n \log n)\) operations).
            <br><br>
            The convolution theorem is fundamental in:
            <ul style="padding-left: 40px;">
                <li><strong>Signal processing:</strong> Filtering operations are implemented as convolutions</li>
                <li><strong>Image processing:</strong> Blurring, sharpening, and edge detection use convolution kernels</li>
                <li><strong>Deep learning:</strong> Convolutional neural networks (CNNs) use convolution operations</li>
                <li><strong>Probability theory:</strong> The PDF of a sum of independent random variables is the convolution 
                of their individual PDFs</li>
            </ul>
            <div class="proof">
                <span class="proof-title">Proof of Convolution Theorem:</span>
                Starting with the definition of the Fourier transform:
                \[
                \begin{align*}
                \mathcal{F}\{f * g\}(\omega) &= \int_{-\infty}^{\infty} (f * g)(x)e^{-i\omega x} \, dx \\\\
                &= \int_{-\infty}^{\infty} \left(\int_{-\infty}^{\infty} f(t)g(x-t) \, dt\right) e^{-i\omega x} \, dx \\\\
                &= \int_{-\infty}^{\infty} f(t) \left(\int_{-\infty}^{\infty} g(x-t)e^{-i\omega x} \, dx\right) dt
                \end{align*}
                \]
                Let \(u = x - t\), then \(dx = du\) and:
                \[
                \begin{align*}
                &= \int_{-\infty}^{\infty} f(t) \left(\int_{-\infty}^{\infty} g(u)e^{-i\omega (u+t)} \, du\right) dt \\\\
                &= \int_{-\infty}^{\infty} f(t)e^{-i\omega t} \left(\int_{-\infty}^{\infty} g(u)e^{-i\omega u} \, du\right) dt \\\\
                &= \left(\int_{-\infty}^{\infty} f(t)e^{-i\omega t} \, dt\right) \cdot \left(\int_{-\infty}^{\infty} g(u)e^{-i\omega u} \, du\right) \\\\
                &= \hat{f}(\omega) \cdot \hat{g}(\omega)
                \end{align*}
                \]
            </div>
            </p>
            </section>

            <section id="discrete" class="section-content">
            <h2>Discrete Fourier Transform (DFT)</h2>
            <p>
            In practice, we often work with discrete, finite sequences of data rather than continuous functions. 
            The <strong>Discrete Fourier Transform (DFT)</strong> is the discrete analog of the continuous Fourier transform.
            <br><br>
            For a sequence of \(N\) complex numbers \(\{x_0, x_1, \ldots, x_{N-1}\}\), the DFT is defined as:
            \[
            X_k = \sum_{n=0}^{N-1} x_n e^{-\frac{2\pi i}{N}kn}, \quad k = 0, 1, \ldots, N-1
            \]
            <br>
            The <strong>inverse DFT (IDFT)</strong> recovers the original sequence:
            \[
            x_n = \frac{1}{N}\sum_{k=0}^{N-1} X_k e^{\frac{2\pi i}{N}kn}, \quad n = 0, 1, \ldots, N-1
            \]
            <br>
            The DFT can be expressed as a matrix multiplication. Define the \(N \times N\) <strong>DFT matrix</strong>:
            \[
            W = \begin{bmatrix}
            1 & 1 & 1 & \cdots & 1 \\
            1 & \omega & \omega^2 & \cdots & \omega^{N-1} \\
            1 & \omega^2 & \omega^4 & \cdots & \omega^{2(N-1)} \\
            \vdots & \vdots & \vdots & \ddots & \vdots \\
            1 & \omega^{N-1} & \omega^{2(N-1)} & \cdots & \omega^{(N-1)^2}
            \end{bmatrix}
            \]
            where \(\omega = e^{-\frac{2\pi i}{N}}\) is a primitive \(N\)-th root of unity.
            <br><br>
            Then the DFT can be written as:
            \[
            \mathbf{X} = W\mathbf{x}
            \]
            where \(\mathbf{x} = [x_0, x_1, \ldots, x_{N-1}]^T\) and \(\mathbf{X} = [X_0, X_1, \ldots, X_{N-1}]^T\).
            <br><br>
            The DFT matrix has remarkable properties:
            <ul style="padding-left: 40px;">
                <li>The columns of \(W\) are orthogonal (but not orthonormal)</li>
                <li>\(W^*W = NI\), where \(W^*\) is the conjugate transpose</li>
                <li>The inverse is \(W^{-1} = \frac{1}{N}W^*\)</li>
            </ul>
            <br>
            Direct computation of the DFT using this matrix multiplication requires \(O(N^2)\) operations. However, 
            the <strong>Fast Fourier Transform (FFT)</strong> algorithm reduces this to \(O(N \log N)\), making 
            Fourier analysis practical for large datasets.
            </p>
            </section>

            <section id="fft" class="section-content">
            <h2>Fast Fourier Transform (FFT)</h2>
            <p>
            The <strong>Fast Fourier Transform (FFT)</strong> is not a different transform, but rather an efficient 
            algorithm for computing the DFT. The most common FFT algorithm is the <strong>Cooley-Tukey algorithm</strong>, 
            which uses a divide-and-conquer approach.
            <br><br>
            The key insight is that the DFT of size \(N\) can be expressed in terms of two DFTs of size \(\frac{N}{2}\) 
            (assuming \(N\) is a power of 2). We split the sequence into even and odd indexed elements:
            \[
            \begin{align*}
            X_k &= \sum_{n=0}^{N-1} x_n e^{-\frac{2\pi i}{N}kn} \\\\
            &= \sum_{m=0}^{N/2-1} x_{2m} e^{-\frac{2\pi i}{N}k(2m)} + \sum_{m=0}^{N/2-1} x_{2m+1} e^{-\frac{2\pi i}{N}k(2m+1)} \\\\
            &= \sum_{m=0}^{N/2-1} x_{2m} e^{-\frac{2\pi i}{N/2}km} + e^{-\frac{2\pi i}{N}k}\sum_{m=0}^{N/2-1} x_{2m+1} e^{-\frac{2\pi i}{N/2}km}
            \end{align*}
            \]
            Define \(E_k\) as the \(k\)-th element of the DFT of the even-indexed subsequence and \(O_k\) as the \(k\)-th 
            element of the DFT of the odd-indexed subsequence. Then for \(k = 0, 1, \ldots, N/2-1\):
            \[
            X_k = E_k + e^{-\frac{2\pi i}{N}k}O_k
            \]
            and using the periodicity of DFT, for \(k = N/2, \ldots, N-1\):
            \[
            X_k = E_{k-N/2} - e^{-\frac{2\pi i}{N}(k-N/2)}O_{k-N/2}
            \]
            <br>
            This decomposition can be applied recursively when \(N\) is a power of 2. The recurrence relation is:
            \[
            T(N) = 2T(N/2) + O(N)
            \]
            which gives:
            \[
            T(N) = O(N \log N)
            \]
            <br>
            The FFT algorithm revolutionized signal processing when it was popularized by Cooley and Tukey in 1965. 
            It made real-time digital signal processing feasible and is now fundamental to:
            <ul style="padding-left: 40px;">
                <li>Audio and video compression (MP3, JPEG, MPEG)</li>
                <li>Wireless communications (OFDM in WiFi, 4G/5G)</li>
                <li>Medical imaging (MRI reconstruction)</li>
                <li>Numerical solution of PDEs</li>
            </ul>
            <br>
            Modern implementations like FFTW (Fastest Fourier Transform in the West) use advanced techniques 
            to achieve near-optimal performance on various hardware architectures.
            </p>
            </section>

            <section id="ml" class="section-content">
            <h2>Applications in Machine Learning</h2>
            <p>
            Fourier methods have numerous applications in modern machine learning and data science:
            <br><br>
            <strong>1. Random Fourier Features:</strong>
            <br>
            As mentioned in the <a href="../Machine_learning/intro_classification.html">classification section</a>, 
            <strong>random Fourier features</strong> provide an explicit approximation to shift-invariant kernel functions. 
            For a shift-invariant kernel \(k(x, y) = k(x - y)\), <strong>Bochner's theorem</strong> states that \(k\) 
            can be represented as the Fourier transform of a non-negative measure. Specifically, if \(k\) is a continuous, 
            positive definite, shift-invariant kernel on \(\mathbb{R}^d\), then there exists a non-negative finite measure 
            \(\mu\) such that:
            \[
            k(\delta) = \int_{\mathbb{R}^d} e^{i\omega^T\delta} d\mu(\omega)
            \]
            <br>
            For the RBF (Gaussian) kernel \(k(\delta) = e^{-\frac{\|\delta\|^2}{2\sigma^2}}\), the measure corresponds to 
            \(\mu \sim \mathcal{N}(0, \sigma^{-2}I)\).
            <br><br>
            We can approximate the kernel using Monte Carlo sampling. For real-valued features:
            \[
            z_\omega(x) = \sqrt{2}\cos(\omega^Tx + b)
            \]
            where \(\omega\) is sampled from \(\mu\) and \(b \sim \text{Uniform}[0, 2\pi]\). The feature map is:
            \[
            \phi(x) = \sqrt{\frac{2}{D}}\begin{bmatrix} \cos(\omega_1^Tx + b_1) \\ \vdots \\ \cos(\omega_D^Tx + b_D) \end{bmatrix}
            \]
            which satisfies \(\mathbb{E}_{\omega, b}[z_\omega(x)z_\omega(y)] = k(x-y)\).
            <br><br>
            This technique, introduced by Rahimi and Recht (2007), allows kernel methods to scale to large datasets by 
            converting them into linear methods with complexity \(O(nD)\) instead of \(O(n^2)\).
            <br><br>
            <strong>2. Time Series Analysis:</strong>
            <br>
            Fourier transforms are essential for analyzing temporal patterns:
            <ul style="padding-left: 40px;">
                <li><strong>Spectral analysis:</strong> Identifying dominant frequencies and periodicities in data 
                (used in finance, climate science, neuroscience)</li>
                <li><strong>Seasonal decomposition:</strong> Separating trend, seasonal, and residual components 
                using Fourier basis functions</li>
                <li><strong>Filtering:</strong> Removing noise or extracting specific frequency bands</li>
                <li><strong>Forecasting:</strong> Using Fourier features as inputs to ML models for capturing periodic patterns</li>
            </ul>
            <br>
            <strong>3. Signal and Image Processing:</strong>
            <br>
            FFT-based methods are ubiquitous in modern data processing:
            <ul style="padding-left: 40px;">
                <li><strong>Audio processing:</strong> Speech recognition systems convert audio to spectrograms 
                (frequency representations over time) using Short-Time Fourier Transform (STFT)</li>
                <li><strong>Image compression:</strong> JPEG uses the Discrete Cosine Transform (DCT), closely related 
                to the DFT, to compress images</li>
                <li><strong>Data augmentation:</strong> Manipulating frequency components for augmenting training data 
                (e.g., SpecAugment for speech)</li>
            </ul>
            <br>
            <strong>4. Efficient Computation in Neural Networks:</strong>
            <br>
            While direct application of FFT in neural networks is uncommon in practice, understanding the Fourier 
            perspective provides valuable intuition:
            <ul style="padding-left: 40px;">
                <li>Convolution operations in CNNs can theoretically be computed via FFT for very large kernels</li>
                <li>Spectral analysis helps understand which frequencies neural networks learn to represent</li>
                <li>Frequency-domain data augmentation (phase/amplitude manipulation) improves model robustness</li>
            </ul>
            <br><br>
            Understanding Fourier methods provides essential intuition for signal processing, time series analysis, 
            and frequency-domain thinkingâ€”skills that are invaluable across machine learning, data science, and 
            computational applications.
            </p>
            </section>
        </div>
        <script src="/js/main.js"></script>
    </body>
</html>