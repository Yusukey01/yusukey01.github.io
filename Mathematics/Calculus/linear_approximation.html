---
layout: default
title: Linear Approximations
topic_id: calc-1
level: detail 
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body>
        {% include learning_resource_schema.html topic_id=page.topic_id %}
        
        <div class="hero-section">
            <h1 class="webpage-name">The Derivative of \(f:\mathbb{R}^n \rightarrow \mathbb{R}\)
            </h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#lapp">Linear Approximations</a>
            <a href="#diff">Differentials</a>
            <a href="#ex1">Example 1: \(f(x) = x^Tx\) where \(x \in \mathbb{R}^n\)</a>
            <a href="#ex2">Example 2: \(f(x) = x^TAx\) where \(x \in \mathbb{R}^n\) and \(A \in \mathbb{R}^{n \times n}\)</a>
            <a href="#ex3">Example 3: \(f(x) = \| x \|_2\) where \(x \in \mathbb{R}^n\)</a>   
        </div> 

        <div class="container">  
           
            <section id="lapp" class="section-content">
                <h2>Linear Approximations</h2>
                <p>
                    In the study of complex systems - from the orbits of planets to the loss landscapes of deep neural networks - most functions are 
                    inherently nonlinear and difficult to solve directly. Linear approximation is the fundamental strategy of calculus: it approximates a 
                    complex function \(f(x)\) near a specific point \(x_o\) using the simplest possible tool - a linear function. 
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Linearization</span>
                    <p>
                        The <strong>linearization</strong> of \(f\) at \(x_o\) is the linear function \(L(x)\) defined by:
                        \[
                        L(x) = f(x_o) + f'(x_o)(x - x_o) \approx f(x) \tag{1}
                        \]
                        where \(f'(x_o)\) represents the instantaneous rate of change at \(x_o\):
                        \[
                        f'(x_o) = \lim_{x \to x_o} \frac{f(x)-f(x_o)}{x-x_o}.
                        \]
                    </p>
                </div>

                <p>
                    By constructing the tangent line at \((x_o, f(x_o))\), we create a local model where the function behaves predictably. 
                    This local predictability is what allows optimization algorithms to take "steps" toward a minimum, even when the global 
                    shape of the function is unknown.
                </p>
 
                <p>
                    Equivalently, from equation (1), 
                    \[
                    f(x) - f(x_o) \approx f'(x_o)(x -x_o) 
                    \]
                    The graph of \(L\) is the tangent line at \((x_o, f(x_o))\). Linear approximations form the foundation of differentiation 
                    and provide a <strong>local</strong> linear model for \(f(x)\). This local predictability is what allows optimization algorithms 
                    to take "steps" toward a minimum, even when the global shape of the function is unknown. Now, we extend this concept to differentials.
                </p>
            </section>
    
            <section id="diff" class="section-content">
                <h2>Differentials</h2>
                <p>
                    While linearization focuses on the function value, <strong>differentials</strong> describe the relationship between infinitesimally 
                    small changes in input quantities (\(dx\)) and the resulting change in output quantities (\(dy\)). 
                </p>

                <p>
                    Consider a differentiable function \(y = f(x)\). We define the differential \(dy\) as:
                    \[
                    dy = f'(x)dx.
                    \]
                    In practice, \(dx\) and \(dy\) are arbitrary small numbers. Also, if \(dx \neq 0\), then we recover the 
                    familiar derivative form:
                    \[
                    \frac{dy}{dx} = f'(x)
                    \]
                    where the left side now represents the ratio of differentials.
                </p>
                <p>    
                    As \(dx \to 0\), the differential \(dy\) becomes an increasingly accurate approximation of the true change 
                    \(\Delta y = f(x + dx) - f(x)\). More rigorously, we express this using the asymptotic notation:
                    \[
                    f(x + dx) - f(x) = f'(x)dx + o(dx).
                    \]
                    where \(o(dx)\) represents higher-order terms that vanish faster than \(dx\) as \(dx \to 0\).
                    <br>
                    This highlights that the differential \(dy = f'(x)dx\) serves as a linear approximation to \(\Delta y\).
                </p>
                
                <p>
                    More generally, the differential of \(f\) can be expressed as:
                    \[
                    df = f(x + dx) - f(x) = f'(x)dx,
                    \] 
                    where \(df\) represents the linearized change in \(f(x)\) due to an infinitesimally small change in \(x\).
                </p>

                <p>
                    Here, \(df\) is the change in the output, \(dx\) is the change in the input, and most importantly, 
                    \(f'(x)\) acts as a <strong>linear operator</strong> that maps \(dx\) to \(df\). 
                </p>
                
                <div class="insight-box">
                        <h3>Derivative as an Operator</h3>
                        <p>
                            In foundational calculus, we often view the derivative \(f'(x)\) as a static value (the slope). However, 
                            in high-dimensional computer science, we must view it as a <strong>linear operator</strong>. 
                        </p>
                        <p>
                            In the equation \(df = f'(x)dx\), the derivative acts as a "transformer" that maps a small displacement 
                            in the input space (\(dx\)) to a displacement in the output space (\(df\)). This perspective is vital 
                            when \(x\) is no longer a scalar, but a vector \(\vec{x} \in \mathbb{R}^n\) or a matrix \(X \in \mathbb{R}^{m \times n}\), 
                            leading directly to the concept of the <strong>Jacobian</strong> and <strong>Gradient</strong>.
                        </p>
                </div>
            </section>
        
            <section id="ex1" class="section-content">
                <h2>Example 1: \(f(x) = x^Tx\) where \(x \in \mathbb{R}^n\)</h2>

                <p>
                    In machine learning, we rarely optimize single variables. We optimize weight <strong>vectors</strong>. Applying differential 
                    notation to vectors requires careful attention to dimensions and the <strong>Product Rule</strong>.
                </p>

                <div class="theorem">
                        <span class="theorem-title">Theorem: Differential Product Rule</span>  
                        If both \(g\) and \(h\) are differentiable mappings, the differential of their product \(f(x) = g(x)h(x)\) is:
                        \[
                        df = (dg)h + g(dh). \tag{1}
                        \]
                </div>

                <div class="proof">
                        <span class="proof-title">Quick derivation:</span>  
                        <p>
                        \[
                            \begin{align*}
                            df &= g(x+dx)h(x+dx) - g(x)h(x) \\\\
                            &= [g(x) +dg][h(x) + dh]-g(x)h(x) \\\\
                            &= g(x)h(x) + (dg)h + g(dh) + (dg)(dh) -g(x)h(x)
                            \end{align*}
                            \]
                            Then \((dg)(dh)\) is negligible, and we get (1).
                        </p>
                </div>

                <h3>Example 1: Squared \(L_2\) Norm \(f(x) = x^Tx\), \(x \in \mathbb{R}^n\)</h3>

                <p>
                    This function represents the squared distance from the origin â€” a core component of <strong>Mean Squared Error (MSE)</strong>.
                    In this case, the input is the vector \(x\), and the output is the scalar \(x^Tx\).
                </p>

                <p>
                    To compute the derivative of this function, we start with:
                    \[
                    f(x) = x^Tx = \sum_{i=1}^n x_i^2 ,
                    \]
                    where \(x_i\) is the \(i\)-th entry of the vector \(x\).
                </p>

                <p>
                    Then the <strong>gradient</strong> of \(f\), denoted by  \(\nabla f\) is:
                    \[
                    \nabla f = \begin{bmatrix}
                                \frac{\partial f }{\partial x_1} \\ 
                                \frac{\partial f }{\partial x_2} \\ 
                                \vdots \\
                                \frac{\partial f }{\partial x_n}
                                \end{bmatrix}
                            =  \begin{bmatrix} 2x_1 \\ 2x_2\\ \vdots \\  2x_n \end{bmatrix}
                            = 2x
                    \]      
                </p>

                <p>
                    <strong>Note: Input: vector & Output: scalar \(\Longrightarrow\) First derivative: column vector (gradient).</strong>
                </p>

                <p>
                    Now, let's derive the same result using differential notation. Note: \(dx \in \mathbb{R}^n\).
                </p>

                <div class="proof">
                        <span class="proof-title">Example 1</span>  
                <p>
                    By the <strong>product rule</strong>, and the commutativity of the vector inner product:
                    \[
                    \begin{align*}
                    d(x^Tx) &= (dx^T)x + x^T(dx) \\\\
                            &= x^Tdx + x^Tdx \\\\
                            &= 2x^Tdx.
                    \end{align*}
                    \]
                    Note: \(dx^T = (dx)^T\) because
                    \[\begin{align*}
                    d(x^T) &= (x + dx)^T - x^T \\\\
                        &= x^T + (dx)^T - x^T \\\\
                        &= (dx)^T
                    \end{align*}.
                    \]
                    Thus the gradient is 
                    \[
                    \nabla f = (2x^T)^T = 2x.
                    \]
                    Note: \(2x^T\) is a "row" vector and to get a column vector \(\nabla f\), we need the transpose of \(2x^T\).
                </p>
            </section>

            <section id="ex2" class="section-content">
            <h2>Example 2: \(f(x) = x^TAx\) where \(x \in \mathbb{R}^n\) and \(A \in \mathbb{R}^{n \times n}\)</h2>
            <p>
            Let's use the differential representation: 
            \[\begin{align*}
            df &= f(x + dx) -f(x) \\\\
               &= (x + dx)^T A (x + dx) - x^T A x
            \end{align*}
            \]
            Expanding this expression, we get:
            \[
            df = x^TAx + dx^T A x + x^TAdx + dx^T A dx - x^T A x 
            \]
            It is valid to ignore the higher-order term \(dx^T A dx\), which becomes negligible as \(dx \to 0\).
            Then
            \[
            df = dx^TAx + x^TAdx.
            \]
            since \(dx^TAx\) is a scalar, \((dx^TAx)^T = x^TA^Tdx\). Then we get:
            \[
            df = x^TA^Tdx + x^TAdx = x^T(A^T + A)dx
            \]
            Here, 
            \[
            (A^T + A)^T = A + A^T =  (A^T + A)
            \].
            So, \((A^T + A)^T\) is symmetric and thus: 
            \[
            \nabla f = (A+A^T)x.
            \]
            if \(A\) is symmetric (\(x^TAx\) is a quadratic form), \(\nabla f = (A+A^T)x = (A+A)x  = 2Ax\).
            <br>
            Also, Example 1 is a special case: \(A\) is an identity matrix. 
            </p>
            </section>

            <section id="ex3" class="section-content">
            <h2>Example 3: \(f(x) = \| x \|_2\) where \(x \in \mathbb{R}^n\)</h2>
            <p>
            Now, it is simple to find the derivative of <strong>\(L_2\) norm</strong>.
            <br>
            Let \(r = \| x \|\),  and then:
            \[
            \begin{align*}
            & r^2 = x^Tx \\\\
            &\Longrightarrow 2rdr = 2x^Tdr \\\\
            &\Longrightarrow  dr = \frac{x^T}{r} = \frac{x^T}{\| x \|} \\\\\
            &\Longrightarrow  \nabla f = \frac{x}{\| x \|}.
            \end{align*}
            \]
            </p>
            </section>
        </div>
        <script src="/js/main.js"></script>   
    </body>
</html>