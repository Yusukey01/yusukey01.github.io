<!DOCTYPE html>
<html>
    <head> 
        <title>Fisher Information Matrix</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Fisher information matrix</h1>
        <blockquote>
            The <strong>Fisher information matrix</strong> is related to the <strong>curvature</strong> of log 
            likelihood functions. In frequentist statistics, it characterizes the sampling distribution of the MLE. On the 
            other hand, in Bayesian statistics, it used to derive Jeffreys' uninformative priors. In addition, FIM is introduced 
            as a part of optimization methods such as the natural gradient descent. 
            <br><br>
            First, we define a <strong>score function</strong> as the gradient of the log likelihood with respect 
            to the parameter vector \(\theta\):
            \[
            s(\theta) = \nabla_{\theta} \log p(x | \theta).
            \]
            The <strong>Fisher information matrix (FIM)</strong> is defined to be the <strong>covariance</strong> of the 
            score function:
            \[
            F(\theta) = \mathbb{E }_{x \sim p(x|\theta)} [s(\theta)s(\theta)^T].
            \]
            <div class="theorem">
                <span class="theorem-title">Theorem 1:</span>
                The Fisher information matrix equals the expected Hessian of the negative log likelihood (NLL).
                \[
                F(\theta) = \mathbb{E }_{x \sim \theta} [\nabla^2 \log p(x |\theta)]
                \]
            </div>
        </blockquote>


        <a href="../../index.html">Back to Home </a>
        <br> <a href="probability.html">Back to Probability </a>   
    </body>
</html>