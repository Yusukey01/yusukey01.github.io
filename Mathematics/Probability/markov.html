<!DOCTYPE html>
<html>
    <head> 
        <title>Markov Chain</title>
        <link rel="stylesheet" href="../styles.css">
        <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <div class="toc-container">
            <h2>Contents</h2>
            <ul>
                <li><a href="#lm">Language Model</a></li>
            </ul>
        </div>
        <h1 id="lm">Language Model</h1>
        <blockquote>
            The <strong>Markov chain</strong> is a fundamental concept that appear in various fields. Although the core idea is 
            the same, the way they are used and studied can vary across disciplines. Let's see a specific application of the Markov chain.
            <br><br>
            Suppose our goal is  to generate a joint probability distribution over variable-length sequences: \(P(y_{1:T})\). 
            If \(y_t \in \{1, \cdots, K\}\) represents a <strong>word</strong> from a <strong>vocabulary</strong> with \(K\) possible 
            values, the resulting <strong>language model</strong> represents a distribution over possible sentences of length \(T\). 
            <br><br>
            By the chain rule of probability, 
            \[
            P(y_{1:T}) = P(y_1)P(y_2 | y_1)P(y_3 | y_2, y_1)\cdots = \prod_{t = 1}^{T} P(y_t | y_{t_1 : t-1}).
            \]
            This is too expensive as \(t\) grows. Intead, in <strong>Markov chain</strong>, we assume that the next state depends 
            solely on the current state:
            \[
            P(y_{1:T}) = P(y_1)P(y_2 | y_1)P(y_3 | y_2)P(y_4 | y_3)\cdots =  P(y_1)\prod_{t = 2}^{T} P(y_t | y_{t-1}).
            \]
            This <strong>memoryless property</strong> simplifies both the analysis and computation of probabilities.
            Here, the function \(p(y_t | y_{t-1})\) is called the <strong>transition function</strong>, or <strong>transition kernel</strong>. 
            It satisfies the conditions: 
            <ul>
                <li>\(P(y_t | y_{t-1}) \geq 0\)</li>
                <li>\(\sum_{k=1}^K P(y_t | y_{t-1} = j)  =1 \)</li>
            </ul>
            We can represent this probabilities of transitioning from one state to another as a 
            <a href="../Linear_algebra/stochastic.html"><strong>stochastic matrix</strong></a>:
            \[
            A_{jk} = P(y_t = k | y_{t-1} = j)
            \]
            where each row sums to 1. Wcan consider this matrix as the conditional probability Table(CPT). Since we assume this is the same 
            for all time steps, the model is <strong>time-invariant</strong>.
            <br><br>
            We can generalize the model for the last \(M\) observations(or memory length): 
            \[
            P(y_{1:T}) = P(y_1 : M) \prod_{t = M + 1}^T P(y_t | y_{t - M : t - 1})
            \]
            This is called an <strong>M'th order Markov model</strong>. For example, if \(M = 2\), then \(y_t\) depends on \(y_{t-1}\) and \(y_{t-2}\), which means 
            that we model the probability distribution over 3 words (trigram model). 
            <br>
            Note: In practice, for large vocabulary sizes, we need additional assumptions.(e.g. neural language model)
            <br><br>
            Like the language model, we use the <strong>Markov Chain</strong> for the <strong>sequential Data Modeling</strong>. Also, 
            <strong>Markov Chain Monte Carlo (MCMC)</strong> is widely used in Bayesian statistics for approximate inference when direct 
            sampling is challenging. 
        </blockquote>

        <h1></h1>
        <blockquote>
          
            <br><br>
            
        </blockquote>

        <br><a href="../../index.html">Back to Home </a>
        <br> <a href="probability.html">Back to Probability </a>   
    </body>
</html>