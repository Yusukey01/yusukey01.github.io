---
layout: default
title: Random Variables
level: detail
description: Learn about random variables, expected values, variance.
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>   
    <body>
        <!-- Meta script for random_variables.html -->
        <script type="application/ld+json">
        {
        "@context": "https://schema.org",
        "@type": "LearningResource",
        "name": "{{ page.title }}",
        "description": "{{ page.description }}",
        "learningResourceType": "lesson",
        "educationalUse": "instruction",
        "educationalLevel": "university",
        "interactivityType": "{% if page.content contains 'Interactive Demo' or page.content contains 'demo' %}active{% else %}expositive{% endif %}",
        "author": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
        },
        "publisher": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
        },
        "about": [
            { "@type": "Thing", "name": "Random Variables" },
            { "@type": "Thing", "name": "Expected Value" },
            { "@type": "Thing", "name": "Variance" },
            { "@type": "Thing", "name": "Standard Deviation" },
            { "@type": "Thing", "name": "Discrete Random Variables" },
            { "@type": "Thing", "name": "Continuous Random Variables" },
            { "@type": "Thing", "name": "Probability Mass Function" },
            { "@type": "Thing", "name": "PMF" },
            { "@type": "Thing", "name": "Probability Density Function" },
            { "@type": "Thing", "name": "PDF" },
            { "@type": "Thing", "name": "Cumulative Distribution Function" },
            { "@type": "Thing", "name": "CDF" },
            { "@type": "Thing", "name": "Sample Space" },
            { "@type": "Thing", "name": "Numerical Value" },
            { "@type": "Thing", "name": "Mean" },
            { "@type": "Thing", "name": "Weighted Average" },
            { "@type": "Thing", "name": "Center of Gravity" },
            { "@type": "Thing", "name": "Symmetric Distribution" },
            { "@type": "Thing", "name": "Linear Transformation" },
            { "@type": "Thing", "name": "Fundamental Theorem of Calculus" }
        ],
        "teaches": [
            "Random variable fundamentals",
            "Expected value calculation",
            "Variance and standard deviation",
            "Discrete vs continuous distributions"
        ],
        "isPartOf": {
            "@type": "Course",
            "name": "Probability & Statistics",
            "description": "Explore fundamental concepts of probability and statistics essential for machine learning",
            "provider": {
            "@type": "Organization",
            "name": "MATH-CS COMPASS",
            "url": "https://yusukey01.github.io"
            },
            "instructor": {
            "@type": "Person",
            "name": "Yusuke Yokota",
            "jobTitle": "Mathematics & Computer Science Educator"
            },
            "courseCode": "III",
            "hasCourseInstance": {
            "@type": "CourseInstance",
            "courseMode": "online",
            "courseWorkload": "PT2H30M",
            "instructor": {
                "@type": "Person",
                "name": "Yusuke Yokota"
            }
            },
            "offers": {
            "@type": "Offer",
            "price": "0",
            "priceCurrency": "USD",
            "availability": "https://schema.org/InStock",
            "category": "free"
            }
        }
        }
        </script>

        <div class="hero-section">
            <h1 class="webpage-name">Random Variables
            </h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#rv">Random Variables</a>
            <a href="#exp">Expected Value</a>
            <a href="#var">Variance</a>
        </div> 

        <div class="container">  
           
            <section id="rv" class="section-content">
            <h2>Random Variables</h2>
            <p>
            In machine learning, we can consider any unknown quantities as <strong>random variables</strong>. A random variable 
            associates a distinct numerical value with each possible outcome in the <strong>sample space</strong>. (Formally, it is a 
            single valued fuction.) Usually, we denote a random variable by a capital letter (\(X\)) and a specific value taken by a
            random variable by the corresponding lower case letter (\(x\)). 
            <br><br>
            A random variable is <strong>discrete</strong> if the number of possible values it takes is finite or countably infinite. 
            We can describe the collection of probabilities as a function of \(x\):
            \[
            f(x) = P(X = x)
            \]
            we call \(f(x)\) a <strong>probability mass function (p.m.f.)</strong>.
            <br>
            Then
            <ol style="padding-left: 40px;">
                <li>\(f(x) \geq 0\) for all \(x\).</li>
                <li>\(\sum_{x} f(x) = 1\).</li>
            </ol>
            <br>
            <strong>Cumulative distribution function(c.d.f.)</strong> of p.m.f. is 
            \[
            F(x) = P(X \leq x) = \sum_{k \leq x} f(k).
            \]
            Note: \(P(a \leq X \leq b) = F(b) - F(a - 1)\).
            <br><br>
            A random variable is <strong>continuous</strong> if it can be any value from one or more intervals of real numbers. Since 
            the possible values are uncountably infinte, instead of p.m.f., we use the <strong>probability density function (p.d.f.)</strong>.
            <br><br>
            <ol style="padding-left: 40px;">
                <li>\(f(x) \geq 0\) for all \(x\).</li>
                <li>\(\int_{- \infty}^\infty f(x)\,dx = 1\)</li>
                <li>\(P(a \leq X \leq b) = \int_{a}^b f(x)\,dx\) for any \(a \leq b\)</li>  
            </ol>
            <br>
            <strong>Cumulative distribution function(c.d.f.)</strong> of p.d.f. is 
            \[
            F(x) =  P(X \leq x) = \int_{- \infty}^x f(u)\,du.
            \]
            So, by the Fundamental Theorem of Calculus,  
            \[
            f(x) = \frac{dF(x)}{dx}.
            \]
            Note: \(P(a \leq X \leq b) = \int_{a}^b f(x)\,dx =  F(b) - F(a)\).
            </p>
            </section>

            <section id="exp" class="section-content">
            <h2>Expected Values</h2>
            <p>
            The <strong>expected value (mean)</strong> of a discrete random variable \(X\) is defined as 
            \[
            \mathbb{E}[X] = \mu = \sum_{x}x f(x)
            \]
            which is weighted average of all possible values taken by \(X\).
            <br><br>
            For a continuous random variable, 
            \[
            \mathbb{E}[X] = \mu = \int x f(x) \,dx
            \]
            We could consider the expected value as the center of gravity of the distribution of \(X\). So, if the 
            mean equals to the median, the distribution of \(X\) must be symmetric. 
            <br>
            Note: 
            \[
            \begin{align*}
            \mathbb{E}[aX+b] &= \int (ax+b) f(x) \,dx  \\\\
                             &= a \int x f(x) dx + b \int f(x)dx \\\\
                             &= a\mathbb{E}[X]+ b.
            \end{align*}
            \]
            </p>
            </section>

            <section id="var" class="section-content">
            <h2>Variance</h2>
            <p>
            The <strong>variance</strong> of a random variable \(X\) is defined as 
            \[\sigma^2 = \text{ Var }(X) = \mathbb{E}[(X - \mu)^2] \geq 0
            \]
            Or, an alternative expression is given by
            \[
            \begin{align*}
            \mathbb{E}[(x - \mu)^2] &= \mathbb{E}[X^2 -2\mu X + \mu^2] \\\\
                                    &= \mathbb{E}[X^2]  -2\mu \mathbb{E}[X]  + \mathbb{E}[\mu^2] \\\\
                                    &= \mathbb{E}[X^2]  -2\mu^2  + \mu^2 \\\\ 
                                    &= \mathbb{E}[X^2]  -\mu^2 
            \end{align*}
            \] 
            Note: \(\text{Var }[constant] = 0\)
            <br>
            Also, we define the square root of the variance as the <strong>Standard deviation</strong>
             \[
             \text{SD }[X] = \sigma = \sqrt{\text{Var }(X)}
             \]
            <br>
            <div class="theorem">
                <span class="theorem-title">Theorem 1:</span> 
                \[
                \text{Var }[aX + b] = a^2 \text{Var }[X] \quad a,\, b \in \mathbb{R}
                \]
                Note: the additive constant \(b\) does not affect the distribution of \(X\). 
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                \[
                \begin{align*}
                \text{Var }[aX + b] 
                &= \mathbb{E}[(aX+b)^2]  - (\mathbb{E}[aX+b])^2  \\\\
                &= a^2\mathbb{E}[X^2] -2ab\mathbb{E}[X] + b^2 - (a^2(\mathbb{E}[X])^2 +2ab\mathbb{E}[X] +b^2)\\\\
                &= a^2(\mathbb{E}[X^2] - (\mathbb{E}[X])^2 )\\\\
                &= a^2 \text{Var }[X] 
                \end{align*}
                \]
            </div>
            </p>
            </section>
        </div>
        <script src="/js/main.js"></script> 
    </body>
</html>