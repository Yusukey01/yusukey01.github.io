---
layout: default
title: Random Variables
level: detail
description: Learn about random variables, expected values, variance.
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>   
    <body>
        <div class="hero-section">
            <h1 class="webpage-name">Random Variables
            </h1>
        </div>

        <div class="topic-nav">
            <a href="#rv">Random Variables</a>
            <a href="#exp">>Expected Value</a>
            <a href="#var">Variance</a>
        </div> 

        <div class="container">  
           
            <section id="rv" class="section-content">
            <h2>Random Variables</h2>
            <p>
            In machine learning, we can consider any unknown quantities as <strong>random variables</strong>. A random variable 
            associates a distinct numerical value with each possible outcome in the <strong>sample space</strong>. (Formally, it is a 
            single valued fuction.) Usually, we denote a random variable by a capital letter (\(X\)) and a specific value taken by a
            random variable by the corresponding lower case letter (\(x\)). 
            <br><br>
            A random variable is <strong>discrete</strong> if the number of possible values it takes is finite or countably infinite. 
            We can describe the collection of probabilities as a function of \(x\):
            \[
            f(x) = P(X = x)
            \]
            we call \(f(x)\) a <strong>probability mass function (p.m.f.)</strong>.
            <br>
            Then
            <ol style="padding-left: 40px;">
                <li>\(f(x) \geq 0\) for all \(x\).</li>
                <li>\(\sum_{x} f(x) = 1\).</li>
            </ol>
            <br>
            <strong>Cumulative distribution function(c.d.f.)</strong> of p.m.f. is 
            \[
            F(x) = P(X \leq x) = \sum_{k \leq x} f(k).
            \]
            Note: \(P(a \leq X \leq b) = F(b) - F(a - 1)\).
            <br><br>
            A random variable is <strong>continuous</strong> if it can be any value from one of more intervales of real numbers. Since 
            the possible values are uncountably infinte, instead of p.m.f., we use the <strong>probability density function (p.d.f.)</strong>.
            <br><br>
            <ol style="padding-left: 40px;">
                <li>\(0 \leq f(x) \leq 1\) for .</li>
                <li>\(\int_{- \infty}^\infty f(x)\,dx = 1\)</li>
                <li>\(P(a \leq X \leq b) = \int_{a}^b f(x)\,dx\) for any \(a \leq b\)</li>  
            </ol>
            <br>
            <strong>Cumulative distribution function(c.d.f.)</strong> of p.d.f. is 
            \[
            F(x) =  P(X \leq x) = \int_{- \infty}^x f(u)\,du.
            \]
            So, by the Fundamental Theorem of Calculus,  
            \[
            f(x) = \frac{dF(x)}{dx}.
            \]
            Note: \(P(a \leq X \leq b) = \int_{a}^b f(x)\,dx =  F(b) - F(a)\).
            </p>
            </section>

            <section id="exp" class="section-content">
            <h2>Expected Values</h2>
            <p>
            The <strong>expected value (mean)</strong> of a discrete random variable \(X\) is defined as 
            \[
            \mathbb{E}[X] = \mu = \sum_{x}x f(x)
            \]
            which is weighted average of all possible values taken by \(X\).
            <br><br>
            For a continuous random variable, 
            \[
            \mathbb{E}[X] = \mu = \int x f(x) \,dx
            \]
            We could consider the expected value as the center of gravity of the distribution of \(X\). So, if the 
            mean equals to the median, the distribution of \(X\) must be symmetric. 
            <br>
            Note: 
            \[
            \begin{align*}
            \mathbb{E}[aX+b] &= \int (ax+b) f(x) \,dx  \\\\
                             &= a \int x f(x) dx + b \int f(x)dx \\\\
                             &= a\mathbb{E}[X]+ b.
            \end{align*}
            \]
            </p>
            </section>

            <section id="var" class="section-content">
            <h2>Variance</h2>
            <p>
            The <strong>variance</strong> of a random variable \(X\) is defined as 
            \[\sigma^2 = \text{ Var }(X) = \mathbb{E}[(X - \mu)^2] \geq 0
            \]
            Or, an alternative expression is given by
            \[
            \begin{align*}
            \mathbb{E}[(x - \mu)^2] &= \mathbb{E}[X^2 -2\mu X + \mu^2] \\\\
                                    &= \mathbb{E}[X^2]  -2\mu \mathbb{E}[X]  + \mathbb{E}[\mu^2] \\\\
                                    &= \mathbb{E}[X^2]  -2\mu^2  + \mu^2 \\\\ 
                                    &= \mathbb{E}[X^2]  -\mu^2 
            \end{align*}
            \] 
            Note: \(\text{Var }[constant] = 0\)
            <br>
            Also, we define the square root of the variance as the <strong>Standard deviation</strong>
             \[
             \text{SD }[X] = \sigma = \sqrt{\text{Var }(X)}
             \]
            <br>
            <div class="theorem">
                <span class="theorem-title">Theorem 1:</span> 
                \[
                \text{Var }[aX + b] = a^2 \text{Var }[X] \quad a,\, b \in \mathbb{R}
                \]
                Note: the additive constant \(b\) does not affect the distribution of \(X\). 
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                \[
                \begin{align*}
                \text{Var }[aX + b] 
                &= \mathbb{E}[(aX+b)^2]  - (\mathbb{E}[aX+b])^2  \\\\
                &= a^2\mathbb{E}[X^2] -2ab\mathbb{E}[X] + b^2 - (a^2(\mathbb{E}[X])^2 +2ab\mathbb{E}[X] +b^2)\\\\
                &= a^2(\mathbb{E}[X^2] - (\mathbb{E}[X])^2 )\\\\
                &= a^2 \text{Var }[X] 
                \end{align*}
                \]
            </div>
            </p>
            </section>
        </div>
        <script src="/js/main.js"></script> 
    </body>
</html>