---
layout: default
title: Random Variables
topic_id: prob-2
level: detail
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>   
    <body>
        {% include learning_resource_schema.html topic_id=page.topic_id %}
       
        <div class="hero-section">
            <h1 class="webpage-name">Random Variables</h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#rv">Random Variables</a>
            <a href="#exp">Expected Value</a>
            <a href="#var">Variance</a>
        </div> 

        <div class="container">  

            <section id="rv" class="section-content">

                <h2>Random Variables</h2>
                
                <p>
                    In <a href="basic.html"><strong>Part 1</strong></a>, we developed probability in terms of events — 
                    subsets of a sample space. While this framework is logically complete, it is insufficient 
                    for the quantitative demands of statistics and machine learning. We need to associate 
                    <em>numerical values</em> with outcomes so that we can compute averages, measure spread, 
                    and apply the tools of calculus. A <strong>random variable</strong> is precisely this bridge: 
                    it is a function that maps each outcome in the sample space to a real number.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Random Variable</span>
                    <p>
                        A <strong>random variable</strong> is a function \(X: S \to \mathbb{R}\) that assigns a numerical 
                        value to each outcome in the sample space \(S\). We denote random variables by capital letters 
                        (\(X, Y, Z\)) and specific values they take by the corresponding lowercase letters (\(x, y, z\)).
                    </p>
                </div>

                <p>
                    Random variables come in two fundamental types, depending on the nature of the values they can take. 
                    This distinction determines the mathematical tools — summation or integration — used to analyze them.
                </p>

                <h3><strong>Discrete Random Variables</strong></h3>
                <p>
                    A random variable is <strong>discrete</strong> if the set of values it can take is finite or 
                    countably infinite (e.g., \(\{0, 1, 2, \ldots\}\)). The probability structure of a discrete 
                    random variable is completely characterized by its <strong>probability mass function</strong>.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Probability Mass Function (p.m.f.)</span>
                    <p>
                        The <strong>probability mass function</strong> of a discrete random variable \(X\) is the function
                        \[
                        f(x) = P(X = x)
                        \]
                        satisfying:
                    </p>
                    <ol style="padding-left: 40px;">
                        <li>\(f(x) \geq 0\) for all \(x\).</li>
                        <li>\(\sum_{x} f(x) = 1\), where the sum is over all possible values of \(X\).</li>
                    </ol>
                </div>

                <p>
                    To answer questions of the form "what is the probability that \(X\) is at most \(x\)?", 
                    we accumulate the mass function into a running total. This cumulative perspective is 
                    especially useful for computing probabilities over intervals.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Cumulative Distribution Function (Discrete Case)</span>
                    <p>
                        The <strong>cumulative distribution function (c.d.f.)</strong> of a discrete random variable \(X\) is
                        \[
                        F(x) = P(X \leq x) = \sum_{k \leq x} f(k).
                        \]
                        It follows that \(P(a \leq X \leq b) = F(b) - F(a-1)\) for integer-valued random variables.
                    </p>
                </div>

                <h3><strong>Continuous Random Variables</strong></h3>
                <p>
                    A random variable is <strong>continuous</strong> if it can take any value from one or more intervals 
                    of real numbers. Since the set of possible values is uncountably infinite, the probability that \(X\) 
                    takes any single specific value is zero: \(P(X = x) = 0\). Instead of assigning mass to individual points, 
                    we describe probabilities through a density function whose integral over an interval gives the 
                    probability that \(X\) falls in that interval.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Probability Density Function (p.d.f.)</span>
                    <p>
                        The <strong>probability density function</strong> of a continuous random variable \(X\) is a 
                        function \(f(x)\) satisfying:
                    </p>
                    <ol style="padding-left: 40px;">
                        <li>\(f(x) \geq 0\) for all \(x\).</li>
                        <li>\(\int_{-\infty}^{\infty} f(x)\,dx = 1\).</li>
                        <li>\(P(a \leq X \leq b) = \int_{a}^{b} f(x)\,dx\) for any \(a \leq b\).</li>
                    </ol>
                    <p>
                        Note that \(f(x)\) itself is <em>not</em> a probability — it is a density. In particular, 
                        \(f(x)\) can exceed 1 (e.g., the uniform distribution on \([0, 0.5]\) has density \(f(x) = 2\)).
                    </p>
                </div>

                <div class="theorem">
                    <span class="theorem-title">Definition: Cumulative Distribution Function (Continuous Case)</span>
                    <p>
                        The <strong>cumulative distribution function</strong> of a continuous random variable \(X\) is
                        \[
                        F(x) = P(X \leq x) = \int_{-\infty}^{x} f(u)\,du.
                        \]
                        By the Fundamental Theorem of Calculus, the density is recovered as:
                        \[
                        f(x) = \frac{dF(x)}{dx}
                        \]
                        at every point where \(F\) is differentiable. Furthermore, 
                        \(P(a \leq X \leq b) = F(b) - F(a)\).
                    </p>
                </div>

                <p>
                    Note that for a continuous random variable, \(P(X = a) = \int_a^a f(x)\,dx = 0\), so 
                    \(P(a \leq X \leq b) = P(a < X < b)\). The distinction between strict and non-strict 
                    inequalities only matters in the discrete case.
                </p>

                <p>
                    With the language of random variables and their distributions established, we can now ask 
                    the two most fundamental questions about any distribution: where is its center, and 
                    how spread out is it? These are captured by the <strong>expected value</strong> and 
                    <strong>variance</strong>, respectively.
                </p>
            </section>

            <section id="exp" class="section-content">

                <h2>Expected Value</h2>
                
                <p>
                    The <strong>expected value</strong> (or <strong>mean</strong>) of a random variable provides a single 
                    number that summarizes the "center" of its distribution. It is a weighted average of all possible values, 
                    where each value is weighted by its probability. This concept is indispensable in machine learning: 
                    loss functions are expectations, model predictions are conditional expectations, and training 
                    algorithms minimize expected risk.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Expected Value</span>
                    <p>
                        The <strong>expected value</strong> of a random variable \(X\) is defined as:
                        \[
                        \mathbb{E}[X] = \mu = 
                        \begin{cases}
                        \displaystyle\sum_{x} x\, f(x) & \text{if } X \text{ is discrete} \\[10pt]
                        \displaystyle\int_{-\infty}^{\infty} x\, f(x)\,dx & \text{if } X \text{ is continuous}
                        \end{cases}
                        \]
                        provided the sum or integral converges absolutely.
                    </p>
                </div>

                <p>
                    The expected value can be interpreted as the <strong>center of gravity</strong> of the distribution. 
                    If the distribution is symmetric about some point \(c\), then \(\mathbb{E}[X] = c\), meaning 
                    the mean coincides with the median.
                </p>

                <p>
                    One of the most useful properties of expectation is its <strong>linearity</strong>, which holds 
                    regardless of whether the random variables involved are independent.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem 1: Linearity of Expectation</span>
                    <p>
                        For any constants \(a, b \in \mathbb{R}\),
                        \[
                        \mathbb{E}[aX + b] = a\,\mathbb{E}[X] + b.
                        \]
                    </p>
                </div>

                <div class="proof">
                    <span class="proof-title">Proof (continuous case):</span>
                    <p>
                        \[
                        \begin{align*}
                        \mathbb{E}[aX + b] &= \int_{-\infty}^{\infty} (ax + b)\, f(x)\,dx \\\\
                                            &= a\int_{-\infty}^{\infty} x\, f(x)\,dx + b\int_{-\infty}^{\infty} f(x)\,dx \\\\
                                            &= a\,\mathbb{E}[X] + b.
                        \end{align*}
                        \]
                        The discrete case follows identically by replacing integrals with sums.
                    </p>
                </div>

                <p>
                    Knowing the center of a distribution is valuable, but it tells us nothing about how concentrated 
                    or dispersed the values are around that center. Two distributions can share the same mean yet 
                    differ dramatically in spread. To quantify this spread, we introduce the variance.
                </p>

            </section>

            <section id="var" class="section-content">
                
                <h2>Variance</h2>
                
                <p>
                    The <strong>variance</strong> measures the expected squared deviation of a random variable from its 
                    mean. A small variance indicates that the values of \(X\) tend to cluster tightly around \(\mu\), 
                    while a large variance indicates wide dispersion. In machine learning, variance appears 
                    everywhere: in the bias-variance tradeoff, in gradient noise during stochastic optimization, 
                    and in the uncertainty quantification of Bayesian predictions.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Variance and Standard Deviation</span>
                    <p>
                        The <strong>variance</strong> of a random variable \(X\) with mean \(\mu = \mathbb{E}[X]\) is:
                        \[
                        \text{Var}(X) = \sigma^2 = \mathbb{E}\bigl[(X - \mu)^2\bigr] \geq 0.
                        \]
                        The <strong>standard deviation</strong> is \(\sigma = \sqrt{\text{Var}(X)}\), which has the same 
                        units as \(X\).
                    </p>
                </div>

                <p>
                    The definition involves the unknown quantity \(\mathbb{E}[X]\) inside the expectation. 
                    Expanding the square yields a computationally convenient alternative:
                    \[
                    \begin{align*}
                    \text{Var}(X) = \mathbb{E}\bigl[(X - \mu)^2\bigr]
                                  &= \mathbb{E}[X^2 - 2\mu X + \mu^2] \\\\
                                  &= \mathbb{E}[X^2] - 2\mu\,\mathbb{E}[X] + \mu^2 \\\\
                                  &= \mathbb{E}[X^2] - \mu^2.
                    \end{align*}
                    \]
                    That is, the variance equals the <strong>mean of the square minus the square of the mean</strong>. 
                    Note that \(\text{Var}(c) = 0\) for any constant \(c\), since a constant has no spread.
                </p>

                <p>
                    The following result describes how variance transforms under linear operations. Unlike 
                    expectation, variance is affected by scaling but not by translation.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem 2: Variance of a Linear Transformation</span> 
                    <p>
                        For any constants \(a, b \in \mathbb{R}\),
                        \[
                        \text{Var}(aX + b) = a^2\,\text{Var}(X).
                        \]
                        The additive constant \(b\) shifts the distribution without changing its spread.
                    </p>
                </div>

                <div class="proof">
                    <span class="proof-title">Proof:</span>
                    <p>
                        Using the alternative formula and linearity of expectation:
                        \[
                        \begin{align*}
                        \text{Var}(aX + b) 
                        &= \mathbb{E}\bigl[(aX+b)^2\bigr] - \bigl(\mathbb{E}[aX+b]\bigr)^2 \\\\
                        &= \bigl(a^2\mathbb{E}[X^2] + 2ab\,\mathbb{E}[X] + b^2\bigr) - \bigl(a\,\mathbb{E}[X] + b\bigr)^2 \\\\
                        &= a^2\mathbb{E}[X^2] + 2ab\,\mathbb{E}[X] + b^2 - a^2(\mathbb{E}[X])^2 - 2ab\,\mathbb{E}[X] - b^2 \\\\
                        &= a^2\bigl(\mathbb{E}[X^2] - (\mathbb{E}[X])^2\bigr) \\\\
                        &= a^2\,\text{Var}(X).
                        \end{align*}
                        \]
                    </p>
                </div>

                <div class="insight-box">
                    <h3>Insight: Random Variables in Machine Learning</h3>
                    <p>
                        The framework of random variables, expectations, and variances is the language in which 
                        virtually all of machine learning is written. A model's <strong>loss function</strong> is an 
                        expectation: we minimize \(\mathbb{E}[\ell(Y, \hat{Y})]\) over the data distribution. 
                        The <strong>bias-variance decomposition</strong> shows that a model's expected prediction error 
                        decomposes as \(\text{Bias}^2 + \text{Variance} + \text{Irreducible Noise}\), directly using 
                        the concepts defined here. In the next parts, we will study specific families of distributions 
                        - <a href="gamma.html"><strong>Gamma and Beta</strong></a>, 
                        <a href="gaussian.html"><strong>Gaussian</strong></a>, and others - that serve as building 
                        blocks for probabilistic models throughout statistics and machine learning.
                    </p>
                </div>

            </section>
                       
        </div>
        <script src="/js/main.js"></script> 
    </body>
</html>