<!DOCTYPE html>
<html>
    <head> 
        <title>Random Variables</title>
        <link rel="stylesheet" href="../styles.css">
        <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body>
        <nav class="navbar">
            <div class="logo">
                <h1>Section III - Probability & Statistics</h1>
            </div>
            <ul class="nav-links">
                <li><a href="../../index.html">Home</a></li>
                <li><a href="../Linear_algebra/linear_algebra.html">Linear Algebra</a></li>
                <li><a href="../Calculus/calculus.html">Calculus to Optimization & Analysis</a></li>
                <li><a href="probability.html">Probability & Statistics</a></li>
                <li><a href="../Discrete/discrete_math.html">Discrete Mathematics & Algorithms</a></li>
            </ul>
            <div class="menu-toggle">&#9776;</div>
        </nav>

        <div class="hero-section">
            <h1 class="webpage-name">Random Variables
            </h1>
        </div>

        <div class="topic-nav">
            <a href="#rv">Random Variables</a>
            <a href="#exp">>Expected Value</a>
            <a href="#var">Variance</a>
        </div> 

        <div class="container">  
           
            <section id="rv" class="section-content">
            <h2>Random Variables</h2>
            <p>
            In machine learning, we can consider any unknown quantities as <strong>random variables</strong>. A random variable 
            associates a distinct numerical value with each possible outcome in the <strong>sample space</strong>. (Formally, it is a 
            single valued fuction.) Usually, we denote a random variable by a capital letter (\(X\)) and a specific value taken by a
            random variable by the corresponding lower case letter (\(x\)). 
            <br><br>
            A random variable is <strong>discrete</strong> if the number of possible values it takes is finite or countably infinite. 
            We can describe the collection of probabilities as a function of \(x\):
            \[
            f(x) = P(X = x)
            \]
            we call \(f(x)\) a <strong>probability mass function (p.m.f.)</strong>.
            <br>
            Then
            <ol style="padding-left: 40px;">
                <li>\(f(x) \geq 0\) for all \(x\).</li>
                <li>\(\sum_{x} f(x) = 1\).</li>
            </ol>
            <br>
            <strong>Cumulative distribution function(c.d.f.)</strong> of p.m.f. is 
            \[
            F(x) = P(X \leq x) = \sum_{k \leq x} f(k).
            \]
            Note: \(P(a \leq X \leq b) = F(b) - F(a - 1)\).
            <br><br>
            A random variable is <strong>continuous</strong> if it can be any value from one of more intervales of real numbers. Since 
            the possible values are uncountably infinte, instead of p.m.f., we use the <strong>probability density function (p.d.f.)</strong>.
            <br><br>
            <ol style="padding-left: 40px;">
                <li>\(0 \leq f(x) \leq 1\) for .</li>
                <li>\(\int_{- \infty}^\infty f(x)\,dx = 1\)</li>
                <li>\(P(a \leq X \leq b) = \int_{a}^b f(x)\,dx\) for any \(a \leq b\)</li>  
            </ol>
            <br>
            <strong>Cumulative distribution function(c.d.f.)</strong> of p.d.f. is 
            \[
            F(x) =  P(X \leq x) = \int_{- \infty}^x f(u)\,du.
            \]
            So, by the Fundamental Theorem of Calculus,  
            \[
            f(x) = \frac{dF(x)}{dx}.
            \]
            Note: \(P(a \leq X \leq b) = \int_{a}^b f(x)\,dx =  F(b) - F(a)\).
            </p>
            </section>

            <section id="exp" class="section-content">
            <h2>Expected Values</h2>
            <p>
            The <strong>expected value (mean)</strong> of a discrete random variable \(X\) is defined as 
            \[
            \mathbb{E}[X] = \mu = \sum_{x}x f(x)
            \]
            which is weighted average of all possible values taken by \(X\).
            <br><br>
            For a continuous random variable, 
            \[
            \mathbb{E}[X] = \mu = \int x f(x) \,dx
            \]
            We could consider the expected value as the center of gravity of the distribution of \(X\). So, if the 
            mean equals to the median, the distribution of \(X\) must be symmetric. 
            <br>
            Note: \(\mathbb{E}[aX+b] = \int (ax+b) f(x) \,dx = a \int x f(x) dx + b \int f(x)dx = a\mathbb{E}[X]+ b\).
            </p>
            </section>

            <section id="var" class="section-content">
            <h2>Variance</h2>
            <p>
            The <strong>variance</strong> of a random variable \(X\) is defined as 
            \[\sigma^2 = \text{ Var }(X) = \mathbb{E}[(X - \mu)^2] \geq 0
            \]
            Or, an alternative expression is given by
            \[
            \begin{align*}
            \mathbb{E}[(x - \mu)^2] &= \mathbb{E}[X^2 -2\mu X + \mu^2] \\\\
                                    &= \mathbb{E}[X^2]  -2\mu \mathbb{E}[X]  + \mathbb{E}[\mu^2] \\\\
                                    &= \mathbb{E}[X^2]  -2\mu^2  + \mu^2 \\\\ 
                                    &= \mathbb{E}[X^2]  -\mu^2 
            \end{align*}
            \] 
            Note: \(\text{Var }[constant] = 0\)
            <br>
            Also, we define the square root of the variance as the <strong>Standard deviation</strong>
             \[
             \text{SD }[X] = \sigma = \sqrt{\text{Var }(X)}
             \]
            <br>
            <div class="theorem">
                <span class="theorem-title">Theorem 1:</span> 
                \[
                \text{Var }[aX + b] = a^2 \text{Var }[X] \qquad a,\, b \in \mathbb{R}
                \]
                Note: the additive constant \(b\) does not affect the distribution of \(X\). 
            </div>
            <div class="proof">
                <span class="proof-title">Proof:</span>
                \[
                \begin{align*}
                \text{Var }[aX + b] 
                &= \mathbb{E}[(aX+b)^2]  - (\mathbb{E}[aX+b])^2  \\\\
                &= a^2\mathbb{E}[X^2] -2ab\mathbb{E}[X] + b^2 - (a^2(\mathbb{E}[X])^2 +2ab\mathbb{E}[X] +b^2)\\\\
                &= a^2(\mathbb{E}[X^2] - (\mathbb{E}[X])^2 )\\\\
                &= a^2 \text{Var }[X] 
                \end{align*}
                \]
            </div>
            </p>
            </section>
        </div>
        <!-- Footer -->
        <footer>
            <div class="footer-content">
                <div class="footer-links">
                    <h3>Quick Links</h3>
                    <ul>
                        <li><a href="../../index.html">Home</a></li>
                        <li>  <a href="probability.html">Section III - Probability & Statistics</a></li>
                        <li><a href="basic.html">Basic Probability Ideas</a></li>   
                        <li><a href="random_variables.html">Random Variables</a></li> 
                        <li><a href="gamma.html">Gamma & Beta Distribution</a></li>
                        <li><a href="gaussian.html">Normal (Gaussian) Distribution</a></li> 
                        <li><a href="student.html">Student's \(t\)-Distribution</a></li>
                        <li><a href="covariance.html">Covariance</a></li>   
                        <li><a href="correlation.html">Correlation</a></li> 
                        <li><a href="mvn.html">Multivariate Distributions</a></li>
                        <li><a href="mle.html">Maximum Likelihood Estimate</a></li> 
                        <li><a href="hypothesis_testing.html">Statistical Inference & Hypothesis Testing</a></li>
                        <li><a href="linear_regression.html">Linear Regression</a></li>   
                        <li><a href="entropy.html">Entropy</a></li> 
                        <li><a href="convergence.html">Convergence</a></li>
                        <li><a href="bayesian.html">Intro to Bayesian Statistics</a></li> 
                        <li><a href="expfamily.html">The Exponential Family</a></li>
                        <li><a href="fisher_info.html">Fisher Information Matrix</a></li>
                        <li><a href="decision_theory.html">Bayesian Decision Theory</a></li>
                        <li><a href="markov.html">Markov Chains</a></li>          
                    </ul>
                </div>
            </div>
            
            <div class="footer-bottom">
                <p>&copy; 2025 Math-CS Compass. All rights reserved.</p>
            </div>
        </footer> 
        <script src="/main.js"></script>    
    </body>
</html>