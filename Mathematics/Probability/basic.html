---
layout: default
title: Basic Probability Ideas
topic_id: prob-1
level: detail
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body>
        {% include learning_resource_schema.html topic_id=page.topic_id %}
        
        <div class="hero-section">
            <h1 class="webpage-name">Basic Probability Ideas</h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#pro">Probability</a>
            <a href="#conditional">Conditional Probability</a>
            <a href="#total">Law of Total Probability</a>
            <a href="#bayes">Bayes' Theorem</a>
        </div> 

        <div class="container">  
           
            <section id="pro" class="section-content">

                <h2>Probability</h2>

                <p>
                    At the heart of machine learning lies a simple but profound question: how do we reason about uncertainty? 
                    Every prediction a model makes, every classification it outputs, rests on a mathematical framework for 
                    quantifying the likelihood of events. <strong>Probability theory</strong> provides this framework. Before 
                    we can discuss random variables, distributions, or Bayesian inference, we must establish the foundational 
                    language of sample spaces, events, and the axioms that govern how probabilities behave.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Sample Space and Events</span>
                    <p>
                        The collection of every possible outcome of an experiment is called the <strong>sample space</strong>, 
                        denoted \(S\). It can be discrete (finite or countably infinite) or continuous (uncountably infinite).
                    </p>
                    <p>
                        An <strong>event</strong> \(A\) is a subset of the sample space, \(A \subseteq S\). An event 
                        is said to <strong>occur</strong> if the outcome of the experiment belongs to \(A\).
                    </p>
                </div>

                <p>
                    With the sample space and events defined, we need a consistent way to assign numerical 
                    measures of likelihood to events. The following axioms provide the minimal requirements that any 
                    probability assignment must satisfy.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Probability Axioms</span>
                    <p>
                        A <strong>probability</strong> \(P\) on a sample space \(S\) is a function \(P: \mathcal{F} \to [0,1]\) 
                        (where \(\mathcal{F}\) is a collection of events) satisfying:
                    </p>
                    <ol style="padding-left: 40px;">
                        <li><strong>Non-negativity</strong>: \(0 \leq P(A) \leq 1\) for every event \(A\).</li>
                        <li><strong>Normalization</strong>: \(P(S) = 1\).</li>
                        <li><strong>Additivity</strong>: If events \(A\) and \(B\) are <strong>mutually exclusive</strong> 
                            (i.e., \(A \cap B = \emptyset\)), then
                            \[
                            P(A \cup B) = P(A) + P(B).
                            \]
                        </li>
                    </ol>
                </div>
                
                <p>
                    These axioms immediately imply \(P(\emptyset) = 0\), since \(S\) and \(\emptyset\) are mutually exclusive 
                    and \(S = S \cup \emptyset\), giving \(P(S) = P(S) + P(\emptyset)\).
                </p>

                <p>
                    When the sample space is finite and all outcomes are equally likely, the probability of an event 
                    reduces to a counting problem:
                    \[
                    P(A) = \frac{|A|}{|S|} = \frac{\text{number of outcomes in } A}{\text{number of outcomes in } S}.
                    \]
                    This classical formula motivates the counting techniques below.
                </p>

                <p>
                    From the axioms, the following fundamental properties can be derived using basic set algebra:
                </p> 

                <ol style="padding-left: 40px;">
                    <li><strong>Complement rule</strong>:<br>
                        \[
                        P(\bar{A}) = 1 - P(A)
                        \]
                        since \(P(S) = P(A \cup \bar{A}) = P(A) + P(\bar{A})\), where \(A\) and \(\bar{A}\) are mutually exclusive.
                    </li>
                    <li><strong>Addition rule (inclusion-exclusion)</strong>:<br>
                        \[
                        P(A \cup B) = P(A) + P(B) - P(A \cap B)
                        \]
                        Note: When \(A\) and \(B\) are mutually exclusive, \(P(A \cap B) = 0\), recovering Axiom 3.
                    </li>
                    <li><strong>Monotonicity</strong>:<br>
                        If \(B \subseteq A\), then \(A = B \cup (A \cap \bar{B})\) with disjoint union, so
                        \[
                        P(A) - P(B) = P(A \cap \bar{B}) \geq 0.
                        \]
                    </li>
                    <li><strong>De Morgan's laws</strong>:<br>
                        \[
                        \begin{align*}
                        P(\overline{A \cup B}) &= P(\bar{A} \cap \bar{B}) \\\\
                        P(\overline{A \cap B}) &= P(\bar{A} \cup \bar{B})
                        \end{align*}
                        \]
                    </li>
                </ol>

                <p>
                    The formula \(P(A) = |A|/|S|\) requires us to count the elements in \(A\) and \(S\). For complex 
                    experiments, direct enumeration quickly becomes impractical. The following counting principles 
                    provide systematic tools for this task.
                </p>

                <ol style="padding-left: 40px;">
                    <li><strong>Multiplication principle</strong>:<br>
                        If an experiment consists of a sequence of operations \(O_1, O_2, \ldots, O_r\) 
                        with \(n_1, n_2, \ldots, n_r\) outcomes respectively, then the total number of possible outcomes 
                        is the product \(n_1 n_2 \cdots n_r\).
                    </li>
                    <li><strong>Permutation</strong>:<br>
                        An ordered selection of \(r\) objects from \(n\) distinct objects (sampling without replacement 
                        where order matters):
                        {% raw %}
                        \[
                        {}_nP_r = n(n-1)(n-2)\cdots(n-r+1) = \frac{n!}{(n-r)!}.
                        \] 
                        {% endraw %}
                    </li>
                    <li><strong>Combination</strong>:<br>
                        An unordered selection of \(r\) objects from \(n\) distinct objects (sampling without replacement 
                        where order does not matter):
                        \[
                        \binom{n}{r} = \frac{n!}{r!(n-r)!} = \frac{{}_nP_r}{r!}.
                        \] 
                        This is the <strong>binomial coefficient</strong>. More generally, partitioning \(n\) objects 
                        into \(k\) groups of sizes \(r_1, r_2, \ldots, r_k\) with \(r_1 + r_2 + \cdots + r_k = n\) 
                        yields the <strong>multinomial coefficient</strong>:
                        \[
                        \frac{n!}{r_1!\, r_2!\, \cdots\, r_k!}.
                        \]
                        For example, the number of ways to deal 52 cards evenly among 4 players is 
                        \(\frac{52!}{(13!)^4}\).
                    </li>
                </ol><br>

                <p>
                    With these tools in hand, we can compute probabilities for a wide range of discrete experiments. 
                    However, many real-world situations require reasoning about how the probability of one event changes 
                    when we learn that another event has occurred. This leads us naturally to the concept of 
                    conditional probability.
                </p>

                <div class="insight-box">
                    <h3>From Axioms to Measure Theory</h3>
                    <p>
                        The axioms presented here work well for finite and countable sample spaces. However, when the 
                        sample space is uncountable (e.g., \(S = \mathbb{R}\)), Axiom 3 must be strengthened to 
                        <strong>countable additivity</strong>, and we cannot assign probabilities to <em>every</em> subset 
                        of \(S\) without encountering paradoxes. This necessitates the formal machinery of 
                        \(\sigma\)-algebras and probability measures, which we develop rigorously in 
                        <a href="../Calculus/measure.html"><strong>Section II - Part 11: Measure Theory with Probability</strong></a>.
                        The intuitive treatment here provides the working foundation needed for the sections that follow.
                    </p>
                </div>

            </section>

            <section id="conditional" class="section-content">

                <h2>Conditional Probability</h2>

                <p>
                    In practice, we rarely evaluate probabilities in a vacuum. When a medical test returns positive, 
                    we want the probability of disease <em>given</em> the test result. When a spam filter processes 
                    an email, it needs the probability that the message is spam <em>given</em> the words it contains. 
                    Conditional probability formalizes this idea of updating beliefs in light of new information.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Conditional Probability</span>
                    <p>
                        The <strong>conditional probability</strong> of an event \(A\) given that event \(B\) has occurred 
                        (with \(P(B) > 0\)) is defined as:
                        \[
                        P(A \mid B) = \frac{P(A \cap B)}{P(B)}. \tag{1}
                        \]
                    </p>
                </div>

                <p>
                    Intuitively, once we know that \(B\) has occurred, the effective sample space shrinks from \(S\) to \(B\), 
                    and we ask what fraction of \(B\) also belongs to \(A\). Rearranging Equation (1) gives the useful 
                    <strong>multiplication rule</strong>:
                    \[
                    P(A \cap B) = P(A \mid B)\, P(B). \tag{2}
                    \]
                </p>

                <p>
                    Since \(P(A \cap B) = P(B \cap A)\), we can also write:
                    \[
                    P(B \mid A) = \frac{P(A \cap B)}{P(A)} = \frac{P(A \mid B)\, P(B)}{P(A)}. \tag{3}
                    \]
                    Equation (3) is the simplest form of <strong>Bayes' theorem</strong>, which we will state more 
                    generally after introducing the Law of Total Probability.
                </p>

                <p>
                    A natural question arises: when does learning about \(B\) provide <em>no</em> information about \(A\)? 
                    This motivates the concept of independence.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Independence</span>
                    <p>
                        Two events \(A\) and \(B\) are <strong>mutually independent</strong> if
                        \[
                        P(A \cap B) = P(A)\,P(B).
                        \]
                        Equivalently (when \(P(B) > 0\)): \(P(A \mid B) = P(A)\), meaning that observing \(B\) does not 
                        change the probability of \(A\).
                    </p>
                </div>

                <p>
                    Independence propagates to complements. If \(A\) and \(B\) are mutually independent, then:
                    \[
                    \begin{align*}
                    P(A \cap \bar{B}) &= P(A)\bigl[1 - P(B)\bigr] \\\\
                                      &= P(A) - P(A)P(B) \\\\
                                      &= P(A) - P(A \cap B) \\\\
                                      &= P(A)\,P(\bar{B}).
                    \end{align*}
                    \]
                    Similarly, \(P(\bar{A} \cap B) = P(\bar{A})\,P(B)\) and 
                    \(P(\bar{A} \cap \bar{B}) = P(\bar{A})\,P(\bar{B})\). That is, independence of \(A\) and \(B\) 
                    implies independence of any combination involving their complements.
                </p>
                
                <p>
                    <strong>Caution:</strong> Independence and mutual exclusivity are fundamentally different concepts. 
                    If \(A\) and \(B\) are mutually exclusive with \(P(A) > 0\) and \(P(B) > 0\), then 
                    \(P(A \cap B) = 0 \neq P(A)P(B)\), so they are <em>not</em> independent. In fact, learning that 
                    one occurred tells us the other certainly did not â€” the events carry maximal information about each other.
                </p>

                <p>
                    Conditional probability allows us to decompose complex probability calculations by conditioning on 
                    different scenarios. When those scenarios partition the entire sample space, we obtain a powerful 
                    computational tool: the Law of Total Probability.
                </p>

            </section>

            <section id="total" class="section-content">
                
                <h2>Law of Total Probability</h2>

                <p>
                    Often, the direct computation of \(P(A)\) is difficult, but the conditional probabilities 
                    \(P(A \mid B_i)\) under different scenarios \(B_i\) are known or easier to estimate. 
                    The Law of Total Probability provides a systematic way to compute \(P(A)\) by 
                    summing over all possible scenarios.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem 1: Law of Total Probability</span> 
                    <p>
                        Let \(B_1, B_2, \ldots, B_k\) be a <strong>partition</strong> of the sample space \(S\): 
                        the events are mutually exclusive (\(B_i \cap B_j = \emptyset\) for \(i \neq j\)) and 
                        exhaustive (\(B_1 \cup B_2 \cup \cdots \cup B_k = S\)), with \(P(B_i) > 0\) for each \(i\). 
                        Then for any event \(A\),
                        \[
                        \begin{align*}
                        P(A)  &= \sum_{i = 1} ^k P(A \mid B_i)\,P(B_i) \\\\
                              &= P(A \mid B_1)\,P(B_1) + P(A \mid B_2)\,P(B_2) + \cdots +  P(A \mid B_k)\,P(B_k). \\\\
                        \end{align*}
                        \]
                    </p>
                </div>

                <div class="proof">
                    <span class="proof-title">Proof:</span>
                    <p>
                        Since \(\{B_i\}\) partitions \(S\), we can decompose \(A\) as:
                        \[
                        A = (A \cap B_1) \cup (A \cap B_2) \cup \cdots \cup (A \cap B_k).
                        \]
                        The sets \(A \cap B_i\) are mutually exclusive (because the \(B_i\) are), so by Axiom 3 applied 
                        repeatedly:
                        \[
                        \begin{align*}
                        P(A) &= P[(A \cap B_1) \cup (A \cap B_2) \cup \cdots \cup (A \cap B_k)] \\\\
                             &= P(A \cap B_1) +  P(A \cap B_2) + \cdots +  P(A \cap B_k) \\\\
                             &= \sum_{i=1}^{k} P(A \cap B_i) \\\\
                             &= \sum_{i=1}^{k} P(A \mid B_i)\,P(B_i)
                        \end{align*}
                        \]
                        where the last equality follows from the multiplication rule (Equation 2).
                    </p>
                </div>

                <p>
                    The Law of Total Probability is the key ingredient needed to state Bayes' theorem in its 
                    most useful form: it provides the denominator \(P(A)\) that normalizes the posterior probability.
                </p>

            </section>

            <section id="bayes" class="section-content">
                <h2>Bayes' Theorem</h2>
                
                <p>
                    We saw in Equation (3) that \(P(B \mid A) = P(A \mid B)\,P(B) / P(A)\). The quantity \(P(B)\) is called the 
                    <strong>prior probability</strong> of \(B\) - our belief about \(B\) before observing any data - and \(P(B \mid A)\) 
                    is the <strong>posterior probability</strong> - our updated belief after observing that \(A\) has occurred. This 
                    inversion of conditioning, from \(P(A \mid B)\) to \(P(B \mid A)\), is the foundation of <strong>Bayesian statistics</strong> 
                    and lies at the heart of many machine learning algorithms.
                </p>

                <p>
                    By applying the Law of Total Probability to the denominator, we obtain the general form of Bayes' theorem.
                </p>
                
                <div class="theorem">
                    <span class="theorem-title">Theorem 2: Bayes' Theorem</span>
                    <p>
                        Let \(B_1, B_2, \ldots, B_k\) be a partition of the sample space \(S\) with \(P(B_i) > 0\) 
                        for each \(i\). Then for any event \(A\) with \(P(A) > 0\) and for \(j = 1, 2, \ldots, k\),
                        \[
                        \begin{align*}
                        P(B_j \mid A) &= \frac{P(A \mid B_j)\,P(B_j)}{\sum_{i=1}^{k} P(A \mid B_i)\,P(B_i)} \\\\
                                      &= \frac{P(B_j \cap A)}{P(A)}.
                        \end{align*}
                        \]
                    </p>
                </div>

                <p>
                    The numerator \(P(A \mid B_j)\,P(B_j) = P(A \cap B_j)\) captures how likely the observed data \(A\) 
                    is under hypothesis \(B_j\), weighted by our prior belief. The denominator is the total probability 
                    \(P(A)\), which serves as a normalizing constant ensuring the posterior probabilities sum to one.
                </p>

                <div class="insight-box">
                    <h3>Insight: Bayes' Theorem in Machine Learning</h3>
                    <p>
                        Bayes' theorem is the foundation of probabilistic machine learning. In a <strong>classification</strong> 
                        setting, let \(B_1, B_2, \ldots, B_k\) represent possible classes and let \(A\) represent observed 
                        features (e.g., pixel values, word frequencies, or sensor readings). Then \(P(B_j \mid A)\) is the 
                        posterior probability that the input belongs to class \(B_j\). This reasoning underlies 
                        <strong>Naive Bayes classifiers</strong>, <strong>Bayesian neural networks</strong>, 
                        and the entire framework of <strong>Bayesian inference</strong>. 
                        In medical diagnosis, \(B_1, \ldots, B_k\) represent possible diseases, \(A\) represents observed symptoms, 
                        and the posterior \(P(B_j \mid A)\) ranks the most likely diagnoses.
                    </p>

                    <p>
                        The denominator is the total probability \(P(A)\), which serves as a normalizing constant. In practice, 
                        especially in Bayesian inference, calculating this denominator is often the most computationally 
                        challenging part, as it may involve high-dimensional integrals that are analytically intractable. 
                        <strong>Developing methods to approximate this term is a major focus of modern probabilistic modeling, 
                        which we will explore in later sections.</strong>
                    </p>
                </div>
                
                <p>
                    With the foundations of probability, conditional reasoning, and Bayes' theorem established, we are 
                    ready to move beyond events and introduce <strong>random variables</strong> - numerical functions on the 
                    sample space that enable the full power of calculus and algebra to be brought to bear on 
                    probabilistic problems. This is the subject of 
                    <a href="random_variables.html"><strong>Part 2: Random Variables</strong></a>.
                </p>

            </section>
             
        </div> 
        <script src="/js/main.js"></script> 
    </body>
</html>