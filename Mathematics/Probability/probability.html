<!DOCTYPE html>
<html>
    <head> 
        <title>Probability</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Probability & Statistics</h1>
        <blockquote>
            <p style="text-indent: 40px;">
            Machine learning is an elegant fusion of statistics and algorithms. To truly understand machine learning, a strong 
            grasp of <strong>probability</strong> is essential. In Section I: Linear Algebra, we intentionally avoided discussing applications related 
            to probability, focusing instead on foundational concepts. Now, it's time to build upon the probabilistic basis of machine 
            learning. This section will introduces  the essential concepts of probability, providing the tools and insights necessary 
            to understand and apply machine learning techniques.    
            </p>
        </blockquote>
        <section>
            <h2><a href="basic.html"><strong>Part 1: Basic Probability Ideas </strong></a></h2>     
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Probability</span>
                    <span>Sample Space</span>
                    <span>Events</span>
                    <span>Mutually Exclusive</span>
                    <span>Permutation</span>
                    <span>Combinations</span>
                    <span>Conditional Probability</span>
                    <span>Independent Events</span>
                    <span>Law of Total Probability</span>
                    <span>Bayes' Theorem</span>          
                </div>
                
            <h2><a href="random_variables.html"><strong>Part 2: Random Variables </strong></a></h2>       
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Discrete Random Variables</span>
                    <span>continuous Random Variables</span>
                    <span>probability Mass Function (p.m.f.)</span>
                    <span>probability Density Function (p.d.f.)</span>
                    <span>Cumulative Distribution Function(c.d.f.)</span>
                    <span>Expected Value</span>
                    <span>Variance</span>
                    <span>Standard Deviation</span>
                </div>
            
            <h2><a href="gamma.html"><strong>Part 3: Gamma & Beta Distribution</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Gamma Distribution</span>
                    <span>Gamma Function</span> 
                    <span>Exponential Distribution</span>
                    <span>Beta Function</span>
                    <span>Beta Distribution</span>
                    <span>Uniform Distribution</span>
                </div>
            
            <h2><a href="gaussian.html"><strong>Part 4: Normal (Gaussian) Distribution</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Gaussian Function</span>
                    <span>Error Function</span>
                    <span>Gaussian Integral</span>
                    <span>Normal(Gaussian) Distribution</span> 
                    <span>Standard Normal Distribution</span>
                    <span>Independent and Identically Distributed(i.i.d.)</span>
                    <span>Random Sample</span>
                    <span>Sample Mean</span>
                    <span>Sample Variance</span>
                    <span>Central Limit Theorem</span>
                </div>

            <h2><a href="covariance.html"><strong>Part 5: Covariance </strong></a></h2>      
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Covariance</span>
                    <span>Covariance matrix</span>
                    <span>Total Variance</span>
                    <span>Principal Component</span>
                    <span>Principal Component Analysis(PCA)</span>
                </div>
       
            <h2><a href="correlation.html"><strong>Part 6: Correlation</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Cross-Covariance matrix</span>
                    <span>Auto-Covariance matrix</span> 
                    <span>Correlation Coefficient</span>
                    <span>Correlation matrix</span>
                </div>

            <h2><a href="mvn.html"><strong>Part 7: Multivariate Normal Distribution</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Multivariate Normal Distribution (MVN)</span>
                    <span>Bivariate Normal Distribution</span> 
                </div>

            <h2><a href="mle.html"><strong>Part 8: Maximum Likelihood Estimate</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Point Estimator</span>
                    <span>Mean Square Error(MSE)</span>
                    <span>Standard Error (SE)</span>
                    <span>Likelihood Function</span> 
                    <span>Log-likelihood Function</span> 
                    <span>Maximum Likelihood Estimate (MLE)</span>   
                    <span>Binomial Distribution</span>
                    <span>Sample Proportion</span>
                </div>     


            <h2><a href="linear_regression.html"><strong>Part 9: Linear Regression</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Linear Regression</span>
                    <span>Least-Squares Estimation</span>
                </div> 
            
            <h2><a href="entropy.html"><strong>Part 10: Entropy</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Information Content</span>
                    <span>Entropy</span>
                    <span>Joint Entropy</span>
                    <span>Conditional Entropy</span>
                    <span>Cross Entropy</span>
                    <span>KL Divergence (Relative Entropy, Information Gain)</span>
                    <span>Gibbs' Inequality</span>
                    <span>Log Sum Inequality</span>
                    <span>Jensen's Inequality</span>
                    <span>Mutual Information (MI)</span>
                </div> 

            <h2><a href="convergence.html"><strong>Part 11: Convergence</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Convergence in Probability</span>
                    <span>Convergence in Distribution</span>
                    <span>Asymptotic Distribution</span>
                </div>


        </section>
        <br>
        <a href="../../index.html">Back to Home </a>
    </body>
</html>