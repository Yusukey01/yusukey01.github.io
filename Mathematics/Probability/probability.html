<!DOCTYPE html>
<html>
    <head> 
        <title>Probability</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Probability & Statistics</h1>
        <blockquote>
            <p style="text-indent: 40px;">
            To truly understand machine learning, a strong grasp of <strong>probability theory</strong> and <strong>statistics</strong> 
            is essential because machine learning is an elegant combination statistics and algorithms. In Section I: Linear Algebra, we 
            intentionally avoided applications related to statistics, focusing instead on foundational concepts. Now, it's time to build 
            upon the probabilistic basis of machine learning. This section introduces the essential concepts of probability, providing 
            the tools and insights necessary to understand and apply machine learning techniques. At its core, statistics involves inferring 
            unknown parameters from outcomes. This process is the inverse of probability theory. Two main approaches dominate statistical 
            inference: <strong>frequentist statistics</strong>, which treats parameters as fixed and data as random, and in contrast, 
            <strong>Bayesian statistics</strong>, which treats data as fixed and parameters as random. In particular, Bayesian statistics 
            forms the foundation of many machine learning algorithms. 
            </p>
        </blockquote>
        <section>
            <h2><a href="basic.html"><strong>Part 1: Basic Probability Ideas </strong></a></h2>     
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Probability</span>
                    <span>Sample Space</span>
                    <span>Events</span>
                    <span>Mutually Exclusive</span>
                    <span>Permutation</span>
                    <span>Combinations</span>
                    <span>Conditional Probability</span>
                    <span>Independent Events</span>
                    <span>Law of Total Probability</span>
                    <span>Bayes' Theorem</span>          
                </div>
                
            <h2><a href="random_variables.html"><strong>Part 2: Random Variables </strong></a></h2>       
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Discrete Random Variables</span>
                    <span>continuous Random Variables</span>
                    <span>probability Mass Function (p.m.f.)</span>
                    <span>probability Density Function (p.d.f.)</span>
                    <span>Cumulative Distribution Function(c.d.f.)</span>
                    <span>Expected Value</span>
                    <span>Variance</span>
                    <span>Standard Deviation</span>
                </div>
            
            <h2><a href="gamma.html"><strong>Part 3: Gamma & Beta Distribution</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Gamma Distribution</span>
                    <span>Gamma Function</span> 
                    <span>Exponential Distribution</span>
                    <span>Beta Function</span>
                    <span>Beta Distribution</span>
                    <span>Uniform Distribution</span>
                </div>
            
            <h2><a href="gaussian.html"><strong>Part 4: Normal (Gaussian) Distribution</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Gaussian Function</span>
                    <span>Error Function</span>
                    <span>Gaussian Integral</span>
                    <span>Normal(Gaussian) Distribution</span> 
                    <span>Standard Normal Distribution</span>
                    <span>Independent and Identically Distributed(i.i.d.)</span>
                    <span>Random Sample</span>
                    <span>Sample Mean</span>
                    <span>Sample Variance</span>
                    <span>Central Limit Theorem</span>
                </div>

            <h2><a href="covariance.html"><strong>Part 5: Covariance </strong></a></h2>      
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Covariance</span>
                    <span>Covariance matrix</span>
                    <span>Total Variance</span>
                    <span>Principal Component</span>
                    <span>Principal Component Analysis(PCA)</span>
                </div>
       
            <h2><a href="correlation.html"><strong>Part 6: Correlation</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Cross-Covariance matrix</span>
                    <span>Auto-Covariance matrix</span> 
                    <span>Correlation Coefficient</span>
                    <span>Correlation matrix</span>
                </div>

            <h2><a href="mvn.html"><strong>Part 7: Multivariate Normal Distribution</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Multivariate Normal Distribution (MVN)</span>
                    <span>Bivariate Normal Distribution</span> 
                </div>

            <h2><a href="mle.html"><strong>Part 8: Maximum Likelihood Estimate</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Point Estimator</span>
                    <span>Mean Square Error(MSE)</span>
                    <span>Standard Error (SE)</span>
                    <span>Likelihood Function</span> 
                    <span>Log-likelihood Function</span> 
                    <span>Maximum Likelihood Estimate (MLE)</span>   
                    <span>Binomial Distribution</span>
                    <span>Sample Proportion</span>
                </div>     


            <h2><a href="linear_regression.html"><strong>Part 9: Linear Regression</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Linear Regression</span>
                    <span>Least-Squares Estimation</span>
                </div> 
            
            <h2><a href="entropy.html"><strong>Part 10: Entropy</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Information Content</span>
                    <span>Entropy</span>
                    <span>Joint Entropy</span>
                    <span>Conditional Entropy</span>
                    <span>Cross Entropy</span>
                    <span>KL Divergence (Relative Entropy, Information Gain)</span>
                    <span>Gibbs' Inequality</span>
                    <span>Log Sum Inequality</span>
                    <span>Jensen's Inequality</span>
                    <span>Mutual Information (MI)</span>
                </div> 

            <h2><a href="convergence.html"><strong>Part 11: Convergence</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Convergence in Probability</span>
                    <span>Convergence in Distribution</span>
                    <span>Asymptotic(limiting) Distribution</span>
                    <span>Moment Generating Function(m.g.f.)</span>
                    <span>Central Limit Theorem(CLT)</span>
                </div>
            
            <h2><a href="bayesian.html"><strong>Part 12: Bayesian Statistics-1 (Introduction)</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Bayesian Inference</span>
                    <span>Prior Distribution </span>
                    <span>Posterior Distribution</span>
                    <span>Marginal Likelihood</span>
                    <span>Conjugate Prior</span>
                    <span>posterior Predictive Distribution:</span>
                    <span>Beta-Binomial Model</span>
                    <span>Normal Distribution Model with known Variance \(\sigma^2\)</span>
                    <span>Normal Distribution Model with known Mean \(\mu\)</span>
                </div> 
            
            <h2><a href="expfamily.html"><strong>Part 13: The Exponential Family</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Exponential Family</span>
                    <span>Natural Parameters(Canonical Parameters)</span>
                    <span>Base Measure</span>
                    <span>Sufficient Statistics</span>
                    <span>Partition Function</span>
                    <span>Minimal Representation</span>
                    <span>Natural Exponential Family(NEF)</span>
                    <span>Moment Parameters</span>
                    <span>Precision Matrix</span>
                    <span>Information Form</span>
                    <span>Moment Matching</span>
                    <span>Cumulants</span>
                </div>

                <h2><a href="fisher_info.html"><strong>Part 14: Fisher Information Matrix</strong></a></h2>
                <p><strong>Key words:</strong></p>
                <div class="keywords">
                    <span>Fisher Information Matrix(FIM)</span>
                    <span>Score Finction</span>
                    <span>Covariance</span>
                    <span>Negative Log Likelihood</span>
                    <span>Log Partition Function</span>
                    <span>KL Divergence</span>
                    <span>Natural Gradient</span>
                </div>
            
            
        </section>
        <br>
        <a href="../../index.html">Back to Home </a>
    </body>
</html>