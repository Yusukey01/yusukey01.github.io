---
layout: default
title: Intro to Bayesian Statistics
topic_id: prob-14
level: detail
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body>
        {% include learning_resource_schema.html topic_id=page.topic_id %}
       
        <div class="hero-section">
            <h1 class="webpage-name">Intro to Bayesian Statistics</h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#bayesian">Bayesian Inference</a>
            <a href="#conjugate">Conjugate Prior</a>
            <a href="#normal">Univariate Normal Distribution Model</a>
        </div> 

        <div class="container">  
           
            <section id="bayesian" class="section-content">
                <h2>Bayesian Inference</h2>

                 <p>
                    In <a href="mle.html"><strong>Part 9</strong></a>, we developed maximum likelihood estimation for fitting parameters 
                    to data, and in <a href="hypothesis_testing.html"><strong>Part 10</strong></a>, we introduced both frequentist confidence 
                    intervals and Bayesian credible intervals as ways to quantify uncertainty. The credible interval example there gave a first 
                    glimpse of the Bayesian approach - treating the parameter as a random variable and computing a posterior via a conjugate prior. 
                    In <a href="convergence.html"><strong>Part 13</strong></a>, we proved the convergence theorems that guarantee these estimation 
                    procedures are well-founded. We now develop the Bayesian framework systematically.
                </p>

                <p>
                    Recall the core idea: the unknown parameter \(\theta\) is treated as a <strong>random variable</strong> with a probability 
                    distribution, and the observed data \(\mathcal{D}\) are considered fixed. Prior knowledge or uncertainty about \(\theta\) 
                    is encoded in a <strong>prior distribution</strong> \(p(\theta)\), which is updated after observing data to produce a 
                    <strong>posterior distribution</strong> \(p(\theta \mid \mathcal{D})\) via <a href="basic.html#bayes"><strong>Bayes' theorem</strong></a>:
                    \[
                    p(\theta \mid \mathcal{D}) = \frac{p(\theta)\,p(\mathcal{D} \mid \theta)}{p(\mathcal{D})}.
                    \]
                    Let us now examine each component in detail:
                </p>

                <ol style="padding-left: 40px;">
                    <li><strong>Prior distribution</strong> \(p(\theta)\):<br>
                        <p>
                            Encodes our belief about the parameters \(\theta\) before observing any data. 
                            It captures prior knowledge, domain expertise, or initial uncertainty through a specific probability distribution.
                        </p>  
                    </li> 
                    
                    <li><strong>Likelihood</strong> \(p(\mathcal{D} \mid \theta)\):<br>
                        <p>
                            Quantifies how well a specific value of \(\theta\) explains the observed data \(\mathcal{D}\). 
                            This term represents the underlying model of the data-generating process.
                        </p>
                    </li>
                    
                    <li><strong>Marginal likelihood</strong> (or <strong>evidence</strong>) \(p(\mathcal{D})\):<br>
                        <p>
                            Serves as a normalization constant that ensures the posterior integrates to one. 
                            While often ignored during parameter estimation, it is indispensable for <strong>model selection</strong>, 
                            as it allows for the objective comparison of different probabilistic models.
                        </p>
                        <p>
                            For continuous parameters, marginal likelihood is computed by integrating over all possible values of \(\theta\):  
                            \[
                            p(\mathcal{D}) = \int p(\theta')p(\mathcal{D} \mid \theta') \, d\theta'.
                            \]
                            In the integral for the marginal likelihood, we use \(\theta'\) instead of \(\theta\) to clarify that 
                            the integration is over the entire parameter space, not a specific parameter. 
                        </p>
                        <p>
                            For discrete  parameters, marginal likelihood is given by:
                            \[
                            p(\mathcal{D}) = \sum_{\theta'} p(\theta')p(\mathcal{D} \mid \theta').
                            \]
                        </p>
                    </li>   
                </ol>
                
            </section>

            <section id="conjugate" class="section-content">
                <h2>Conjugate Prior</h2>

                <p>
                    One of the main challenges in Bayesian inference is choosing an appropriate prior. In general, finding the 
                    exact normalizing constant of the posterior requires evaluating the integral in the marginal likelihood, which 
                    is often intractable. What if there are families of priors for which the posterior has a known closed form 
                    without this difficulty?
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Conjugate Prior</span>
                    <p>
                        A prior \(p(\theta) \in \mathcal{F}\) is said to be a <strong>conjugate prior</strong> for a likelihood function 
                        \(p(\mathcal{D} \mid \theta)\) if the posterior is in the same parameterized family as the prior: 
                        \[
                        p(\theta \mid \mathcal{D}) \in \mathcal{F}. 
                        \]
                    </p>
                </div>

                <p>
                    Through the following example, we introduce basic Bayesian inference ideas and an example of a conjugate prior.
                </p>

                <div class="proof">
                    <span class="proof-title">Example 1: Beta-Binomial Model</span>
                    <p>
                        Consider tossing a coin \(N\) times. Let \(\theta \in [0, 1]\) be a chance of getting head. We record the outcomes as 
                        \(\mathcal{D} = \{y_n \in \{0, 1\} : n = 1 : N\}\). We assume the data are iid.
                    </p>

                    <p>
                        If we consider a sequence of coin tosses, the <strong>likelihood</strong> can be written as a Bernoulli likelihood model: 
                        \[
                        \begin{align*}
                        p(\mathcal{D} \mid \theta) &= \prod_{n = 1}^N \theta^{y_n}(1 - \theta)^{1-y_n} \\\\
                                                &= \theta^{N_1}(1 - \theta)^{N_0}
                        \end{align*}
                        \]
                        where \(N_1\) and \(N_0\) are the number of heads and tails respectively. (Sample size: \(N_1 + N_0 = N\))
                    </p>

                    <p>
                        Alternatively, we can consider the Binomial likelihood model: 
                        The likelihood has the following form:
                        \[
                        \begin{align*}
                        p(\mathcal{D} \mid \theta) &= \text{Bin } (y \mid N, \theta)  \\\\
                                                &= \begin{pmatrix} N \\ y \end{pmatrix} \theta^y (1 - \theta)^{N - y} \\\\
                                                &\propto  \theta^y (1 - \theta)^{N - y}
                        \end{align*}
                        \]
                        where \(y\) is the number of heads.
                    </p>

                    <p>
                        Next, we have to specify a <strong>prior</strong>. If we know nothing about the parameter, an 
                        <strong>uninformative prior</strong> can be used:
                        \[
                        p(\theta) = \text{Unif }(\theta \mid 0, 1).
                        \]
                        However, "in this example", using <a href="gamma.html#beta_d">Beta distribution</a>, 
                        we can represent the prior as follows:
                        \[
                        \begin{align*}
                        p(\theta) = \text{Beta }(\theta \mid a, b) &= \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\theta^{a-1}(1-\theta)^{b-1} \tag{1} \\\\
                                                                &\propto \theta^{a-1}(1-\theta)^{b-1}
                        \end{align*}
                        \]
                        where \(a, b > 0\) are usually called hyper-parameters.(Our main parameter is \(\theta\).)
                    </p>

                    <p>
                        Note: If \(a = b = 1\), we get the uninformative prior. 
                    </p>

                    <p>
                        Using Bayes' rule, the <strong>posterior</strong> is proportional to the product of the likelihood and the prior:
                        \[
                        \begin{align*}
                        p(\theta \mid \mathcal{D}) &\propto [\theta^{y}(1 - \theta)^{N-y}] \cdot [\theta^{a-1}(1-\theta)^{b-1}] \\\\
                                                &\propto \text{Beta }(\theta \mid a+y, \, b+N-y) \\\\
                                                &= \frac{\Gamma(a+b+N)}{\Gamma(a+y)\Gamma(b+N-y)}\theta^{a+y-1}(1-\theta)^{b+N-y-1}. \tag{2}
                        \end{align*}
                        \]
                        Here, the posterior has the same functional form as the prior. Thus, the beta distribution is the 
                        <strong>conjugate prior</strong> for the binomial distribution. 
                    </p>

                    <p>
                        Once we got the posterior distribution, for example, we can use <strong>posterior mean</strong> \(\bar{\theta}\) as a point estimate of \(\theta\):
                        \[
                        \begin{align*}
                        \bar{\theta} = \mathbb{E }[\theta \mid \mathcal{D}] &= \frac{a+y}{(a+y) + (b+N-y)} \\\\
                                                                        &= \frac{a+y}{a+b+N}.
                        \end{align*}
                        \]
                        Note: 
                        By adjusting hyper-parameters \(a\) and \(b\), we can control the influence of the prior on the posterior.
                    </p>

                    <p>
                        If \(a\) and \(b\) are small, the posterior mean will closely reflect the data: 
                        \[
                        \bar{\theta} \approx  \frac{y}{N} = \hat{\theta}_{MLE}
                        \]
                        while if \(a\) and \(b\) are large, the posterior mean will be more influenced by the prior.
                    </p>
                    <p>
                        Often we need to check the <strong>standard error</strong> of our estimate, which is the posterior standard deviation:
                        \[
                        \begin{align*}
                        \text{SE }(\theta) &= \sqrt{\text{Var }[\theta \mid \mathcal{D}]} \\\\
                                        &= \sqrt{\frac{(a+y)(b+N-y)}{(a+b+N)^2(a+b+N+1)}}
                        \end{align*}
                        \]
                        Here, if \(N \gg a, b\), we can simplify the <strong>posterior variance</strong> as follows:
                        \[
                        \begin{align*}
                        \text{Var }[\theta \mid \mathcal{D}] &\approx \frac{y(N-y)}{(N)^2 N} \\\\
                                                        &= \frac{y}{N^2} - \frac{y^2}{N^3} \\\\
                                                        &= \frac{\hat{\theta}(1 - \hat{\theta})}{N}
                        \end{align*}
                        \]
                        where \(\hat{\theta} = \frac{y}{N}\) is the MLE.
                    </p>
                    <p>
                        Thus, the standard error is given by 
                        \[
                        \text{SE }(\theta) \approx \sqrt{\frac{\hat{\theta}(1 - \hat{\theta})}{N}}.
                        \]
                    </p>
                    <p>
                        From (1) and (2), the <strong>marginal likelihood</strong> is given by the ratio of normalization constants(beta functions) 
                        for the prior and posterior:
                        \[
                        p(\mathcal{D}) = \frac{B(a+y,\, b+N-y)}{B(a, b)}.
                        \]
                        Note: In general, computing the marginal likelihood is too expensive or impossible, but the conjugate prior allows us to get the 
                        exact marginal likelihood easily. Otherwise, we have to introduce some approximation methods.
                    </p>
                    <p>
                        Finally, to make predictions for new observations, we use <strong>posterior predictive distribution</strong>:
                        \[
                        p(x_{new} \mid \mathcal{D}) = \int p(x_{new} \mid \theta) p(\theta \mid \mathcal{D}) d\theta.
                        \]
                        Again, like computing the marginal likelihood, it is difficult to compute posterior predictive distribution, but in this case, 
                        we can get it easily due to the conjugate prior. 
                    </p>
                    <p>
                        For example, the probability of observing a head in the next coin toss is given by:
                        \[
                        \begin{align*}
                        p(y_{new}=1 \mid \mathcal{D}) &= \int_0 ^1  p(y_{new}=1 \mid \theta) p(\theta \mid \mathcal{D}) d\theta \\\\
                                                &= \int_0 ^1 \theta \text{Beta }(\theta \mid a+y, \, b+N-y) d\theta \\\\
                                                &= \mathbb{E }[\theta \mid \mathcal{D}] \\\\
                                                &= \frac{a+y}{a+b+N}.
                        \end{align*}
                        \]
                        Note: As you can see, the hyper-parameters \(a\) and \(b\) are critical in the whole process of our inference. 
                        In practice, setting up hyper-parameters is one of the most challenging aspects of the project. 
                    </p>
                </div>

                <div class="insight-box">
                    <h3>Hyperparameters as Pseudo-Counts</h3>
                    <p>
                        In machine learning, the hyper-parameters \(a\) and \(b\) of the Beta prior can be highly intuitive: they act as 
                        <strong>pseudo-observations</strong> or <strong>effective prior counts</strong>. Before flipping the coin even once, 
                        an AI agent with a prior of \(\text{Beta}(a, b)\) behaves exactly as if it has already observed \(a\) heads and \(b\) tails. 
                        This structural equivalence is a common trick in natural language processing (like Laplace smoothing in Naive Bayes), 
                        preventing models from assigning zero probability to unseen events.
                    </p>
                </div>

            </section>

            <section id="normal" class="section-content">
                <h2>Univariate Normal Distribution Model</h2>


                <p>
                    We now apply the same Bayesian framework to the <a href="gaussian.html"><strong>normal distribution</strong></a>. 
                     Given the univariate normal distribution \(N(\mu, \sigma^2)\), there are three cases for our target posterior: 
                </p>

                <ol style="padding-left: 40px;">
                    <li>\(p(\mu \mid \mathcal{D}, \sigma^2)\): Variance \(\sigma^2\) is known.</li>
                    <li>\(p(\sigma^2 \mid \mathcal{D}, \mu)\): Mean \(\mu\) is known.</li>
                    <li>\(p(\mu, \sigma^2 \mid \mathcal{D})\): Both are unknown.</li>
                </ol>

                <p>
                    <p>
                    Here, we discuss cases 1 and 2. (Case 3 requires the normal-inverse-gamma conjugate prior and is treated in 
                    more advanced references.)
                </p>

                <div class="proof">
                    <span class="proof-title">Example 2: Normal distribution model with known variance \(\sigma^2\)</span>

                    <p>
                        In the case where \(\sigma^2\) is known constant, the <strong>likelihood</strong> for \(\mu\) is given by 
                        \[
                        \begin{align*}
                        p(\mathcal{D} \mid \mu) &= \prod_{n=1}^N \frac{1}{\sqrt{2\pi \sigma^2}} \exp \left(-\frac{(y_n - \mu)^2}{2\sigma^2}\right)\\\\
                                                &= \left(\frac{1}{\sqrt{2\pi \sigma^2}}\right)^N \exp \left(- \sum_{n=1}^N \frac{(y_n - \mu)^2}{2\sigma^2}\right) \\\\
                                                &\propto \exp \left(-\frac{1}{2\sigma^2} \sum_{n=1}^N (y_n - \mu)^2 \right).
                        \end{align*}
                        \]
                    </p>

                    <p>
                        The <strong>conjugate prior</strong> is another normal distribution:
                        \[
                        \begin{align*}
                        p(\mu) &= N(\mu \mid \, \mu_0, \sigma_0^2) \\\\
                            &\propto \exp \left(-\frac{(\mu - \mu_0)^2}{2\sigma_0^2} \right).
                        \end{align*}
                        \]
                    </p>

                    <p>
                        Now, we can compute the <strong>posterior</strong> as follows:
                        \[
                        \begin{align*}
                        p(\mu \mid \, \mathcal{D}, \sigma^2) 
                        &\propto \exp \left(-\frac{1}{2\sigma^2} \sum_{n=1}^N (y_n - \mu)^2 \right) \cdot \exp \left(-\frac{(\mu - \mu_0)^2}{2\sigma_0^2} \right) \\\\
                        &= \exp \left\{-\frac{1}{2}\left(\frac{N}{\sigma^2}+\frac{1}{\sigma_0^2} \right)\mu^2 +\left(\frac{\sum y_n}{\sigma^2} +\frac{\mu_0}{\sigma_0^2} \right)\mu 
                                    + \left(-\frac{1}{2\sigma^2} \sum_{n=1}^N y_n^2 - \frac{\mu_0^2}{2\sigma_0^2} \right) \right\}
                        \end{align*}
                        \]
                        Since \(-\frac{1}{2\sigma^2} \sum_{n=1}^N y_n^2 - \frac{\mu_0^2}{2\sigma_0^2}\) is constant with respect to \(\mu\), we ignore it.
                    </p>

                    <p>
                        Let \(A = \left(\frac{N}{\sigma^2}+\frac{1}{\sigma_0^2} \right)\) and \(B = \left(\frac{\sum y_n}{\sigma^2} +\frac{\mu_0}{\sigma_0^2} \right)\), 
                        and completing the square, we get:
                        \[
                        \begin{align*}
                        p(\mu \mid \, \mathcal{D}, \sigma^2) 
                        &\propto \exp \left\{-\frac{1}{2}A\mu^2 + B\mu \right\} \\\\
                        &= \exp \left\{-\frac{1}{2}A \left(\mu - \frac{B}{A} \right)^2 + \frac{B^2}{2A}\right\}.                     
                        \end{align*}
                        \]
                    </p>

                    <p>
                        Since the term \(\frac{B^2}{2A}\) does not depend on \(\mu\), and \(-\frac{1}{2}A \left(\mu - \frac{B}{A} \right)^2\) 
                        is a quadratic form of an univariate normal distribution, we conclude that
                        \[
                        \begin{align*}
                        p(\mu \mid \, \mathcal{D}, \sigma^2)  = N(\mu \mid \, \mu_N, \sigma_N^2 )
                        \end{align*}
                        \]
                        where the <strong>posterior variance</strong> is given by:
                        \[
                        \begin{align*}
                        \sigma_N^2 &= \frac{1}{A} \\\\
                                &= \frac{\sigma^2 \sigma_0^2}{N\sigma_0^2 + \sigma^2}
                        \end{align*}
                        \]
                        and the <strong>posterior mean</strong> is given by:
                        \[
                        \begin{align*}
                        \mu_N &= \frac{B}{A} \\\\
                            &= \sigma_N^2 \left(\frac{\mu_0}{\sigma_0^2} + \frac{N \bar{y}}{\sigma^2} \right) \\\\
                            &= \frac{\sigma^2}{N\sigma_0^2 + \sigma^2}\mu_0 + \frac{N\sigma_0^2}{N\sigma_0^2 + \sigma^2}\bar{y} \\\\
                        \end{align*}
                        \]
                        where \(\bar{y} = \frac{1}{N}\sum_{n=1}^N y_n\) is the empirical mean. 
                    </p>

                    <p>
                        Note: In this case, \(\mu_0\) and \(\sigma_0^2\) are hyper-parameters of the prior distribution. For example, as you can 
                        see the form of the posterior mean \(\mu_N\), a small \(\sigma_0^2\) gives more weight to the prior mean \(\mu_0\), while 
                        a large \(\sigma_0^2\) reduces the influence of the prior, making the posterior more rely on the data.
                    </p>
                </div>

                <div class="insight-box">
                    <h3>Condition Number in Deep Learning</h3>
                    <p>
                        The true power of conjugate priors in computer science is memory efficiency. In <strong>online learning</strong>, we do not need 
                        to store massive historical datasets in memory. Because the posterior and prior share the same functional form, today's posterior 
                        simply becomes tomorrow's prior. For sequential data points \(y_1, y_2\), the update rule is structurally elegant:
                        \[
                        p(\mu \mid y_1, y_2) \propto p(y_2 \mid \mu) p(\mu \mid y_1)
                        \]
                        An AI system only needs to maintain the current sufficient statistics (like \(\mu_N\) and \(\sigma_N^2\)) and update them as new data 
                        streams in, demonstrating a perfect synergy between mathematical structure and computational limits.
                    </p>  
                </div>

                <div class="proof">
                    <span class="proof-title">Example 3: Normal distribution model with known mean \(\mu\)</span>

                    <p>
                        In the case where \(\mu\) is known constant, the <strong>likelihood</strong> for \(\sigma^2\) is given by 
                        \[
                        \begin{align*}
                        p(\mathcal{D} \mid \sigma^2) 
                        &= \frac{1}{(2 \pi \sigma^2)^{\frac{N}{2}}} \exp \left(-\frac{1}{2\sigma^2} \sum_{n=1}^N (y_n - \mu)^2 \right) \\\\
                        &\propto (\sigma^2)^{-\frac{N}{2}} \exp \left(-\frac{1}{2\sigma^2} \sum_{n=1}^N (y_n - \mu)^2 \right).            
                        \end{align*}
                        \]
                        The "standard" <strong>conjugate prior</strong> is the <strong>inverse gamma distribution</strong>:
                        \[
                        \begin{align*}
                        p(\sigma^2) &= \text{InvGamma }(\sigma^2 \mid \, a, b) \\\\
                                    &= \frac{b^a}{\Gamma(a)}(\sigma^2)^{-(a+1)} \exp \left(- \frac{b}{\sigma^2}\right)
                        \end{align*}
                        \]
                        where \(a > 0\) is the shape parameter and  \(b > 0\) is the scale parameter.
                    </p>

                    <p>
                        The <strong>posterior</strong> is given by:
                        \[
                        \begin{align*}
                        p(\sigma^2 \mid \, \mathcal{D}, \mu) 
                        &\propto \left\{ (\sigma^2)^{-\frac{N}{2}} \exp \left(-\frac{1}{2\sigma^2} \sum_{n=1}^N (y_n - \mu)^2 \right) \right\}
                                      \cdot \left\{\frac{b^a}{\Gamma(a)}(\sigma^2)^{-(a+1)} \exp \left(- \frac{b}{\sigma^2}\right) \right\} \\\\    
                        &= (\sigma^2)^{-(a+\frac{N}{2}+1)} \exp \left\{ - \frac{1}{\sigma^2}\left(b + \frac{1}{2} \sum_{n=1}^N (y_n - \mu)^2 \right) \right\}.                                                           
                        \end{align*}
                        \]
                        Here, let \(\hat{a} = a + \frac{N}{2}\), and \(\hat{b} = b + \frac{1}{2} \sum_{n=1}^N (y_n - \mu)^2\).
                        Thus,
                        \[
                        p(\sigma^2 \mid \, \mathcal{D}, \mu) = \text{InvGamma }(\sigma^2 \mid \, \hat{a}, \hat{b}).
                        \]
                    </p>

                    <p>
                        Alternatively, we can choose <strong>scaled inverse chi-squared distribution</strong> as the conjugate prior:
                        \[
                        \begin{align*}
                        p(\sigma^2) &= \text{ScaledInv- }\chi^2(\sigma^2 \mid \, \nu_0, \sigma_0^2) \\\\
                                    &= \text{InvGamma }\left(\sigma^2 \mid \, \frac{\nu_0}{2}, \frac{\nu_0 \sigma_0^2}{2}\right) \\\\
                                    &\propto (\sigma^2)^{-\frac{\nu_0}{2}-1} \exp \left(- \frac{\nu_0 \sigma_0^2}{2\sigma^2} \right)
                        \end{align*}
                        \]
                        where \(\nu\) is the degrees of freedom. 
                    </p>
                    <p>
                        Thus, the posterior is given by:
                        \[
                        p(\sigma^2 \mid \, \mathcal{D}, \mu) 
                        = \text{ScaledInv- }\chi^2 \left(\sigma^2 \mid \, \nu_0 + N, \, \frac{\nu_0 \sigma_0^2 + \sum_{n=1}^N (y_n - \mu)^2}{\nu_0 + N}\right).
                        \]
                        A benefit of using this form is that we can control the strength of the prior by the single hyper-parameter \(\nu_0\).
                    </p>
                </div>

                <div class="insight-box">
                    <h3>Anomaly Detection and Uncertainty</h3>
                    <p>
                        This model is a cornerstone for <strong>quality control</strong> and process monitoring. In industrial manufacturing, the "target" mean of 
                        a process is often known from historical data, while the variance represents the stability of the process.
                    </p>
                    <p>
                        In machine learning, this is the fundamental principle of <strong>anomaly detection</strong>. Unlike simple frequentist methods that use a 
                        point estimate for variance, the Bayesian approach evaluates new data points against the <strong>posterior predictive distribution</strong>. 
                        By integrating over the inverse-gamma posterior of \(\sigma^2\), the resulting predictive distribution (a Student's t-distribution) naturally 
                        accounts for our uncertainty about the variance itself. This makes the system far more robust: when we have very little data, the model is "cautious" 
                        and requires stronger evidence to flag a point as an anomaly.
                    </p>
                </div>
                
                <p>
                    The Beta prior was conjugate for the Binomial likelihood, and the Normal prior was conjugate for the Normal likelihood with 
                    known variance. Is there a unifying structure that explains <em>why</em> these conjugacies exist? In 
                    <a href="expfamily.html"><strong>Part 15: The Exponential Family</strong></a>, we show that all these distributions belong to a 
                    single parametric family - the exponential family - whose canonical form guarantees the existence of 
                    conjugate priors and reduces MLE to moment matching.
                </p>

                
            </section>
        </div>
        <script src="/js/main.js"></script>
    </body>
</html>