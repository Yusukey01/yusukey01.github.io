<!DOCTYPE html>
<html>
    <head> 
        <title>Bayesian Statistics 1</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css">
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <h1>Bayesian inference</h1>
        <blockquote>
            The core of statistics is inferring the unknown parameters \(\theta\) given observed data \(\mathcal{D} = \{x_1, x_2, \cdots, x_n\}\), 
            which are random samples drawn from a probability distribution. This process is the inverse of probability theory. There are two main 
            approaches. One is called <strong>frequentist statistics</strong> which many people are familiar with, treats parameters as fixed and data as 
            random. The other is called <strong>Bayesian statistics</strong> which is the foundation for machine learning algorithms.
            <br><br>
            In Bayesian statistics, we assume that prior knowledge about the unknown parameters can be explained by a probability 
            distribution, which is called <strong>prior distribution</strong>, \(p(\theta)\). This means that the unknown parameters \(\theta\) are 
            treated as <strong>random variables</strong>, while the data \(\mathcal{D}\) are considered fixed. This approach is opposite 
            to that of frequentist statistics, where parameters are fixed and data are considered random. 
            <br><br>
            Bayesian inference updates our belief(= prior distribution) by using the observed data and
            expresses our updated belief about the parameters as the <strong>posterior distribution</strong>, \(p(\theta | \mathcal{D})\) 
            using Bayes' rule:
            \[
            \begin{align*}
            p(\theta | \mathcal{D}) &= \frac{p(\theta)p(\mathcal{D}| \theta)}{p(\mathcal{D})} \\\\
                                    &= \frac{p(\theta)p(\mathcal{D}| \theta)}{\int p(\theta ')p(\mathcal{D} | \theta ') \, d\theta '}
            \end{align*}
            \]
            The components are defined as follows:
            <ol>
                <li><strong>Prior distribution</strong> \(p(\theta)\):</li> 
                Represents our belief about the parameters \(\theta\) before observing any data. 
                It encodes prior knowledge, assumptions, or uncertainty about \(\theta\).
                <li><strong>Likelihood</strong> \(p(\mathcal{D}| \theta)\):</li>
                Describes how likely the observed data \(\mathcal{D}\) is, given a specific value of \(\theta\). 
                This reflects the model of the data-generating process.
                <li><strong>Marginal likelihood</strong>(or <strong>evidence</strong>) \(p(\mathcal{D})\): </li>
                A normalization constant, which is important when we evaluate different models, otherwise we can ignore this term because 
                it is just a constant with respect to parameters \(\theta\).
                It is computed by integrating over all possible values of \(\theta\):  
                \[
                p(\mathcal{D}) = \int p(\theta')p(\mathcal{D} | \theta') \, d\theta'.
                \]
                Note: In the integral for the marginal likelihood, we use \(\theta'\) instead of \(\theta\) to clarify that 
                the integration is over the entire parameter space, not a specific parameter. 
            </ol>
            
        </blockquote>

        <h1>Conjugate Prior</h1>
        <blockquote>
            In general, specifying a prior is a bottleneck of the Bayesian inference. Here, we introduce some special case of priors.
            <br><br>
            A prior \(p(\theta) \in \mathcal{F}\) is saied to be <strong>conjugate prior</strong> for a likelihood function \(p(\mathcal{D} | \theta)\) if 
            the posterior is in the same parameterized family as the prior: \(p(\mathcal{D} | \theta) \in \mathcal{F}\). 
            <br><br>
            Through the following example, we introduce basic Bayesian inference ideas and an example of a conjugate prior.
            <div class="proof">
                <span class="proof-title">Example 1: Beta-Binomial Model</span>
                Consider tossing a coin \(N\) times. Let \(\theta \in [0, 1]\) be a chance of getting head. We record the outcomes as 
                \(\mathcal{D} = \{y_n \in \{0, 1\} : n = 1 : N\}\). We assume the data are iid.
                <br><br>
                If we consider a sequence of coin tosses, the <strong>likelihood</strong> can be written as the Bernoulli likelihood model: 
                \[
                p(\mathcal{D} | \theta) = \prod_{n = 1}^N \theta^{y_n}(1 - \theta)^{1-y_n} = \theta^{N_1}(1 - \theta)^{N_0}
                \]
                where \(N_1\) and \(N_0\) are the number of heads and tails respectively. (Sample size: \(N_1 + N_0 = N\))
                <br><br>
                Alternatively, we can consider the Binomial likelihood model: 
                The likelihood has the following form:
                \[
                p(\mathcal{D} | \theta) = \text{Bin } (y | N, \theta) = \begin{pmatrix} N \\ y \end{pmatrix} \theta^y (1 - \theta)^{N - y} \propto  \theta^y (1 - \theta)^{N - y}
                \]
                where \(y\) is the number of heads.
                <br><br>
                Next, we have to specify a <strong>prior</strong>. If we know nothing about the parameter, <strong>uninformative prior</strong> can 
                be used:
                \[
                p(\theta) = \text{Unif }(\theta | 0, 1).
                \]
                However, "in this example", using beta distribution(See <a href="gamma.html">Gamma & Beta distribution </a>), we can represent the prior as follows:
                \[
                \begin{align*}
                p(\theta) = \text{Beta }(\theta | a, b) &= \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\theta^{a-1}(1-\theta)^{b-1} \tag{1} \\\\
                                                        &\propto \theta^{a-1}(1-\theta)^{b-1}
                \end{align*}
                \]
                where \(a, b > 0\) are usually called hyper-parameters.(Our main parameter is \(\theta\).)
                <br>
                Note: If \(a = b = 1\), we get the uniformative prior. 
                <br><br>
                Using Bayes' rule, the <strong>posterior</strong> is proportional to the product of the likelihood and the prior:
                \[
                \begin{align*}
                p(\theta | \mathcal{D}) &\propto [\theta^{y}(1 - \theta)^{N-y}] \cdot [\theta^{a-1}(1-\theta)^{b-1}] \\\\
                                        &\propto \text{Beta }(\theta | a+y, \, b+N-y) \\\\
                                        &= \frac{\Gamma(a+b+N)}{\Gamma(a+y)\Gamma(b+N-y)}\theta^{a+y-1}(1-\theta)^{b+N-y-1}. \tag{2}
                \end{align*}
                \]
                Here, the posterior has the same functional form of as the prior. Thus, the beta distribution is the <strong>conjugate prior</strong> for the 
                binomial distribution. 
                <br><br>
                Once we got the posterior distribution, for example, we can use <strong>posterior mean</strong>, \(\bar{\theta}\) as a point estimate of \(\theta\):
                \[
                \bar{\theta} = \mathbb{E }[\theta | \mathcal{D}] = \frac{a+y}{(a+y) + (b+N-y)} = \frac{a+y}{a+b+N}.
                \]
                Note: 
                By adjusting hyper-parameters \(a\) and \(b\), we can control the influence of the prior on the posterior.
                <br>
                If \(a\) and \(b\) are small, the posterior mean will closely reflect the data: 
                \[
                \bar{\theta} \approx  \frac{y}{N} = \hat{\theta}_{MLE}
                \]
                while if \(a\) and \(b\) are large, the posterior mean will be more influenced by the prior.
                <br><br>
                Often we need to check the <strong>standard error</strong> of our estimate, which is the posterior standard deviation:
                \[
                \begin{align*}
                \text{SE }(\theta) &= \sqrt{\text{Var }[\theta | \mathcal{D}]} \\\\
                                   &= \sqrt{\frac{(a+y)(b+N-y)}{(a+b+N)^2(a+b+N+1)}}
                \end{align*}
                \]
                Here, if \(N \gg a, b\), we can simplify the <strong>posterior variance</strong> as follows:
                \[
                \begin{align*}
                \text{Var }[\theta | \mathcal{D}] &\approx \frac{y(N-y)}{(N)^2 N} \\\\
                                                  &= \frac{y}{N^2} - \frac{y^2}{N^3} \\\\
                                                  &= \frac{\hat{\theta}(1 - \hat{\theta})}{N}
                \end{align*}
                \]
                where \(\hat{\theta} = \frac{y}{N}\) is the MLE.
                <br><br>
                Thus, the standard error is given by 
                \[
                \text{SE }(\theta) \approx \sqrt{\frac{\hat{\theta}(1 - \hat{\theta})}{N}}.
                \]
                <br>
                From (1) and (2), the <strong>marginal likelihood</strong> is given by the ratio of normalization constants(beta functions) 
                for the prior and posterior:
                \[
                p(\mathcal{D}) = \frac{B(a+y,\, b+N-y)}{B(a, b)}.
                \]
                Note: In general, computing the marginal likelihood is too expensive or impossible, but the conjugate prior allows us to get the 
                exact marginal likelihood easily. Otherwise, we have to introduce some approximation methods.
                <br><br>
                Finally, to make predictions for new observations, we use <strong>posterior predictive distribution</strong>:
                \[
                p(x_{new} | \mathcal{D}) = \int p(x_{new} | \theta) p(\theta | \mathcal{D}) d\theta.
                \]
                Again, like computing the marginal likelihood, it is difficult to compute posterior predictive distribution, but in this case, 
                we can get it easily due to the conjugate prior. 
                <br>
                For example, the probability of observing a head in the next coin toss is given by:
                \[
                \begin{align*}
                p(y_{new}=1 | \mathcal{D}) &= \int_0 ^1  p(y_{new}=1 | \theta) p(\theta | \mathcal{D}) d\theta \\\\
                                           &= \int_0 ^1 \theta \text{Beta }(\theta | a+y, \, b+N-y) d\theta \\\\
                                           &= \mathbb{E }[\theta|\mathcal{D}] \\\\
                                           &= \frac{a+y}{a+b+N}.
                \end{align*}
                \]
                Note: As you can see, the hyper-parameters \(a\) and \(b\) is critical in the whole process of our inference. In practice, setting up 
                hyper-parameters is one of the most challenging factor of the project. 
            </div>
        </blockquote>

        <h1>Univariate Normal Distribution Model</h1>
        <blockquote>
            Given the univariate normal distribution \(N(\mu, \sigma^2)\), there are three cases for our target posterior: 
            <ol>
                <li>\(p(\mu | \mathcal{D}, \sigma^2) \): Variance \(\sigma^2\) is known.</li>
                <li>\(p(\sigma^2 | \mathcal{D}, \mu) \): Mean \(\mu\) is known.</li>
                <li>\(p(\mu, \sigma^2 | \mathcal{D})\): Both \(\sigma^2\) and \(\mu\) are unknown.</li>
            </ol>
            Here, we only discuss the first case.
            <div class="proof">
                <span class="proof-title">Example 2: Normal distribution model with known \(\sigma^2\)</span>
                The likelihood for \(\mu\) is given by 
                \[
                \begin{align*}
                p(\mathcal{D}| \mu) &= \prod_{n=1}^N \frac{1}{\sqrt{2\pi \sigma^2}} \exp \Big(-\frac{(y_n - \mu)^2}{2\sigma^2}\Big)\\\\
                                    &\propto \exp \Big(-\frac{1}{2\sigma^2} \sum_{n=1}^N (y_n - \mu)^2 \Big).
                \end{align*}
                \]
                The conjugate prior is another normal distribution:
                \[
                \begin{align*}
                p(\mu) &= N(\mu | \, \mu_0, \sigma_0^2) \\\\
                       &\propto \exp \Big(-\frac{(\mu - \mu_0)^2}{2\sigma_0^2} \Big).
                \end{align*}
                \]
                <br>
                The posterior is given by:
                \[
                \begin{align*}
                p(\mu | \, \mathcal{D}, \sigma^2) &\propto \exp \Big(-\frac{1}{2\sigma^2} \sum_{n=1}^N (y_n - \mu)^2 \Big) \cdot \exp \Big(-\frac{(\mu - \mu_0)^2}{2\sigma_0^2}  \Big) \\\\
                                                  &= \exp \Big\{-\frac{1}{2}\Big(\frac{N}{\sigma^2}+\frac{1}{\sigma_0^2} \Big)\mu^2 +\Big(\frac{\sum y_n}{\sigma^2} +\frac{\mu_0}{\sigma_0^2} \Big)\mu 
                                                                + \Big(-\frac{1}{2\sigma^2} \sum_{n=1}^N y_n^2 - \frac{\mu_0^2}{2\sigma_0^2} \Big) \Big\}
                \end{align*}
                \]
                Since \(-\frac{1}{2\sigma^2} \sum_{n=1}^N y_n^2 - \frac{\mu_0^2}{2\sigma_0^2}\) are constant with respect to \(\mu\), we ignore these terms.
                <br>
                Let \(A = \Big(\frac{N}{\sigma^2}+\frac{1}{\sigma_0^2} \Big)\) and \(B =\Big(\frac{\sum y_n}{\sigma^2} +\frac{\mu_0}{\sigma_0^2} \Big)\), and completing the square, we get:
                \[
                \begin{align*}
                p(\mu | \, \mathcal{D}, \sigma^2) &\propto \exp \Big\{-\frac{1}{2}A\mu^2 + B\mu \Big\} \\\\
                                                  &= \exp \Big\{-\frac{1}{2}A \Big(\mu - \frac{B}{A} \Big)^2 + \frac{B^2}{2A}\Big\}.                     
                \end{align*}
                \]
                Here, since the term \(\frac{B^2}{2A}\) does not depend on \(\mu\), and \(-\frac{1}{2}A \Big(\mu - \frac{B}{A} \Big)^2\) is a quadratic form of an univariate normal distributuin, we conclude that
                \[
                \begin{align*}
                p(\mu | \, \mathcal{D}, \sigma^2)  = N(\mu | \, \mu_N, \sigma_N^2 )
                \end{align*}
                \]
                where
                \[
                \begin{align*}
                \sigma_N^2 &= \frac{1}{A} \\\\
                           &= \frac{\sigma^2 \sigma_0^2}{N\sigma_0^2 + \sigma^2}
                \end{align*}
                \]
                and
                \[
                \begin{align*}
                \mu_N &= \frac{B}{A} \\\\
                      &= \sigma_N^2 \Big(\frac{\mu_0}{\sigma_0^2} + \frac{N \bar{y}}{\sigma^2} \Big) \\\\
                      &= \frac{\sigma^2}{N\sigma_0^2 + \sigma^2}\mu_0 + \frac{N\sigma^2}{N\sigma^2 + \sigma^2}\bar{y} \\\\
                \end{align*}
                \]
                where \(\bar{y} = \frac{1}{N}\sum_{n=1}^N y_n\) is the empirical mean. 
            </div>
        </blockquote>

        <br><a href="../../index.html">Back to Home </a>
        <br> <a href="probability.html">Back to Probability </a>   
    </body>
</html>