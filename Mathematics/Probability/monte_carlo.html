---
layout: default
title: Monte Carlo Approximation
level: detail
description: Intro to Monte Carlo approximation in the context of Bayesian statistics.
uses_math: true
uses_python: false
---

<!DOCTYPE html>
<html>
    <body>
        <div class="hero-section">
            <h1 class="webpage-name">Monte Carlo Approximation
            </h1>
        </div>

        <div class="topic-nav">
            <a href="#CI">Credible Intervals</a></li>
            <a href="#MC">Monte Carlo Approximation</a></li>
            <a href="#demo">Monte Carlo Approximation Demo</a>
            <a href="#"></a>
            <a href="#"></a>
        </div> 

        <div class="container">  
            <section id="CI" class="section-content">
                <h2>Credible Intervals</h2>
                <p>
                    In practice, a probability distribution is often a high-dimensional object, making it difficult to fully capture its characteristics. 
                    In Bayesian statistics, we frequently summarize the uncertainty of a posterior distribution using a <strong>credible interval</strong>. 
                    A credible interval is not the same as a confidence interval in frequentist statistics, even though they may sometimes numerically coincide.
                </p>
                <p>
                    Formally, for a given significance level \(\alpha \in (0,1)\), a \(100(1-\alpha)\%\) <strong>credible interval</strong> is defined as:
                    \[
                    C_{\alpha}(\mathcal{D}) = (l, u) \quad \text{such that} \quad P(l \leq \theta \leq u \mid \mathcal{D}) = 1 - \alpha,
                    \]
                    where \(l\) and \(u\) denote the lower and upper bounds, respectively. Here, \(\mathcal{D}\) represents the observed data, and the probability is computed under the posterior distribution \(p(\theta \mid \mathcal{D})\).
                </p>
                <p>
                    This interval contains \(1-\alpha\) of the posterior probability mass. A common choice is the <strong>central credible interval</strong>, where \(\frac{1-\alpha}{2}\) of the posterior probability lies in each tail. 
                </p>
                <p>
                    If the cumulative distribution function (cdf) \(F\) of the posterior distribution is known, the central credible interval can be computed as:
                    \[
                    \begin{align*}
                    l &= F^{-1}\left( \frac{\alpha}{2} \right), \\\\
                    u &= F^{-1}\left( 1 - \frac{\alpha}{2} \right),
                    \end{align*}
                    \]
                    where \(F^{-1}\) denotes the quantile function (the inverse of the cdf).
                </p>
                <p>
                    As an example, if the posterior distribution is approximately normal with posterior mean \(\mu\) and posterior standard deviation \(\sigma\), 
                    a rough \(95\%\) credible interval can be set as:
                    \[
                    (l, u) = (\mu - 2\sigma, \mu + 2\sigma),
                    \]
                    because for a standard normal distribution \(\mathcal{N}(0,1)\), approximately \(95\%\) of the probability mass lies within two standard deviations from the mean.
                </p>
                <p>
                    More precisely, when \(p(\theta \mid \mathcal{D}) = \mathcal{N}(\mu, \sigma^2)\) and \(\alpha = 0.05\), the central credible interval endpoints are:
                    \[
                    \begin{align*}
                    l &= \mu + \sigma \Phi^{-1}\left( \frac{\alpha}{2} \right), \\\\
                    u &= \mu + \sigma \Phi^{-1}\left( 1 - \frac{\alpha}{2} \right),
                    \end{align*}
                    \]
                    where \(\Phi\) is the cumulative distribution function (cdf) of the standard normal distribution.
                </p>
                <p>
                    In particular, if the posterior distribution is the standard normal \(p(\theta \mid \mathcal{D}) = \mathcal{N}(0,1)\), then:
                    \[
                    \begin{align*}
                    l &= \Phi^{-1}(0.025) \approx -1.96, \\\\
                    u &= \Phi^{-1}(0.975) \approx 1.96,
                    \end{align*}
                    \]
                    so the \(95\%\) credible interval is approximately \((-1.96, 1.96)\).
                </p>
            </section>

            <section id="MC" class="section-content">
                <h2>Monte Carlo Approximation</h2>
                <p> 
                    In general, it is often difficult to compute the inverse cdf of the posterior distribution exactly. 
                    In such cases, a simple and practical alternative is to use a <strong>Monte Carlo approximation</strong> 
                    based on samples drawn from the posterior. 
                </p> 
                <p> 
                    Suppose we can generate samples \(\theta^{(1)}, \theta^{(2)}, \dots, \theta^{(S)}\) independently from the posterior \(p(\theta \mid \mathcal{D})\).
                    Then, to approximate a \((1-\alpha)\)% credible interval:
                </p> 
                <ul style="padding-left: 40px;"> 
                    <li>Sort the samples in increasing order: \(\theta^{(1)} \leq \theta^{(2)} \leq \cdots \leq \theta^{(S)}\).</li> 
                    <li>Set the lower endpoint \(l\) to be the \(\left(\frac{\alpha}{2}\right)\)-quantile, and the upper endpoint \(u\) to be the \(\left(1 - \frac{\alpha}{2}\right)\)-quantile.</li> 
                </ul> 
                <p> 
                    More precisely, approximate:
                    \[
                    \begin{align*}
                    l &\approx \theta^{\left(\left\lceil S \times \frac{\alpha}{2} \right\rceil\right)}, \\\\
                    u &\approx \theta^{\left(\left\lceil S \times \left(1 - \frac{\alpha}{2}\right) \right\rceil\right)},
                    \end{align*}
                    \]
                    where \(\lceil \cdot \rceil\) denotes the ceiling function, rounding up to the nearest integer if necessary.
                </p> 
                <p> 
                    Intuitively, instead of computing the inverse cdf analytically, we use the <strong>empirical cumulative distribution function (ecdf)</strong> 
                    formed by the sorted samples to estimate the desired quantiles. 
                    As the number of samples \(S \to \infty\), the empirical quantiles converge to the true quantiles of the posterior by the law of large numbers.
                </p>
                <p>
                    This Monte Carlo method is especially powerful when the posterior distribution is complex or high-dimensional, and no closed-form expression 
                    for the cdf or its inverse is available.
                </p>

            </section>

            <section id="demo" class="section-content">
              
                <h2>Monte Carlo Approximation Demo</h2>
                <div id="random_variable_transformation_visualizer"></div>
                     <p>
                     Monte Carlo approximation estimates credible intervals by using samples drawn from the posterior distribution. 
                     For a central credible interval, the steps are:
                     </p>
                     <ol style="padding-left: 40px;">
                       <li>Draw many random samples from the posterior distribution</li>
                       <li>Sort the samples in ascending order</li>
                       <li>Use quantiles to estimate the interval (e.g., the 2.5% and 97.5% quantiles for a 95% interval)</li>
                     </ol>
                     <br>
                     <p>
                     As the number of samples increases, the approximation of the <strong>overall posterior distribution</strong> becomes 
                     more accurate. However, credible intervals based on quantiles may still be misleading—especially in multimodal or skewed 
                     distributions—because they may fall in low-probability regions or exclude important modes.
                     </p>

                     <p>
                     Monte Carlo methods are widely used to approximate posterior distributions when closed-form solutions are unavailable. 
                     They work by drawing samples from the distribution and using those samples to estimate quantities of interest, including 
                     credible intervals.
                     </p>
                     <p>
                     However, in complex cases like <strong>bimodal distributions</strong> (a mixture of two distinct peaks), using empirical 
                     quantiles to compute credible intervals can be problematic. The resulting interval might:
                     </p>
                     <ul style="padding-left: 40px;">
                       <li>Fall in a low-density region between the modes</li>
                       <li>Exclude one of the peaks entirely</li>
                       <li>Misrepresent the uncertainty or shape of the distribution</li>
                     </ul>
                     <br>
                     <p>
                     While Monte Carlo sampling still helps approximate the overall shape of the distribution, <strong>quantile-based credible 
                     intervals can be misleading in multimodal settings</strong>. Alternative approaches like <strong>higher posterior density (HPD)</strong> 
                     intervals, visual inspection, or more advanced sampling techniques may be needed to better capture the distribution's structure.
                     </p>
            </section>

            <section id="" class="section-content">
                <h2></h2>
                <p>
                </p>
            </section>
        </div>

        <script src="/js/main.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/jstat@latest/dist/jstat.min.js"></script>
        <script src="/js/random_variable_transformation_visualizer.js"></script> 

    </body>
</html>