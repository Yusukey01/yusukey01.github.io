---
layout: default
title: Convergence
topic_id: prob-13
level: detail
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body>
        {% include learning_resource_schema.html topic_id=page.topic_id %}

        <div class="hero-section">
            <h1 class="webpage-name">Convergence
            </h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#LLA">Modes of Convergence & The Law of Large Numbers</a>
            <a href="#prob">Convergence in Probability</a>
            <a href="#dist">Convergence in distribution</a>
            <a href="#mgf">Moment Generating Function(mgf)</a>
        </div> 

        <div class="container">  

            <section id="LLA" class="section-content">
                <h2>Modes of Convergence & The Law of Large Numbers</h2>
                <p> 
                    In computer science and practical engineering, we often accept the convergence of probabilities based on experimental 
                    results or large-scale simulations. However, to build mathematically rigorous systems and gain a deeper understanding 
                    of statistics, we must clarify exactly <em>how</em> a sequence of random variables approaches its limit.
                </p>
                <p>
                    There are several ways to define convergence in a statistical context. Here, we introduce three fundamental modes, ordered 
                    from strongest to weakest, and relate them to the <strong>Law of Large Numbers (LLN)</strong>.
                </p>

                <div class="theorem">
                    <span class="theorem-title">1. Almost Sure Convergence (\( \xrightarrow{a.s.} \))</span>
                    <p>
                        This is the strongest form of convergence. We say \(X_n\) converges to \(X\) <strong>almost surely</strong> 
                        if the event where they do <em>not</em> converge has probability zero:
                        \[
                        P\left( \lim_{n \to \infty} X_n = X \right) = 1.
                        \]
                        <strong>Context:</strong> This is the foundation of the <strong>Strong Law of Large Numbers (SLLN)</strong>. 
                        Mathematically, this is the probabilistic analogue of pointwise convergence <a href="../Calculus/lebesgue.html#c_f"><strong>"almost everywhere" (a.e.) in measure theory</strong></a>. 
                        It asserts that while "pathological" non-convergent sequences exist in the sample space, their total measure (probability) is exactly zero:
                        \[ 
                        \bar{X}_n \xrightarrow{a.s.} \mu.
                        \]
                    </p>
                </div>

                <div class="theorem">
                    <span class="theorem-title">2. Convergence in Probability (\( \xrightarrow{P} \))</span>
                    <p>
                        We say \(X_n\) converges to \(X\) <strong>in probability</strong> if, for any tiny error margin \(\epsilon > 0\), the probability 
                        of the difference exceeding \(\epsilon\) goes to zero:
                        \[
                        \lim_{n \to \infty} P(|X_n - X| \geq \epsilon) = 0.
                        \]
                        <strong>Context:</strong> This corresponds to the <strong>Weak Law of Large Numbers (WLLN)</strong>. 
                        It implies that for large \(n\), the sample mean is unlikely to be far from \(\mu\). Unlike SLLN, WLLN 
                        requires weaker conditions (e.g., finite variance via Chebyshev's inequality) but does not guarantee the 
                        stability of individual sample paths.
                    </p>
                </div>

                <div class="theorem">
                    <span class="theorem-title">3. Convergence in Distribution (\( \xrightarrow{D} \))</span>
                    <p>
                        This is the weakest form, focusing only on the cumulative distribution functions (CDFs). We say \(X_n\) converges to \(X\) <strong>in distribution</strong> if:
                        \[
                        \lim_{n \to \infty} F_n(x) = F(x)
                        \]
                        for all points \(x\) where \(F\) is continuous.
                        <br><br>
                        <strong>Context:</strong> This is the basis of the <strong>Central Limit Theorem (CLT)</strong>. Unlike LLN, which says the mean converges to a <em>constant</em>, CLT describes how the standardized <em>fluctuations</em> around that constant converge to a <strong>Normal Distribution</strong>.
                    </p>
                </div>

                <div class="insight-box">
                    <h3>Hierarchical Relationship</h3>
                    <p>
                        These modes of convergence satisfy the following logical implications:
                        \[
                        (X_n \xrightarrow{a.s.} X) \implies (X_n \xrightarrow{P} X) \implies (X_n \xrightarrow{D} X)
                        \]
                        Note: The reverse is not generally true. However, if \(X\) is a constant (like the mean \(\mu\) in LLN), 
                        then convergence in distribution implies convergence in probability.
                    </p>
                </div>

                <p>
                    Now that we have established the theoretical landscape of convergence, let's focus on <strong>Convergence in Distribution</strong>. 
                    After developing the formal definitions and key theorems in the following sections, we provide a rigorous proof of the Central Limit 
                    Theorem using Moment Generating Functions.
                </p>
            </section>
           
            <section id="prob" class="section-content">
                <h2>Convergence in Probability</h2>
                <p> 
                    Convergence in probability captures the idea that \(X_n\) becomes increasingly unlikely to deviate 
                    from \(X\) by any fixed amount. Unlike almost sure convergence, it does not require individual 
                    sample paths to converge — only that "large deviations" become rare events.
                </p>
                
                <p>
                    Let \(\{X_n\}\) be a sequence of random variables and \(X\) be a random variable defined on a sample space. 
                    \(X_n\) <strong>converges in probability</strong> to \(X\), denoted by
                    \[
                    X_n \xrightarrow{P} X,
                    \]
                    if \(\quad \forall \epsilon > 0\), 
                    \[
                    \lim_{n \to \infty} P [| X_n - X | \geq \epsilon ] = 0 
                    \]
                    or equivalently,
                    \[
                    \lim_{n \to \infty} P [| X_n - X | < \epsilon ] = 1.
                    \]
                </p>

                <p>
                    A natural question arises: if \(X_n \xrightarrow{P} X\), what happens when we apply a function to \(X_n\)? 
                    The following theorem, known as the <strong>Continuous Mapping Theorem</strong>, answers this question.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Continuous Mapping Theorem</span>
                    Suppose \(X_n \xrightarrow{P} a\) where \(a\) is a constant, and the function \(f\) is continuous at \(a\). Then 
                    \[
                    f(X_n) \xrightarrow{P} f(a).
                    \]
                </div>

                <div class="proof">
                    <span class="proof-title">Proof:</span>
                    Let \(\epsilon > 0\). Since \(f\) is continuous at \(a\), \(\, \exists \delta > 0 \) such that 
                    \[
                    |x - a | < \delta \Longrightarrow |f(x) - f(a)| < \epsilon. 
                    \]
                    Taking the contrapositive, 
                    \[
                    |f(x) - f(a)| \geq \epsilon \Longrightarrow  |x - a | \geq \delta.
                    \]
                    Substituting \(X_n\) for \(x\), we obtain 
                    \[
                    P[|f(X_n) - f(a)| \geq \epsilon] \leq P [| X_n - a| \geq \delta ].
                    \]
                    As \(n \to \infty\), the right-hand side vanishes by assumption, hence \(f(X_n) \xrightarrow{P} f(a)\).
                </div>

                <p>
                    More generally, if \(X_n \xrightarrow{P} X\) (where \(X\) is a random variable, not necessarily constant) 
                    and \(f\) is continuous, then 
                    \[
                    f(X_n) \xrightarrow{P} f(X).
                    \]
                    The proof follows similar logic but requires a more careful measure-theoretic argument.
                </p>

                <p>
                    <strong>Why this matters:</strong> The Continuous Mapping Theorem allows us to transfer convergence results 
                    through transformations. For instance, if sample means converge in probability to \(\mu\), then 
                    \(\bar{X}_n^2 \xrightarrow{P} \mu^2\) and \(e^{\bar{X}_n} \xrightarrow{P} e^\mu\). This is essential 
                    for deriving the asymptotic behavior of estimators and test statistics.
                </p>
            </section>

            <section id="dist" class="section-content">
                <h2>Convergence in distribution</h2>
                 <p> 
                    Unlike convergence in probability, which tracks how the random variables themselves behave, 
                    <strong>convergence in distribution</strong> focuses solely on the cumulative distribution functions (CDFs). 
                    Two sequences of random variables can converge to the same limiting distribution even if they are defined 
                    on entirely different probability spaces.
                </p>

                <p>
                    Let \(\{X_n\}\) be a sequence of random variables and let \(X\) be a random variable. Let \(F_{X_n}\) and 
                    \(F_X\) be the CDFs of \(X_n\) and \(X\) respectively. 
                    <br>
                    Let \(C(F_X)\) denote the set of all points where \(F_X\) is continuous. 
                    <br>
                    \(X_n\) <strong>converges in distribution</strong> to \(X\), denoted by 
                    \[
                    X_n \xrightarrow{D} X,
                    \]
                    if \(\quad \forall x \in C(F_{X})\), 
                    \[
                    \lim_{n \to \infty} F_{X_n} (x) = F_X (x).
                    \]
                    Often the distribution of \(X\) is called the <strong>asymptotic (limiting) distribution</strong> of the sequence \(\{X_n\}\).
                </p>
                <p>
                    <strong>Key distinction:</strong> Convergence in distribution does not imply convergence in probability. 
                    For example, let \(X \sim N(0,1)\) and define \(X_n = -X\) for all \(n\). Then \(X_n \xrightarrow{D} X\) 
                    (since both have the same standard normal distribution), yet \(|X_n - X| = 2|X|\) does not converge to zero 
                    in probability.
                </p>
                <p>
                    However, the reverse implication does hold:
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem:</span>
                    If \(X_n\) converges to \(X\) in probability, then \(X_n\) converges to \(X\) in distribution. 
                </div>

                <p>
                    <strong>Intuition:</strong> If \(X_n\) is increasingly likely to be close to \(X\) (convergence in probability), 
                    then the probability mass of \(X_n\) must accumulate where \(X\) places its mass, forcing the CDFs to align.
                </p>

                <div class="proof">
                    <span class="proof-title">Proof:</span>
                    Suppose \(X_n \xrightarrow{P} X\), and let \(x\) be a point of continuity of \(F_{x_n}\).  
                    <br>
                    \(\forall \, \epsilon > 0\),
                    \[
                    \begin{align*}
                    F_{X_n}(x) &= P[X_n \leq x] \\\\
                            &= P[\{X_n \leq x\} \cap \{|X_n - X| < \epsilon\}] + P [\{X_n \leq x\} \cap \{|X_n - X| \geq \epsilon\}] \\\\
                            &\leq P[X \leq x + \epsilon] + P[|X_n - X| \geq \epsilon]
                    \end{align*}
                    \]
                    Since \(X_n \xrightarrow{P} X\), we know  \(P[|X_n - X| \geq \epsilon] \to 0\). Then we get a upper bound 
                    \[
                    \lim_{n \to \infty} \sup F_{X_n}(x) \leq F_{X}(x + \epsilon) \tag{1}.
                    \]
                    Similarly, we can get a lower bound:
                    \[
                    P[X_n  > x ] \leq P[X \geq x - \epsilon] + P[|X_n - X| \geq \epsilon]
                    \]
                    \[
                    \Longrightarrow  \lim_{n \to \infty} \inf F_{X_n}(x) \geq F_X (x - \epsilon) \tag{2}.
                    \]
                    Combining (1) and (2), we obtain 
                    \[
                    F_X(x - \epsilon) \leq \lim_{n \to \infty} \inf F_{X_n}(x) \leq \lim_{n \to \infty} \sup F_{X_n}(x) \leq F_X (x + \epsilon).
                    \]
                    Here, as \(\epsilon \to 0\), we have
                    \[
                    \lim_{n \to \infty} F_{X_n}(x) = F_X (x)
                    \]
                    because \(x\) is a point of continuity of \(F_{x_n}\). 
                    <br>
                    Therefore
                    \[
                    X_n \xrightarrow{D} X.
                    \]
                </div>
                Now, we can see that the <strong>central limit theorem(CLT)</strong> is a statement about convergence in distribution. 
                (See <a href="gaussian.html#clt"><strong>Here</strong></a>.)
                </p>
            </section>

            <section id="mgf" class="section-content">
                <h2>Moment Generating Function (MGF)</h2>
                <p>
                    To prove convergence in distribution, we need a tool that characterizes distributions and behaves 
                    well under limits. The <strong>moment generating function (MGF)</strong> provides exactly this: 
                    it uniquely determines a distribution (when it exists) and converts the problem of distributional 
                    convergence into the simpler problem of pointwise convergence of functions.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definiton: Moment Generating Function (MGF)</span>
                    <p>
                        Let \(X\) be a random variable such that for some \(h > 0\), the expectation of \(e^{tX}\) exists 
                        for \(t \in (-h, h)\). The <strong>moment generating function</strong> of \(X\) is defined by
                        \[
                        M(t) = \mathbb{E}(e^{tX}), \qquad t \in (-h, h).
                        \]
                    </p>
                </div>

                <p>
                    <strong>Why "moment generating"?:</strong> Expanding \(e^{tX}\) as a power series and taking expectations term-by-term:
                    \[
                    M(t) = \mathbb{E}\left[\sum_{k=0}^{\infty} \frac{(tX)^k}{k!}\right] = \sum_{k=0}^{\infty} \frac{t^k}{k!} \mathbb{E}(X^k).
                    \]
                    Thus, the \(k\)-th derivative at zero gives the <strong>\(k\)-th moment</strong>: 
                    \[
                    M^{(k)}(0) = \mathbb{E}(X^k).
                    \]
                </p>

                <p>
                    <strong>Why require an open interval around 0?</strong> The MGF must exist in a neighborhood of zero 
                    (not just at \(t = 0\)) to guarantee that it uniquely determines the distribution and that we can 
                    differentiate to extract moments. If the MGF exists only at \(t = 0\), it provides no useful information.
                </p>

                <p>
                    The key theorem connecting MGFs to convergence in distribution is:
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Lévy's Continuity Theorem — MGF Version</span>
                    Let \(\{X_n\}\) be a sequence of random variables with MGFs \(M_n(t)\) that exist for \(t \in (-h, h)\). 
                    If \(M_n(t) \to M(t)\) for all \(t\) in some <strong>open interval</strong> containing 0, and \(M(t)\) is the MGF of 
                    a random variable \(X\), then
                    \[
                    X_n \xrightarrow{D} X.
                    \]
                </div>

                <p>
                    This theorem transforms the problem: instead of comparing CDFs pointwise, we show MGFs converge. 
                    We now apply this strategy to prove the Central Limit Theorem.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Central Limit Theorem (CLT)</span>
                    Let \(X_1, X_2, \ldots, X_n\) be i.i.d. random variables with mean \(\mu\) and variance \(\sigma^2 > 0\). 
                    Assume the MGF \(M(t) = \mathbb{E}(e^{tX})\) exists in a neighborhood of zero. Then the standardized sum
                    \[
                    Y_n = \frac{\sum_{i=1}^{n} X_i - n\mu}{\sigma \sqrt{n}} = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma}
                    \]
                    converges in distribution to a standard normal:
                    \[
                    Y_n \xrightarrow{D} N(0, 1).
                    \]
                </div>

                <div class="proof">
                    <span class="proof-title">Proof:</span>
                    <p>
                        <strong>Step 1: MGF of centered variable.</strong><br>
                        Define \(W = X - \mu\). The MGF of \(W\) is:
                        \[
                        m(t) = \mathbb{E}[e^{t(X-\mu)}] = e^{-\mu t} M(t), \qquad t \in (-h, h).
                        \]
                        Note the key properties:
                        \[
                        m(0) = 1, \quad m'(0) = \mathbb{E}(X - \mu) = 0, \quad m''(0) = \mathbb{E}[(X-\mu)^2] = \sigma^2.
                        \]
                    </p>
                    <p>
                        <strong>Step 2: Taylor expansion.</strong><br>
                        By Taylor's theorem with Lagrange remainder, for any \(t\) in the domain, there exists \(\xi\) between \(0\) and \(t\) such that:
                        \[
                        m(t) = m(0) + m'(0)t + \frac{m''(\xi)}{2}t^2 = 1 + \frac{m''(\xi)}{2}t^2.
                        \]
                        We rewrite this as:
                        \[
                        m(t) = 1 + \frac{\sigma^2 t^2}{2} + \frac{[m''(\xi) - \sigma^2]t^2}{2}. \tag{3}
                        \]
                    </p>
                    <p>
                        <strong>Step 3: MGF of the standardized sum.</strong><br>
                        By independence:
                        \[
                        M_n(t) = \mathbb{E}\left[\exp\left(t \cdot \frac{\sum_{i=1}^{n}(X_i - \mu)}{\sigma\sqrt{n}}\right)\right] 
                        = \left[m\left(\frac{t}{\sigma\sqrt{n}}\right)\right]^n.
                        \]
                    </p>
                    <p>
                        <strong>Step 4: Substitute and take limit.</strong><br>
                        Replacing \(t\) with \(\frac{t}{\sigma\sqrt{n}}\) in equation (3):
                        \[
                        m\left(\frac{t}{\sigma\sqrt{n}}\right) = 1 + \frac{t^2}{2n} + \frac{[m''(\xi_n) - \sigma^2]t^2}{2n\sigma^2}
                        \]
                        where \(\xi_n \in \left(0, \frac{t}{\sigma\sqrt{n}}\right)\). Thus:
                        \[
                        M_n(t) = \left\{1 + \frac{t^2}{2n} + \frac{[m''(\xi_n) - \sigma^2]t^2}{2n\sigma^2}\right\}^n.
                        \]
                        As \(n \to \infty\), we have \(\xi_n \to 0\), and by continuity of \(m''(t)\) at \(t = 0\):
                        \[
                        m''(\xi_n) \to m''(0) = \sigma^2 \implies m''(\xi_n) - \sigma^2 \to 0.
                        \]
                        Using the fundamental limit \(\lim_{n \to \infty}\left(1 + \frac{x}{n}\right)^n = e^x\) with \(x = \frac{t^2}{2}\):
                        \[
                        \lim_{n \to \infty} M_n(t) = e^{t^2/2}.
                        \]
                    </p>
                    <p>
                        <strong>Step 5: Identify the limit.</strong><br>
                        The function \(e^{t^2/2}\) is the MGF of \(N(0,1)\). By Lévy's Continuity Theorem:
                        \[
                        Y_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0,1).
                        \]
                    </p>
                </div>

                <div class="insight-box">
                    <h3>Deriving the MGF of \(N(0,1)\)</h3>
                    <p>
                        We verify that \(e^{t^2/2}\) is indeed the MGF of the standard normal:
                        \[
                        \begin{align*}
                        M(t) &= \int_{-\infty}^{\infty} e^{tx} \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \, dx \\\\
                             &= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-(x^2 - 2tx)/2} \, dx \\\\
                             &= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-[(x-t)^2 - t^2]/2} \, dx \\\\
                             &= e^{t^2/2} \underbrace{\int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{-(x-t)^2/2} \, dx}_{= 1}  \\\\
                             &= e^{t^2/2}.
                        \end{align*}
                        \]
                    </p>
                </div>

                <p>
                    <strong>Remark:</strong> Without standardization, the CLT can be written as:
                    \[
                    \sqrt{n}(\bar{X}_n - \mu) \xrightarrow{D} N(0, \sigma^2).
                    \]
                </p>
            </section>
        </div>
        <script src="/js/main.js"></script>    
    </body>
</html>