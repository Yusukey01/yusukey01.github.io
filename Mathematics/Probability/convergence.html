---
layout: default
title: Convergence
topic_id: prob-13
level: detail
uses_math: true
uses_python: false
---
<!DOCTYPE html>
<html>
    <body>
        {% include learning_resource_schema.html topic_id=page.topic_id %}

        <div class="hero-section">
            <h1 class="webpage-name">Convergence</h1>
        </div>

        {% include section_navigation.html %}

        <div class="topic-nav">
            <a href="#LLA">Modes of Convergence & The Law of Large Numbers</a>
            <a href="#prob">Convergence in Probability</a>
            <a href="#dist">Convergence in Distribution</a>
            <a href="#mgf">Moment Generating Function (MGF)</a>
        </div> 

        <div class="container">  

            <section id="LLA" class="section-content">
                <h2>Modes of Convergence & The Law of Large Numbers</h2>

                <p> 
                    We usually accept the convergence of probabilities based on experimental results or large-scale simulations.
                    In <a href="mle.html"><strong>Part 9</strong></a> and <a href="hypothesis_testing.html"><strong>Part 10</strong></a>, 
                    we relied on the idea that sample statistics approximate population parameters as the sample size grows. 
                    But what exactly does "approximate" mean for random variables? Unlike deterministic sequences, 
                    a sequence of random variables can approach a limit in several distinct senses, each with different mathematical 
                    strength and practical implications.
                </p>

                <p>
                    We introduce three fundamental modes of convergence, ordered from strongest to weakest, and connect each to a classical 
                    result in probability theory.
                </p>

                <div class="theorem">
                    <span class="theorem-title">1. Almost Sure Convergence (\(\xrightarrow{a.s.}\))</span>
                    <p>
                        A sequence \(\{X_n\}\) converges to \(X\) <strong>almost surely</strong> 
                        if the event where they do <em>not</em> converge has probability zero:
                        \[
                        P\left( \lim_{n \to \infty} X_n = X \right) = 1.
                        \]
                    </p>
                </div>

                <p>
                    This is the strongest form of convergence. It is the probabilistic analogue of pointwise convergence 
                    <a href="../Calculus/lebesgue.html#c_f"><strong>"almost everywhere" (a.e.) in measure theory</strong></a>: 
                    the set of outcomes \(\omega\) for which \(X_n(\omega) \not\to X(\omega)\) exists as a subset of the sample space, but 
                    has probability zero. Almost sure convergence underpins the following fundamental result.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Strong Law of Large Numbers (SLLN)</span>
                    <p>
                        Let \(X_1, X_2, \ldots\) be i.i.d. random variables with 
                        \(\mathbb{E}[|X_1|] < \infty\) and \(\mathbb{E}[X_1] = \mu\). Then
                        \[
                        \bar{X}_n = \frac{1}{n}\sum_{i=1}^{n} X_i \xrightarrow{a.s.} \mu.
                        \]
                    </p>
                </div>

                <p>
                    The SLLN guarantees that individual sample paths of \(\bar{X}_n\) converge to \(\mu\), except possibly on a set of probability zero. A weaker notion relaxes 
                    this path-level guarantee.
                </p>

                <div class="theorem">
                    <span class="theorem-title">2. Convergence in Probability (\( \xrightarrow{P} \))</span>
                    <p>
                        We say \(X_n\) converges to \(X\) <strong>in probability</strong> if, for every \(\epsilon > 0\), the probability 
                        of the difference exceeding \(\epsilon\) goes to zero:
                        \[
                        \lim_{n \to \infty} P(|X_n - X| \geq \epsilon) = 0.
                        \]
                    </p>
                </div>

                <p>
                    Convergence in probability says that large deviations from \(X\) become increasingly unlikely, but it does not demand that each 
                    individual sample path settles down. This mode of convergence corresponds to the Weak Law.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Weak Law of Large Numbers (WLLN)</span>
                    <p>
                        Let \(X_1, X_2, \ldots\) be i.i.d. random variables with 
                        \(\mathbb{E}[X_1] = \mu\) and \(\text{Var}(X_1) = \sigma^2 < \infty\). Then
                        \[
                        \bar{X}_n \xrightarrow{P} \mu.
                        \]
                    </p>
                </div>

                <p>
                    The WLLN is often proved using <strong>Chebyshev's inequality</strong>, which requires the assumption of a 
                    finite variance (\(\sigma^2 < \infty\)). Since \(\text{Var}(\bar{X}_n) = \sigma^2/n\), we have 
                    \[
                    P(|\bar{X}_n - \mu| \geq \epsilon) \leq \frac{\sigma^2}{n\epsilon^2} \to 0.
                    \]
                    Note: While Chebyshev's proof requires finite variance, Khinchin's theorem shows that the WLLN actually holds 
                    under the same condition as the SLLN — only a finite mean (\(\mathbb{E}[|X_1|] < \infty\)) is needed.
                </p>

                <p>
                    The weakest mode concerns only the distribution functions, not the random 
                    variables themselves.
                </p>

                <div class="theorem">
                    <span class="theorem-title">3. Convergence in Distribution (\( \xrightarrow{D} \))</span>
                    <p>
                        This is the weakest form, focusing only on the cumulative distribution functions (CDFs). We say \(X_n\) converges to \(X\) 
                        <strong>in distribution</strong> if:
                        \[
                        \lim_{n \to \infty} F_n(x) = F(x)
                        \]
                        for all points \(x\) where \(F\) is continuous.
                    </p>
                </div>

                 <p>
                    Convergence in distribution does not require the random variables to be defined on the same probability space.
                    It is purely a statement about CDFs. This is the setting of the <strong>Central Limit Theorem (CLT)</strong>, which 
                    describes how the standardized fluctuations of \(\bar{X}_n\) around \(\mu\) converge to a 
                    <a href="gaussian.html"><strong>normal distribution</strong></a>.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Hierarchy of Convergence Modes</span>
                    <p>
                        The three modes satisfy the following implications:
                        \[
                        \xrightarrow{a.s.} \;\Longrightarrow\; \xrightarrow{P} \;\Longrightarrow\; \xrightarrow{D}.
                        \]
                        The reverse is not generally true. However, if the limit \(X\) is a <strong>constant</strong> 
                        (as in LLN), then convergence in distribution implies convergence in probability.
                    </p>
                </div>

                <div class="insight-box">
                    <h3>Deep Dive: Why so many modes?</h3>
                   
                    <p>
                        The distinction between these modes reflects how "well-behaved" a distribution's <strong>moments</strong> are. 
                        To see why we need these conditions, we first must look at the <a href="student.html#cauchy"><strong>Cauchy Distribution</strong></a>.
                    </p>
                    <ul style="padding-left: 40px;">
                        <li>
                            <strong>The Pathological Case (Cauchy):</strong><br>
                            The Cauchy distribution has such "heavy tails" that its <strong>mean is undefined</strong> 
                            (\(\mathbb{E}[|X|] = \infty\)). Because it lacks a finite mean, the Law of Large Numbers fails completely.
                            The sample average \(\bar{X}_n\) of Cauchy variables does not settle down, and it follows the same Cauchy distribution 
                            as a single observation, no matter how large \(n\) is.
                        </li>
                        <li>
                            <strong>Finite Mean (\(\mathbb{E}[|X|] < \infty\)):</strong><br>
                            This is the bare minimum for the universe to have a "balance point." Under this condition, 
                            the <strong>Strong Law of Large Numbers (SLLN)</strong> guarantees the strongest mode: \(\xrightarrow{a.s.}\).
                        </li>
                        <li>
                            <strong>Finite Variance (\(\sigma^2 < \infty\)):</strong><br>
                            This ensures the "spread" doesn't explode. While the <strong>Weak Law (WLLN)</strong> only needs a finite mean 
                            to reach \(\xrightarrow{P}\), having a finite variance allows us to use <strong>Chebyshev's Inequality</strong> 
                            for a simple proof and, more importantly, enables the <strong>Central Limit Theorem (CLT)</strong>.
                        </li>
                    </ul>
                    <p>
                        We use \(\xrightarrow{P}\) for the <strong>LLN</strong> to confirm our estimates hit the bullseye.<br>
                        We use \(\xrightarrow{D}\) for the <strong>CLT</strong> to understand the "shape" of our uncertainty.<br> 
                        If you are dealing with Cauchy-like heavy tails (common in finance or network theory), these 
                        standard convergence tools may break down.
                    </p>
                </div>

                <p>
                    In the following sections, we develop each of the two weaker modes in detail - first convergence in probability 
                    with the Continuous Mapping Theorem, then convergence in distribution with a proof that the former implies the latter. 
                    Finally, we introduce the moment generating function and use it to give a rigorous proof of the Central Limit Theorem.
                </p>

            </section>
           
            <section id="prob" class="section-content">
                <h2>Convergence in Probability</h2>

                <p> 
                    We now develop convergence in probability in more detail. Recall that this mode captures the idea that 
                    \(X_n\) becomes increasingly unlikely to deviate from \(X\) by any fixed amount. Unlike almost sure 
                    convergence, it does not require individual sample paths to converge pointwise - only that "large deviations" become rare events.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Convergence in Probability</span>
                    <p>
                        Let \(\{X_n\}\) be a sequence of random variables and \(X\) be a random variable on a common probability 
                        space. We say \(X_n\) <strong>converges in probability</strong> to \(X\), written \(X_n \xrightarrow{P} X\), 
                        if for every \(\epsilon > 0\),
                        \[
                        \lim_{n \to \infty} P[|X_n - X| \geq \epsilon] = 0,
                        \]
                        or equivalently,
                        \[
                        \lim_{n \to \infty} P[|X_n - X| < \epsilon] = 1.
                        \]
                    </p>
                </div>

                 <p>
                    A natural question arises: if \(X_n \xrightarrow{P} X\), what happens when we apply a continuous 
                    function to \(X_n\)? The following theorem answers this question and is indispensable for deriving 
                    the asymptotic behavior of estimators.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Continuous Mapping Theorem</span>
                    <p>
                        Suppose \(X_n \xrightarrow{P} a\) where \(a\) is a constant, and the function \(f\) is continuous at \(a\). Then 
                        \[
                        f(X_n) \xrightarrow{P} f(a).
                        \]
                    </p>    
                </div>

                <div class="proof">
                    <span class="proof-title">Proof:</span>
                    <p>
                        Let \(\epsilon > 0\). Since \(f\) is continuous at \(a\), \(\, \exists \delta > 0 \) such that 
                        \[
                        |x - a| < \delta \Longrightarrow |f(x) - f(a)| < \epsilon. 
                        \]
                        Taking the contrapositive, 
                        \[
                        |f(x) - f(a)| \geq \epsilon \Longrightarrow  |x - a| \geq \delta.
                        \]
                        Substituting \(X_n\) for \(x\), we obtain 
                        \[
                        P[|f(X_n) - f(a)| \geq \epsilon] \leq P [|X_n - a| \geq \delta ].
                        \]
                        As \(n \to \infty\), the right-hand side vanishes by assumption, hence \(f(X_n) \xrightarrow{P} f(a)\).
                    </p>
                </div>

                <p>
                    More generally, if \(X_n \xrightarrow{P} X\) (where \(X\) is a random variable, not necessarily constant) 
                    and \(f\) is continuous, then 
                    \[
                    f(X_n) \xrightarrow{P} f(X).
                    \]
                    The proof follows similar logic but requires a more careful measure-theoretic argument.
                </p>

                <p>
                    <strong>Why this matters:</strong> The Continuous Mapping Theorem allows us to transfer convergence results 
                    through transformations. For instance, if sample means converge in probability to \(\mu\), then 
                    \(\bar{X}_n^2 \xrightarrow{P} \mu^2\) and \(e^{\bar{X}_n} \xrightarrow{P} e^\mu\). This is essential 
                    for deriving the asymptotic behavior of estimators and test statistics.
                </p>
            </section>

            <section id="dist" class="section-content">
                <h2>Convergence in Distribution</h2>

                <p> 
                    We now turn to the weakest mode of convergence. Unlike convergence in probability, which tracks how the 
                    random variables themselves behave, <strong>convergence in distribution</strong> focuses solely on the 
                    cumulative distribution functions (CDFs). Two sequences of random variables can converge to the same 
                    limiting distribution even if they are defined on entirely different probability spaces.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Convergence in Distribution</span>
                    <p>
                        Let \(\{X_n\}\) be a sequence of random variables with CDFs \(F_{X_n}\), and let \(X\) be a random variable 
                        with CDF \(F_X\). We say \(X_n\) <strong>converges in distribution</strong> to \(X\), written \(X_n \xrightarrow{D} X\), 
                        if for every point \(x \in C(F_X)\) (where \(C(F_X)\) is the set of all points where \(F_X\) is continuous),
                        \[
                        \lim_{n \to \infty} F_{X_n}(x) = F_X(x).
                        \]
                        The distribution of \(X\) is often called the <strong>asymptotic (limiting) distribution</strong> of 
                        the sequence \(\{X_n\}\).
                    </p>
                </div>

                <p>
                    <strong>Key distinction:</strong> Convergence in distribution does not imply convergence in probability. 
                    For example, let \(X \sim N(0,1)\) and define \(X_n = -X\) for all \(n\). Then \(X_n \xrightarrow{D} X\) 
                    (since both have the same standard normal distribution), yet \(|X_n - X| = 2|X|\) does not converge to zero 
                    in probability.
                </p>
                <p>
                    However, the reverse implication does hold:
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem:</span>
                    <p>
                        If \(X_n\) converges to \(X\) in probability, then \(X_n\) converges to \(X\) in distribution. 
                    </p>
                </div>

                <p>
                    <strong>Intuition:</strong> If \(X_n\) is increasingly likely to be close to \(X\) (convergence in probability), 
                    then the probability mass of \(X_n\) must accumulate where \(X\) places its mass, forcing the CDFs to align.
                </p>

                <div class="proof">
                    <span class="proof-title">Proof:</span>
                    <p>
                        Suppose \(X_n \xrightarrow{P} X\), and let \(x\) be a point of continuity of \(F_X\).
                    </p>

                    <p>
                        <strong>Upper bound.</strong><br>
                        For any \(\epsilon > 0\), partition the event 
                        \(\{X_n \leq x\}\) according to whether \(|X_n - X| < \epsilon\):
                        \[
                        \begin{align*}
                        F_{X_n}(x) &= P[X_n \leq x] \\
                                &= P[\{X_n \leq x\} \cap \{|X_n - X| < \epsilon\}] + P[\{X_n \leq x\} \cap \{|X_n - X| \geq \epsilon\}] \\
                                &\leq P[X \leq x + \epsilon] + P[|X_n - X| \geq \epsilon] \\
                                &= F_X(x + \epsilon) + P[|X_n - X| \geq \epsilon].
                        \end{align*}
                        \]
                        The first inequality holds because \(\{X_n \leq x\} \cap \{|X_n - X| < \epsilon\}\) 
                        implies \(X < x + \epsilon\). Since \(X_n \xrightarrow{P} X\), the second 
                        term vanishes, giving
                        \[
                        \limsup_{n \to \infty} F_{X_n}(x) \leq F_X(x + \epsilon). \tag{1}
                        \]
                    </p>

                    <p>
                        <strong>Lower bound:</strong><br>
                        Similarly, consider the complementary event:
                        \[
                        \begin{align*}
                        1 - F_{X_n}(x) &= P[X_n > x] \\
                                &\leq P[X > x - \epsilon] + P[|X_n - X| \geq \epsilon] \\
                                &= 1 - F_X(x - \epsilon) + P[|X_n - X| \geq \epsilon].
                        \end{align*}
                        \]
                        Rearranging and taking the limit inferior:
                        \[
                        \liminf_{n \to \infty} F_{X_n}(x) \geq F_X(x - \epsilon). \tag{2}
                        \]
                    </p>

                    <p>
                        Combining (1) and (2):
                        \[
                        F_X(x - \epsilon) \leq \liminf_{n \to \infty} F_{X_n}(x) \leq \limsup_{n \to \infty} F_{X_n}(x) \leq F_X(x + \epsilon).
                        \]
                        Since \(x\) is a point of continuity of \(F_X\), letting \(\epsilon \to 0\) gives 
                        \(F_X(x - \epsilon) \to F_X(x)\) and \(F_X(x + \epsilon) \to F_X(x)\), so
                        \[
                        \lim_{n \to \infty} F_{X_n}(x) = F_X(x).
                        \]
                        Since this holds for every continuity point of \(F_X\), we conclude 
                        \(X_n \xrightarrow{D} X\).
                    </p>
                </div>

                <p>
                    We can now see that the <strong>Central Limit Theorem (CLT)</strong> - first stated without proof in 
                    <a href="gaussian.html#clt"><strong>Part 4: Gaussian Distribution</strong></a> - is precisely a statement 
                    about convergence in distribution. To prove the CLT rigorously, we need a tool that characterizes distributions 
                    and behaves well under limits: the moment generating function.
                </p>

            </section>

            <section id="mgf" class="section-content">
                <h2>Moment Generating Function (MGF)</h2>

                 <p>
                    Verifying convergence in distribution directly - by showing pointwise convergence of CDFs at every continuity point - is 
                    often impractical. The <strong>moment generating function (MGF)</strong> provides a powerful alternative: 
                    it uniquely determines a distribution (when it exists) and converts the problem of distributional convergence into the 
                    simpler problem of pointwise convergence of real-valued functions.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Definition: Moment Generating Function (MGF)</span>
                    <p>
                        Let \(X\) be a random variable such that for some \(h > 0\), the expectation of \(e^{tX}\) exists 
                        for \(t \in (-h, h)\). The <strong>moment generating function</strong> of \(X\) is defined by
                        \[
                        M(t) = \mathbb{E}(e^{tX}), \qquad t \in (-h, h).
                        \]
                    </p>
                </div>

                <p>
                    <strong>Why "moment generating"?:</strong> Expanding \(e^{tX}\) as a power series and taking expectations term-by-term:
                    \[
                    \begin{align*}
                    M(t) = \mathbb{E}\left[\sum_{k=0}^{\infty} \frac{(tX)^k}{k!}\right] 
                         = \sum_{k=0}^{\infty} \frac{t^k}{k!} \mathbb{E}(X^k).
                    \end{align*}
                    \]
                    Thus, the \(k\)-th derivative at zero gives the <strong>\(k\)-th moment</strong>: 
                    \[
                    M^{(k)}(0) = \mathbb{E}(X^k).
                    \]
                </p>

                <p>
                    <strong>Why require an open interval around 0?</strong> The MGF must exist in a neighborhood of zero 
                    (not just at \(t = 0\)) to guarantee that it uniquely determines the distribution and that we can 
                    differentiate to extract moments. If the MGF exists only at \(t = 0\), it provides no useful information.
                </p>

                <p>
                    The key theorem connecting MGFs to convergence in distribution is:
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Lévy's Continuity Theorem - MGF Version</span>
                    <p>
                        Let \(\{X_n\}\) be a sequence of random variables with MGFs \(M_n(t)\) that exist for \(t \in (-h, h)\). 
                        If \(M_n(t) \to M(t)\) for all \(t\) in some <strong>open interval</strong> containing 0, and \(M(t)\) is 
                        the MGF of a random variable \(X\), then
                        \[
                        X_n \xrightarrow{D} X.
                        \]
                    </p>
                </div>

                <p>
                    This theorem transforms the problem: instead of comparing CDFs pointwise, we show MGFs converge. 
                    We now apply this strategy to prove the Central Limit Theorem.
                </p>

                <div class="theorem">
                    <span class="theorem-title">Theorem: Central Limit Theorem (CLT)</span>
                    <p>
                        Let \(X_1, X_2, \ldots, X_n\) be i.i.d. random variables with mean \(\mu\) and variance \(\sigma^2 > 0\). 
                        Assume the MGF \(M(t) = \mathbb{E}(e^{tX})\) exists in a neighborhood of zero. Then the standardized sum
                        \[
                        Y_n = \frac{\sum_{i=1}^{n} X_i - n\mu}{\sigma \sqrt{n}} = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma}
                        \]
                        converges in distribution to a standard normal:
                        \[
                        Y_n \xrightarrow{D} N(0, 1).
                        \]
                    </p>
                </div>

                <div class="proof">
                    <span class="proof-title">Proof:</span>
                    <p>
                        <strong>Step 1: MGF of centered variable.</strong><br>
                        Define \(W = X - \mu\). The MGF of \(W\) is:
                        \[
                        m(t) = \mathbb{E}[e^{t(X-\mu)}] = e^{-\mu t} M(t), \qquad t \in (-h, h).
                        \]
                        Note the key properties:
                        \[
                        m(0) = 1, \quad m'(0) = \mathbb{E}(X - \mu) = 0, \quad m''(0) = \mathbb{E}[(X-\mu)^2] = \sigma^2.
                        \]
                    </p>
                    <p>
                        <strong>Step 2: Taylor expansion.</strong><br>
                        By Taylor's theorem with Lagrange remainder, for any \(t\) in the domain, there exists \(\xi\) between \(0\) and \(t\) such that:
                        \[
                        m(t) = m(0) + m'(0)t + \frac{m''(\xi)}{2}t^2 = 1 + \frac{m''(\xi)}{2}t^2.
                        \]
                        We rewrite this as:
                        \[
                        m(t) = 1 + \frac{\sigma^2 t^2}{2} + \frac{[m''(\xi) - \sigma^2]t^2}{2}. \tag{3}
                        \]
                    </p>
                    <p>
                        <strong>Step 3: MGF of the standardized sum.</strong><br>
                        By independence:
                        \[
                        M_n(t) = \mathbb{E}\left[\exp\left(t \cdot \frac{\sum_{i=1}^{n}(X_i - \mu)}{\sigma\sqrt{n}}\right)\right] 
                               = \left[m\left(\frac{t}{\sigma\sqrt{n}}\right)\right]^n.
                        \]
                    </p>
                    <p>
                        <strong>Step 4: Substitute and take limit.</strong><br>
                        Replacing \(t\) with \(\frac{t}{\sigma\sqrt{n}}\) in equation (3):
                        \[
                        m\left(\frac{t}{\sigma\sqrt{n}}\right) = 1 + \frac{t^2}{2n} + \frac{[m''(\xi_n) - \sigma^2]t^2}{2n\sigma^2}
                        \]
                        where \(\xi_n \in \left(0, \frac{t}{\sigma\sqrt{n}}\right)\). Thus:
                        \[
                        M_n(t) = \left\{1 + \frac{t^2}{2n} + \frac{[m''(\xi_n) - \sigma^2]t^2}{2n\sigma^2}\right\}^n.
                        \]
                        As \(n \to \infty\), we have \(\xi_n \to 0\), and by continuity of \(m''(t)\) at \(t = 0\):
                        \[
                        m''(\xi_n) \to m''(0) = \sigma^2 \implies m''(\xi_n) - \sigma^2 \to 0.
                        \]
                        Using the fundamental limit \(\lim_{n \to \infty}\left(1 + \frac{x}{n}\right)^n = e^x\) with \(x = \frac{t^2}{2}\):
                        \[
                        \lim_{n \to \infty} M_n(t) = e^{t^2/2}.
                        \]
                    </p>
                    <p>
                        <strong>Step 5: Identify the limit.</strong><br>
                        The function \(e^{t^2/2}\) is the MGF of \(N(0,1)\). By Lévy's Continuity Theorem:
                        \[
                        Y_n = \frac{\sqrt{n}(\bar{X}_n - \mu)}{\sigma} \xrightarrow{D} N(0,1).
                        \]
                    </p>
                </div>

                <div class="proof">
                    <span class="proof-title">Verification: MGF of \(N(0,1)\)</span>
                    <p>
                        We confirm that \(e^{t^2/2}\) is the MGF of the standard normal distribution:
                        \[
                        \begin{align*}
                        M(t) &= \int_{-\infty}^{\infty} e^{tx} \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \, dx \\
                             &= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-(x^2 - 2tx)/2} \, dx \\
                             &= \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-[(x-t)^2 - t^2]/2} \, dx \\
                             &= e^{t^2/2} \underbrace{\int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{-(x-t)^2/2} \, dx}_{= 1}  \\
                             &= e^{t^2/2}.
                        \end{align*}
                        \]
                        The key step is completing the square in the exponent and recognizing the remaining integral 
                        as the total probability of \(N(t, 1)\).
                    </p>
                </div>

                <p>
                    Without standardization, the CLT can equivalently be written as
                    \[
                    \sqrt{n}(\bar{X}_n - \mu) \xrightarrow{D} N(0, \sigma^2),
                    \]
                    which makes the role of \(\sigma^2\) explicit: the fluctuations of \(\bar{X}_n\) around \(\mu\) 
                    have order \(\sigma / \sqrt{n}\), and once rescaled by \(\sqrt{n}\), they converge to a Gaussian with variance \(\sigma^2\).
                </p>

                <div class="insight-box">
                    <h3>Connections to Machine Learning</h3>
                    <p>
                        The convergence results developed in this section are not merely theoretical. The <strong>Law of Large Numbers</strong> 
                        justifies replacing expectations with sample averages, which is the foundation of empirical risk minimization: 
                        minimizing the training loss converges to minimizing the true expected loss as the dataset grows. The <strong>CLT</strong> 
                        explains why confidence intervals and hypothesis tests (from <a href="hypothesis_testing.html"><strong>Part 10</strong></a>) 
                        work: test statistics are asymptotically normal regardless of the underlying distribution. In deep learning, 
                        the <strong>Continuous Mapping Theorem</strong> ensures that if parameter estimates converge, so do the predictions of any 
                        continuous model.
                    </p>
                </div>

                <p>
                    We now have the tools to reason rigorously about parameter estimation and inference. 
                    In <a href="bayesian.html"><strong>Part 14: Introduction to Bayesian Statistics</strong></a>, we adopt a fundamentally 
                    different perspective on inference - treating parameters themselves as random variables with prior 
                    distributions - where the convergence results developed here ensure that Bayesian and frequentist approaches agree 
                    in the large-sample limit.
                </p>

            </section>
        </div>
        <script src="/js/main.js"></script>    
    </body>
</html>