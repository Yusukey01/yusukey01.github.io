<!DOCTYPE html>
<html>
    <head> 
        <title>Statistical Inference & Hypothesis Testing</title>
        <link rel="stylesheet" href="../styles.css">
        <script id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="https://cdn.jsdelivr.net/pyodide/v0.23.3/full/pyodide.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1">
    </head>
    <body> 
        <div class="toc-container">
            <h2>Contents</h2>
            <ul>
                <li><a href="#NHST">Null Hypothesis Significance Test</a></li>
                <li><a href="#"></a></li>
                <li><a href="#"></a></li>
                <li><a href="#"></a></li>
            </ul>
        </div>

        <h1 id="NHST">Null Hypothesis Significance Test</h1>
        <blockquote>
            Once we have a statistical model (or <strong>hypothesis</strong>), we need to assess whether it's plausible given our data \(\mathcal{D}\). 
            In this section, we introduce <strong>frequentist statistical inference</strong> and <strong>hypothesis testing</strong>. Although 
            <a href="bayesian.html"><strong>Bayesian inference</strong></a> can replace many frequentist techniques and is especially popular in 
            modern machine learning, frequentist methods remain valuable tools â€” they're often simpler to compute, more standardized, and provide 
            complementary insights.
            <br><br>
            Here, we discuss the <strong>null hypothesis significance test(NHST)</strong>.
            <br>
            Suppose we have two competing hypotheses:
            <ul>
                <li><strong>Null Hypothesis</strong> \(H_0\): This is the default assumption.</li>

                <li><strong>Alternative Hypothesis</strong> \(H_1\): This represents the claim we wish to support.</li>
            </ul>
            (So, hypothesis testing is a kind of <strong>binary classification</strong> problem.)
            <br><br>
            Our goal is to decide which hypothesis is more plausible. Usually, our reasoning is that if \(H_0\) is very unlikely, 
            then we conclude that \(H_1\) would be true (i.e., we <strong>reject the null hypothesis</strong>). 
            <br><br>
            Rejecting \(H_0\) does NOT mean \(H_1\) is absolutely true. Conversely, failing to reject \(H_0\) only means 
            that the evidence is insufficient to support \(H_1\). Thus, our conclusion can be wrong: 
            <ul>
                <li><strong>Type I error</strong>(or <strong>false negative</strong>) : Accidentally rejecting the null \(H_0\) when it is true.</li>
                <li><strong>Type II error</strong>(or <strong>false positive</strong>): Accidentally accepting \(H_0\) when the alternative \(H_1\) is true.</li>
            </ul>
            (The type I error rate \(\alpha\) is called <strong>significance</strong> of the hypothesis test.)
            <br><br>
            First, we choose a function of the data \(\mathcal{D}\) that summarizes the evidence against \(H_0\). This is called a 
            <strong>test statistic</strong>, \(test(\mathcal{D})\). Then we can compare its observed value to the value we would expect if the
            data came from the null hypothesis, \(test(\tilde{\mathcal{D}})\) where \(\tilde{\mathcal{D}} \sim H_0\). If the observed value is unexpected
            given \(H_0\), we reject the null hypothesis. To quantity this, we define the <strong>p-value</strong> to be the probability, 
            under \(H_0\), of observing a test statistic that is as large or larger than that actually observed:
            \[
            pval = P(test(\tilde{\mathcal{D}}) \geq test(\mathcal{D}) | \tilde{\mathcal{D}} \sim H_0).
            \]
        </blockquote>

        <h1 id=""></h1>
        <blockquote>
        </blockquote>

        <h1 id=""></h1>
        <blockquote>
        </blockquote>

        <h1 id=""></h1>
        <blockquote>
        </blockquote>


        
        <br><a href="../../index.html">Back to Home </a>
        <br> <a href="probability.html">Back to Probability </a> 

        <script src="../runPythonCode.js"></script>
        <script src="../collapsible.js"></script>  
    </body>
</html>