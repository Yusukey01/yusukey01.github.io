<!DOCTYPE html>
<html>
    <head> 
        <title>Orthogonality</title>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <link rel="stylesheet" href="../styles.css"> 
    </head>
    <body> 
        <h1>Jacobian Matrices</h1>
        <blockquote>
            Consider \(f(x) \in \mathbb{R}^m\), where \(x \in \mathbb{R}^n\). By the differential notation,
            \[
            df = f'(x)dx
            \]
            where \(df \in \mathbb{R}^m \, \), \(dx \in \mathbb{R}^n\) and here, the linear operator \(f'(x)\) is 
            the \(m \times n\) <strong>Jacobian matrix</strong> such that:
            \[
             J_{ij} = \frac{\partial f_i}{\partial x_j}.
            \]
            Here, \(J_{ij}\) represents the rate of change of the \(i\)-th output \(f_i\) with respect to the 
            \(j\)-th input \(x_j\).
            <br>
            For example, Let \(f(x) = \begin{bmatrix}f_1(x) \\ f_2(x) \end{bmatrix}\), 
            and \(x = \begin{bmatrix}x_1 \\ x_2 \end{bmatrix} \). Then
            \[
            df = \begin{bmatrix} \frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} \\
                                 \frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} 
                 \end{bmatrix}
                 \begin{bmatrix} dx_1 \\ dx_2 \end{bmatrix}
              =  \begin{bmatrix} \frac{\partial f_1}{\partial x_1}dx_1 + \frac{\partial f_1}{\partial x_2}dx_2 \\
                                 \frac{\partial f_2}{\partial x_1}dx_1 + \frac{\partial f_2}{\partial x_2}dx_2 
                 \end{bmatrix}.
            \]
            As you can see, the Jacobian matrix \(f'(x)\) acts as a linear operator that maps changes in \(x\) 
            encoded in \(dx\) to corresponding changes in \(f(x)\) encoded in \(df\).
            <br>
            Instead of expressing the Jacobian component by component, it is often more convenient to use a 
            symbolic representation. 
            For example, consider a trivial case: the matrix equation \(f(x) = Ax\) where \(A \in \mathbb{R}^{m \times n}\) 
            is a constant matrix.
            Then 
            \[
            df = f(x + dx) -f(x) = A(x + dx) - Ax = Adx = f'(x)dx
            \]
            Thus \(f'(x) = A \) is the Jacobian matrix. 
            
        </blockquote>

        <h1>Chain Rule</h1>
        <blockquote>
            <div class="theorem">
                <span class="theorem-title">Theorem 1: Chain Rule</span> 
                Suppose \(f(x) = g(h(x))\) where both \(g\) and \(h\) are differentiable. Then
                \[
                df = f'(x)[dx] = g'(h(x))[h'(x)[dx]] 
                \]
            </div>
            Intuitively, if we think about a higher dimensional case, it is clear that the chain rule is not commutative in general. 
            <br>
            For example, consider 
                \[
                x \in \mathbb{R}^n, \, h(x) \in \mathbb{R}^p, \, \text{and } g(h(x)) \in \mathbb{R}^m
                \] 
            Then the output must be the \(m \times n\) <strong>Jacobian matrix</strong> \(f'(x)\).
            <br>
            To construct this \(m \times n\) matrix, we must need the product of the \(m \times p\) Jacobian matrix \(g'(h(x))\) 
            and the \(p \times n\) Jacobian matrix h'(x) in this order. 
        </blockquote>

        
        <a href="../index.html">Back to Home </a>
        <br> <a href="calculus.html">Back to Calculus </a>
    </body>
</html>